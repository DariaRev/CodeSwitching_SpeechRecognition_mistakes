{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gej6xVSr97m",
        "outputId": "3a505d7b-8da5-49dc-da10-a036e0eb7606"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<Response [200]>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/2 [00:00<?, ?it/s]\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 5 \n",
            "---------\n",
            "Парсинг страницы 1 из 6\n",
            "https://habr.com/ru/flows/design/page1\n",
            "Started\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            " 20%|██        | 1/5 [00:19<01:17, 19.42s/it]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 5 \n",
            "---------\n",
            "Парсинг страницы 2 из 6\n",
            "https://habr.com/ru/flows/design/page2\n",
            "Started\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            " 40%|████      | 2/5 [00:40<01:00, 20.20s/it]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 5 \n",
            "---------\n",
            "Парсинг страницы 3 из 6\n",
            "https://habr.com/ru/flows/design/page3\n",
            "Started\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            " 60%|██████    | 3/5 [01:00<00:40, 20.36s/it]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 5 \n",
            "---------\n",
            "Парсинг страницы 4 из 6\n",
            "https://habr.com/ru/flows/design/page4\n",
            "Started\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            " 80%|████████  | 4/5 [01:20<00:20, 20.19s/it]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 5 \n",
            "---------\n",
            "Парсинг страницы 5 из 6\n",
            "https://habr.com/ru/flows/design/page5\n",
            "Started\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 5/5 [01:41<00:00, 20.22s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 1/2 [01:44<01:44, 104.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6 11\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6 5 \n",
            "---------\n",
            "Парсинг страницы 6 из 11\n",
            "https://habr.com/ru/flows/design/page6\n",
            "Started\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            " 20%|██        | 1/5 [00:20<01:21, 20.32s/it]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6 5 \n",
            "---------\n",
            "Парсинг страницы 7 из 11\n",
            "https://habr.com/ru/flows/design/page7\n",
            "Started\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            " 40%|████      | 2/5 [00:40<01:00, 20.21s/it]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6 5 \n",
            "---------\n",
            "Парсинг страницы 8 из 11\n",
            "https://habr.com/ru/flows/design/page8\n",
            "Started\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            " 60%|██████    | 3/5 [01:00<00:40, 20.08s/it]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6 5 \n",
            "---------\n",
            "Парсинг страницы 9 из 11\n",
            "https://habr.com/ru/flows/design/page9\n",
            "Started\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            " 80%|████████  | 4/5 [01:20<00:20, 20.19s/it]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6 5 \n",
            "---------\n",
            "Парсинг страницы 10 из 11\n",
            "https://habr.com/ru/flows/design/page10\n",
            "Started\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 5/5 [01:41<00:00, 20.27s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6 11\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [03:28<00:00, 104.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11 16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "import re\n",
        "import sqlite3\n",
        "from pprint import pprint\n",
        "from tqdm import tqdm  \n",
        "from time import sleep\n",
        "\n",
        "#https://habr.com/ru/company/pixonic/blog/662812/\n",
        "#https://habr.com//ru/company/pixonic/blog/662812/\n",
        "\n",
        "URL_left = 'https://habr.com/ru'\n",
        "URL_right = ['/flows/design/', '/flows/management/', '/flows/marketing/','/flows/develop/']\n",
        "HEADERS = {'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.130 Safari/537.36', 'accept': '*/*'}\n",
        "HOST = 'https://habr.com'\n",
        "FILE = 'habr.csv'\n",
        "\n",
        "def get_html(url, params = None):\n",
        "    r = requests.get(url, headers = HEADERS, params = params, timeout=5)\n",
        "    return r\n",
        "\n",
        "#собираем контент со страницы\n",
        "def get_content(html):\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    items = soup.find_all(\"article\", class_ = \"tm-articles-list__item\")\n",
        "    print(\"Started\")\n",
        "    texts = []\n",
        "    links = []\n",
        "    for item in items:\n",
        "        try:\n",
        "            link = HOST + item.find('a', class_ = 'tm-article-snippet__title-link').get('href')\n",
        "        except Exception:\n",
        "            print('Product link missing')\n",
        "            link = ''\n",
        "        text = get_more_inf(link)\n",
        "        texts.append({\n",
        "            'link':link,\n",
        "            'text':text\n",
        "        })\n",
        "\n",
        "    return texts\n",
        "#собираем articles\n",
        "def get_more_inf(link):\n",
        "    if link == None or link == '':\n",
        "        return '', '', '', ''\n",
        "    text=[]\n",
        "    try:\n",
        "        h = get_html(link)\n",
        "        soup = BeautifulSoup(h.text, 'html.parser')\n",
        "\n",
        "        reviews = soup.find_all('p')\n",
        "        for review in reviews:\n",
        "            #print(review, '\\n------')\n",
        "            new_r = ''.join(review.findAll(text=True))\n",
        "            #new_r=review.get_text(strip=True)\n",
        "            text.append(new_r)\n",
        "        #print(text)\n",
        "        #pages = int(soup.find_all('a', class_='pageNum')[-1].get('data-page-number'))\n",
        "        return text\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "def save_file(items, path):\n",
        "    with open (path, 'w', newline = '') as f:\n",
        "        writer = csv.writer(f, delimiter = ';')\n",
        "        writer.writerow(['link', 'text'])\n",
        "        for item in items:\n",
        "            writer.writerow([item['link'], item['text']])\n",
        "\n",
        "#parse some pages\n",
        "def go_through_pages(URL_left, URL_Right, ix, batches, cafes):\n",
        "    for page in tqdm(range(ix, batches+ix)):\n",
        "        print(ix, batches, '\\n---------')\n",
        "        #if batches+ix > 100:\n",
        "        #   return cafes\n",
        "        URL_new = URL_left+URL_right[0]+f'page{page}'\n",
        "        print('Парсинг страницы', page, 'из', batches+ix)\n",
        "        \n",
        "        print(URL_new)\n",
        "        sleep(2)\n",
        "        html = get_html(URL_new)\n",
        "        cafes.extend(get_content(html.text))\n",
        "    return cafes\n",
        "def parse():\n",
        "    html = get_html(URL_left+URL_right[0])\n",
        "    print(html)\n",
        "    if html.status_code == 200:\n",
        "        cafes = []\n",
        "        #cafes.extend(get_content(html.text))\n",
        "        batches = 5\n",
        "        ix = 1\n",
        "        for i in tqdm(range(2)):\n",
        "            go_through_pages(URL_left, URL_right, ix, batches, cafes)\n",
        "            print(ix, batches+ix)\n",
        "            ix = batches+ix\n",
        "            sleep(3)\n",
        "            print(ix, batches+ix)\n",
        "        return cafes\n",
        "    else:\n",
        "        print ('Error')\n",
        "\n",
        "p = parse()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kg1fuRxyLP3",
        "outputId": "9df20daa-29e6-40b7-83af-cb19b5480ae1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'link': 'https://habr.com/ru/company/koshelek/blog/663510/', 'text': ['Как часто вы задумывались, как пользователи воспринимают ваше приложение? Со стороны разработчика всё просто: вы знаете, как что работает, в каком разделе можно всё найти или настроить и, конечно же, как надо пользоваться фичами. Мы все прекрасно понимаем, в каких случаях приложение будет полезно, чем оно отличается от аналогов и почему именно оно прекрасно. Мы любим свои приложения.', 'Но если зайти в аналитику использования или поговорить с пользователями по душам, то быстро становится понятно, что не все обладают вашим знанием о приложении.\\xa0', 'Та супер-мега полезная функциональность, над которой вы трудились несколько месяцев, вкладывая туда свою душу, силы и деньги, используется лишь малым количеством людей. А невероятный, продуманный, удобный и простой UX-дизайн пользователи не видят в упор. Более того, Полезная Функциональность воспринимается многими, как бесполезный гиммик, который отвлекает от центрального, по-настоящему нужного сценария использования.', 'Не спешите унывать! Это совсем не значит, что ваша новая фича не нужна, не интересна и бесполезна. Скорее всего, масса пользователей даже не знают о ней. Либо вы плохо объяснили, зачем она нужна.', 'Эта проблема коснулась и нас. Наше приложение, Кошелёк, стремительно развивается. У нас появилось и разрабатываются много новых сервисов и функций, помимо хранения скидочных карт. Но внешний вид и структура приложения долгое время оставались прежними. Нам нужно было подготовить приложение и, самое главное, пользователей, к новой функциональности.', 'Впереди нас ждал долгий, но крайне увлекательный путь, главной целью которого была смена устоявшейся парадигмы: «Кошелёк — это приложение, которое хранит ваши карточки».\\xa0', 'Ведь мы умеем и готовимся научиться делать намного больше.', 'Мы начали с обзора существующих решений доставки «знаний» пользователю.', 'В Кошельке есть несколько способов обучения пользователей имеющейся в приложении функциональности:', 'отдельные онбординги по крупным фичам;', 'всплывающие подсказки, ведущие, например, на каталог для выпуска новой карты или на сценарий фотографирования уже выпущенной физической карты;', 'release notes, чтобы зацепить внимание пользователя;', 'пуш-оповещения.', 'Эти инструменты эффективны, но далеко не всегда. Пользователи склонны определять инструменты онбординга как нечто отвлекающее от центрального сценария, поэтому часто не обращают на них внимания.', 'Можно, конечно, нарастить использование этих инструментов. Но тогда пользователи начинают воспринимать все эти бесконечные пуши, подсказки, интро-скрины как навязчивую рекламу. А к 2022 году у огромного множества людей уже давно образовалась раздражающая мозоль от автоматического закрытия этих инструментов. И, конечно же, баннерная слепота.\\xa0', 'Наконец, наше пользовательское исследование показало, что основная активность внутри приложения происходит сразу после установки. Люди изучают большую часть функциональности в новом для себя приложении. Но они не всегда готовы внимательно разобраться, что вообще умеет приложение. Как следствие, они оседают в тех сценариях, которые им нужны и запомнились.\\xa0', 'Если таким пользователям подробнее рассказать про разную функциональность, приложения, они начинают ей интересоваться и даже конвертироваться в активных пользователей. Эту гипотезу мы тоже проверили в упомянутом исследовании.', 'Итого, нам был необходим нативный и удобный в использовании сценарий для 13 миллионов регулярных пользователей. Сценарий, который бы позволял интегрировать точки входа в другие функциональности и был легко расширяем.', 'Мы пришли к логичному выводу — нужно изменить главный экран приложения.', 'Однако, как говорят классики, с большой силой приходит большая ответственность. Нельзя просто взять и изменить экран с центральным сценарием для миллионов пользователей. Потеря удобной центральной функциональности приравнивается нами к самоубийству.', 'В далёком 2016 году в одном приложении появились те самые «кружочки». Сторис сразу же заняли почётное место в самом верху экрана, чтобы цеплять внимание пользователя. Этому же способствовали заботливо отсортированные алгоритмом по вашим интересам список новых сторис от друзей, которые ещё и дополнительно выделялись разноцветной рамкой.', 'Благодаря сторис приложению удалось полностью изменить парадигму своего сервиса — если раньше посты были для каких-то значимых событий и их количество было в среднем 1 пост за 2-3 дня, то сторис же используются для запечатления любых обыденных моментов из жизни. Недолговечность жизни сторис и удобный 15-секундный формат позволяют выкладывать что угодно, не задумываясь о том, как же поддерживать аккуратность своего профиля.\\xa0', 'Тут обойдёмся без визуальных примеров, сами понимаете.', 'Не так давно, в сервисе по заказу такси Яндекс объединил точки входа в остальные сервисы компании. И назвали они свой суперапп Яндекс.GO. С одной стороны, этот кейс подходит крупным продуктам с россыпью собственных сервисов. С другой стороны, если такие гиганты смогли сделать суперапп, то почему приложения поменьше не могут так же эффективно доставлять другие свои сервисы до внимания пользователей?Это масштабируемая история, изучение которой полезно для развития любого приложения.\\xa0\\xa0', 'Вот несколько плюсов подхода:', 'Ниже стоимость привлечения пользователя, так как сервисы находятся в одном приложении.', 'Единая экосистема способствует удержанию пользователей.', 'Проще рассказать пользователю о всех сервисах.', 'Удобная расширяемость и масштабируемость для новых сервисов.', 'Со стороны, без аналитики сложно оценить эффективность российских «супераппов». Единственным косвенным показателем можно считать то, что Яндекс оставил этот вариант, а не откатился обратно еще на этапе тестирования. Значит, трафик достаточно эффективно перетекает между сервисами.', 'Тут я расскажу про собственный опыт со стандартным приложением для чтения книг на iOS — Apple Books. До недавнего времени я воспринимал это приложение только как библиотеку своих книг, pdf и прочего.Но в iOS 13 главную страницу переработали, добавив туда подборки книг из своего магазина. После этого мой взгляд на это приложение изменился: я наконец-то осознал, что в нём можно не просто читать добавленные книги, но и приобрести другие книги из магазина, который я упорно не замечал в предыдущих версиях, когда он был только на отдельном разделе в таб баре.', 'Хоть это открытие и не актуально на данный момент, так как в России отсутствует возможность купить там книги из-за «отсутствия договоров с местными издателями» (но есть возможность бесплатно скачать классику русской и зарубежной литературы, перешедшей в общественное достояние). Тем не менее, я увидел другие функции приложения, на которые раньше не обращал внимания.', 'Ремарка: на данный момент новая главная раскатана на всех пользователей только на iOS. Разработка на Android ведётся полным ходом, так что скоро появится и там.', 'Предпосылок к обновлению главного экрана было достаточно много. Старый вариант был с нами с момента первой версии приложения, которая вышла аж в 2016 году. Старая главная отслужила нам верой и правдой, в своё время она полностью выполняла все свои основные функции.', 'Но за эти 6 лет наш продукт развивался: MAU перевалил за 13 млн, нашими партнёрами являются более 2 000 компаний, в том числе крупные игроки на рынке, у которых есть потребности в более персональной и сложной интеграции.', 'Мы разработали и готовимся выпустить новые сервисы, такие как Кошелёк Pay для оплаты покупок, кэшбэки, сканер чеков, доставку и хранение электронных чеков и другие фичи.', 'С обогащением функциональности приложения мы стали задумываться, как её отразить через главный экран.', 'Старый интерфейс не готов принимать нашу новую функциональность. Всё место на экране занимают карты, нет вариантов интеграции с другими внутренними сервисами продукта, нет вариантов информирования пользователей о новых фичах и персональных предложениях.', 'Помимо этого, одной из значимых проблем со старой главной было обилие легаси кода, большая часть которого была написана в 2016 году на Objective-C. Каждое изменение в этой части проекта сопровождалось болью и постоянно стреляющими багами. А из-за плохой архитектуры было сложно интегрировать в этот модуль новые фичи.', 'Наконец, лишь единицы на проекте знали, как всё на самом деле работает, что очень затрудняло онбординг новых членов команды.\\xa0', 'Таким образом, переход на новый вид главного экрана решает сразу две проблемы: открывает доступ к интеграциям новых сервисов и фичей, и избавляет проект от значимого куска легаси кода.', 'Главным требованием для первой итерации нового интерфейса главной была возможность интеграции наших внутренних сервисов, таких как выпуск карт партнёров, полезная информация о скидках, акции и кэшбэки.', 'Чтобы освободить место под интеграции, нам нужно было уменьшить количество\\xa0 и размер карт на главном экране. При этом пользовательский опыт не должен был пострадать, так как показ карты на кассе магазина — это самый частый сценарий использования Кошелька. Ежемесячно пользователи показывают свои карты на кассе в среднем 98 миллионов раз.', 'Очевидно, что наши пользователи хотят показывать карты быстро и удобно. Ведь когда стоишь в магазине перед кассой, руки неминуемо заняты детьми, покупками, сумками, при этом нужно еще умудриться достать телефон и найти нужную карту.', 'Поэтому главную нужно было перерабатывать так, чтобы пользователь как минимум не заметил особых изменений в ключевом сценарии. Как максимум — получил как можно менее стрессовый опыт.', 'Мы решили использовать концепцию «быстрого доступа» к картам, которые с большей вероятностью подойдут пользователю в данный момент. Нам было очевидно, что среднестатистический пользователь вряд ли регулярно посещает сотни и даже десятки разных магазинов в месяц и использует весь арсенал карт из своего Кошелька.', 'Быстрый доступ не только позволил бы ускорить сценарий показа нужной карты на кассе, но и дал бы возможность безболезненно сократить используемое под карты ценное пространство. А еще подготовить пользователя к предстоящим изменениям.\\xa0', 'Мы начали изучать шаблоны поведения пользователей, как часто и какими картами они пользуются.', 'В результате мы получили занимательную статистику — 90% пользователей открывают не более 7 различных карт в месяц. При этом у половины пользователей 3 или более из этих 7 карт повторяются из месяца в месяц, а у 30% пользователей повторяются 6 или 7 из 7 карт.', 'Дальше началось самое интересное — придумать алгоритм предсказания популярных карт. В первой версии мы решили использовать прямолинейную логику без сложных моделей. Быстрый доступ состоит из 6 карт, первые четыре из которых — это самые часто используемые карты пользователя, две последние — последние выпущенные карты.', 'Несмотря на простоту алгоритма, он достаточно хорошо показал себя на основных сценариях. Шесть выбранных нами карт с 76% вероятностью будут содержать нужную пользователю карточку. Примечательно, что при дальнейшем увеличении числа карт, вероятность увеличивается не сильно (80% вероятности для списка из 8 карт, 81% вероятности для списка из девяти и двенадцати карт).', 'Для эксперимента такой алгоритм подходил идеально: он прост в реализации, не требует участия бэкенда. Но из-за его простоты он хорошо работает только на основных сценариях. А вот если пользователь, например, уедет в другой город, или же просто пойдёт в магазин, который нечасто посещает, то предсказания не будут актуальны.', 'Естественно, долго останавливаться на этой версии мы не собираемся. Путей для развития алгоритма очень много, начиная от использования геолокации, чтобы предлагать карты магазинов поблизости, до модели, которая обучается на основе поведения пользователя и предлагает ему карты в зависимости от времени суток, дня недели и других факторов.', 'В первом эксперименте мы попробовали расставить компоненты по важности:', 'Первым идёт быстрый доступ, поэтому пользователь точно обратит на него внимание и с большей вероятностью станет им пользоваться.', 'Дальше список актуальных предложений для пользователя. В настоящий момент это список полезных карт, которые он может выпустить.', 'В самом конце идёт список всех карт. По нашим ожиданиям, пользователи будут им пользоваться достаточно редко, так как быстрый доступ и поиск по картам должны заменить им долгий поиск по всему списку.', 'Нам было важно не испугать пользователя таким кардинальным изменением главного экрана. За пять лет без визуальных обновлений пользователи Кошелька уже привыкли к его внешнему виду, у них сложились свои основные шаблоны использования приложения.', 'Поэтому мы решили реализовать дополнительный компонент с информацией об обновлении, описанием новой функциональности и некоторыми базовыми подсказками по новому интерфейсу. Мы также добавили «пути отступления» на старый вариант дизайна. Это нужно, чтобы сгладить впечатления у совсем консервативных пользователей либо же в случаях, если будет найдена какая-то критическая ошибка в новой главной.', 'Компонент быстрого доступа появляется только если у пользователя более 13 карт. В противном случае предсказания работают не слишком качественно и этот компонент становится бесполезным.\\xa0', 'В рамках эксперимента нам пришлось отказаться от части визуальных фич, потому что переносить старые было дорого и больно, а писать с нуля оказалось непозволительной роскошью. Нам хотелось как можно скорее запустить эксперимент и проверить наши гипотезы.', 'Результаты эксперимента оказались положительными:', 'Пользователи быстро приняли новый сценарий. Это подтверждают аналитика по использованию быстрого доступа (70% пользователей его используют, 75% из тех, кто попробовал хотя бы раз, продолжают использовать спустя 7 недель), стабильная пользовательская активность по ключевому сценарию и очень малый процент негатива в отзывах.', 'Блоком с рекомендациями карт стали очень активно пользоваться, мы получили сотни тысяч дополнительных выпусков карт лояльности в месяц.', 'Мы были воодушевлены. Пользователи приняли наши изменения, активность выросла, количество выпущенных карт тоже. Поэтому мы решили доработать то, что получилось, и заложить базис для масштабирования функциональности приложения.\\xa0', 'Для этого мы переместили компонент с рекомендациями наверх, а быстрый доступ и список всех карт сгруппировали вместе. Если расположить нужные карты внизу экрана, то пользователю не придётся далеко тянуться пальцем, отпадает необходимость менять положение телефона в руке.', 'Еще такое расположение нам позволило начать эксперименты с переносом карт в выдвигающуюся шторку, так как мы хотели решить проблему масштабирования. Шторка создаёт дополнительное пространство для любых интеграций с нашими сервисами, будь то выпуск новых карт, кэшбэки или просто полезная для пользователя информация, при этом не мешая отображению списка карт.\\xa0', 'На данный момент мы остановились на втором варианте эксперимента, раскатив его на всех пользователей на iOS. Его же мы заканчиваем разрабатывать для пользователей на Android.', 'Параллельно с этим мы продолжаем тестировать возможные варианты для будущего развития дизайна. Например, почти шесть месяцев мы вели эксперименты\\xa0 с контентом под выдвигающейся секцией. В этих экспериментах карты лояльности пользователей мы убрали в шторку.\\xa0', 'Под ней расположили контентную зону, где показывали пользователям разное: предложения от партнеров, самописные статьи в разных категориях, статьи наших партнёров, предложения по кэшбэкам, акции по картам лояльности и даже возможность бронировать рестораны со скидкой.', 'В результате всех этих экспериментов мы поняли, какой формат контента интересен нашему пользователю.\\xa0', 'Нам стало очевидно, что превращать Кошелёк в «журнал» будет долго, сложно и неинтересно. При этом мы увидели потрясающие результаты в экспериментах, где мы предлагали пользователю проникнуть в дополнительный функционал, такой как акции по картам лояльности или кэшбэк.', 'Во время UX-тестов также выяснилось, что шторка не оптимальна для разделения основного сценария приложения и дополнительных. С одной стороны, мы не можем полностью ее закрыть, ведь тогда мы закроем ключевые сценарии. С другой стороны, из-за неполного закрытия мы отнимаем часть контентной зоны. А на маленьких экранах эта часть была довольно значительной.', 'При этом механика «шторки» хорошо считывалась пользователями: её скрывали-раскрывали, разделение областей экрана на имеющиеся карты и доступные предложения оказалось концептом, понятным большинству пользователей. Более того, мы проводили эксперименты на сотнях тысяч пользователей и не увидели ни одного негативного отзыва или обращения в техническую поддержку.', 'Итого, этот вариант дизайна позволил нам провести много экспериментов и лучше понять потребности наших пользователей. Но прямо сейчас реализовывать шторку и контентное пространство мы не готовы. Долго, дорого, а эффективность не доказана.', 'Мы будем развивать главную в направлении большей функциональности для других сервисов. Готовим изменения для улучшения пользовательской навигации по функциям приложения, а также для оповещения пользователей обо всех новых и интересных изменениях в Кошельке.', 'С начала марта 2021 мы запустили два варианта главной и начали пристально следить за результатами. Наши ключевые метрики выросли:', 'Больше пользователей стали заходить в предложения наших партнеров, выпуск новых карт вырос на 7,75%.', 'Блок рекомендаций привлекает внимание пользователей — 43% новых пользователей\\xa0взаимодействовали с ним в первый день.', 'Блок «Часто использую» оказался востребованным, почти половина всех открытых карт приходится на него. При этом пользователи продолжают им пользоваться после первого открытия, его ретеншн составляет более 50%.', 'Медианное время на открытие карты уменьшилось с 3 до 2 секунд.', 'Всего 0,7% пользователей вернулись на старый вариант интерфейса, при этом половина из них позже переключилась обратно.', 'Метрики здоровья, такие как MAU, использование ключевых сценариев и ретеншн не просели.', 'Пользователи «вживую» хорошо отнеслись к новой главной или вообще не заметили изменений. Как мы это узнали? Провели обширный опрос пользователей на фестивале Stereoleto 2021 в своей промо-зоне.\\xa0', 'Это был длинный путь. И нашей главной еще далеко до финальной формы. Нам предстоит еще сильнее её масштабировать и мы только готовимся к раскатке новой версии дизайна на Android. Но мы уже многое поняли\\xa0 и могли бы посоветовать всем, кому предстоит работа над изменением главного экрана. Например:\\xa0', 'Сначала нужно четко определить цель изменений и их необходимость, проанализировать имеющиеся решения и актуальность их для продукта.', 'Работать нужно только в рамках гипотез. Без них работа будет размазанная, безыдейная и, как следствие, бесконечная. При формулировке гипотез, руководствуйтесь принципом - не больше 3 за раз. Чем больше одновременных гипотез тестируется, тем больше результаты одной гипотезы могут повлиять на другую.', 'Сделать «красиво»\\xa0 — не проблема. А вот не сломать привычный сценарий использования — почти искусство.\\xa0', 'Во время эксперимента лучше предусмотреть возможность возвращения на старый дизайн. Если экспериментальные гипотезы не подтверждаются, у ваших пользователей будет путь назад, в комфортный для них дизайн.\\xa0', 'Не надо пытаться сделать сразу очень сложно. Проще и дешевле выбрать менее трудозатратный вариант, способный подтвердить или опровергнуть выдвинутые гипотезы. Убедившись в успешности того или иного подхода, можно итеративно дорабатывать успешную функциональность.', 'Пользователи могут быть (очень) недовольны. Не все пользователи открыты к крупным изменениям, поэтому невозможно создать уникальное решение, которое угодило бы всем и сразу. Точно найдутся люди, недовольные нововведениями. Необходимо сразу себя подготовить к этому и искать в критике возможные пути для улучшений. Ну и не унывать.', 'Друзья, расскажите нам про свой опыт изменения ключевых экранов ваших приложений. Какие советы вы бы дали тем, кто планирует масштабные изменения в проекте?', '', 'iOS Developer']}\n"
          ]
        }
      ],
      "source": [
        "print(p[57])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqrB8KEI6c_j",
        "outputId": "b22f9a15-dedd-402d-91a7-297927de3493"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200\n"
          ]
        }
      ],
      "source": [
        "print(len(p))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujiCh8eq9o7P",
        "outputId": "eae00bda-4a54-4bd9-d60f-0fd4e5c737f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/root/.jupyter\n"
          ]
        }
      ],
      "source": [
        "%cd ~/.jupyter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J225uP8K9rvr",
        "outputId": "cf7e8c72-6cb5-45af-a114-cb344ce7a37e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "jupyter_notebook_config.py  migrated\n"
          ]
        }
      ],
      "source": [
        "! ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPkRIau09zi_"
      },
      "outputs": [],
      "source": [
        "!cat jupyter_notebook_config.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4JXcdL9-jvO",
        "outputId": "fcc80b94-5e25-49ed-b40b-d03c10015ee5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: gedit: command not found\n"
          ]
        }
      ],
      "source": [
        "!gedit jupyter_notebook_config.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFsb_mx7xpK8"
      },
      "outputs": [],
      "source": [
        "def check_eng(dictt):\n",
        "    #sleep(3)\n",
        "    texts_with_eng = []\n",
        "    try:\n",
        "        for elem in p:\n",
        "            for key, value in elem.items():\n",
        "                if key == 'text':\n",
        "                    new_v = ' '.join(value)\n",
        "                    words = new_v.split()\n",
        "                    if len(words) < 20:\n",
        "                        continue\n",
        "                    count = 0\n",
        "                    for elem2 in words:\n",
        "                        if re.search(r'[a-zA-Z]', elem2):\n",
        "                            count +=1\n",
        "                    if count*100/len(words) > 15 and count*100/len(words) <90:\n",
        "                        texts_with_eng.append(' '.join(words))\n",
        "        return texts_with_eng\n",
        "    except TypeError:\n",
        "        print(Exception)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_3g-A7nOcBU"
      },
      "outputs": [],
      "source": [
        "with open('out.txt', 'w') as f:\n",
        "    for elem in p:\n",
        "        for key,value in elem.items():\n",
        "            if key == 'text':\n",
        "                #print(value)\n",
        "                f.write(' '.join(value))\n",
        "                f.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sc4Fp_Pz4KH_"
      },
      "outputs": [],
      "source": [
        "new_p = check_eng(p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yn97q9a871CN",
        "outputId": "db9e48f1-8fdc-409d-c862-e4631f4c666d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Если в 2018 году люди тратили на просмотр видео 1,5 часа в день, то в 2022 году вовлечённость выросла до 2,5 часов. Пользователи делятся видео в два раза чаще, чем любым другим контентом, а motion-графика почти так же популярна, как простые записи. Сделали для вас подборку обучающих ресурсов, программ и инструментов для самостоятельного обучения. В декабре 2021 года английская анимационная студия Wyzowl провела исследование, согласно которому motion-графика занимает второе место по популярности среди всех разновидностей видеоконтента (33%), уступая лишь 9% формату обычной видеозаписи (42%). Видео помогает компаниям привлекать новых клиентов, увеличивать объёмы продаж, повышать узнаваемость бренда, сокращать количество обращений в службу поддержки. Это подтверждают и сами потребители: 88% говорят, что именно просмотр видео убедил их совершить покупку, 72% предпочитают узнавать о новых продуктах и услугах из видеороликов. Рассказываем, как сделать motion-дизайн профессией. Требования работодателей к motion-дизайнерам в 2022 году меняются в зависимости от уровня компании. Мы приведём в качестве примера две вакансии, которые были актуальны на начало мая 2022 года. Это топовые предложения для специалистов высокого класса, на которые следует ориентироваться. В конце марта Apple опубликовала вакансию: от кандидата ждут, что он сможет создавать анимацию, заниматься графическим дизайном и делать видеоролики для рекламных и образовательных проектов компании. Разработка креативной концепции также ложится на специалиста. Кандидат должен работать в After Effects, Illustrator, Photoshop, Premiere Pro, Cinema 4D, Maya и Final Cut Pro. Рассматривают бакалавров в области графического дизайна, медиаискусства или другой смежной специальности. Требования к опыту: 4–10 лет работы по специальности. Про доход ничего не пишут, но на сторонних ресурсах говорят, что средняя зарплата motion-дизайнера в Apple составляет около 80 тысяч долларов в год. Социальная сеть VK опубликовала вакансию motion-дизайнера в команду игрового бренда MY.GAMES. Как и Apple, VK ищет универсального специалиста, который будет не только рисовать и монтировать, но и создавать концепцию роликов и сценарии. Кандидат также должен самостоятельно выставлять свет, строить кадр, записывать качественный звук и подбирать аудиоконтент. Поскольку вакансия в геймдеве, нужно немного работать на базе движка Unity. Требуется портфолио, а про образование не сказано ничего. Набор программ, в которых надо уметь работать, классический: Adobe Premiere, Adobe Photoshop, Adobe After Effects, Photoshop. Про деньги скажут на собеседовании. На hh.ru в вакансиях со схожими функциями указывают зарплаты от 150 до 200 тысяч рублей в месяц. При этом специалисты уровня джун, работающие по чёткому техническому заданию со знанием основных инструментов, могут рассчитывать на 70 тысяч в месяц. Анимация включает в себя множество этапов от рисования эскиза до создания трёхмерных моделей и объединения их в сложную динамическую сцену. Выбор инструментов зависит от специфики работы. Иногда для выполнения задачи достаточно одной программы, а порой приходится задействовать целый набор инструментов. Перечислим основные: Adobe After Effects. Позволяет создавать анимированную графику и визуальные эффекты, а также редактировать видеоряд, в том числе видео 4K и 360/VR. Хорошо работает с другими системами нелинейного монтажа, такими как Avid Media Composer и Final Cut Pro X. Гибко интегрируется с 3D-приложениями: 3ds Max, Maya и Cinema 4D. Доступен в экосистеме Creative Cloud. На сайте Adobe выложены обучающие видео. У Нетологии есть бесплатный курс для освоения базы, начать обучение мжно в любое время. Cinema 4D. Программное решение для 3D-моделирования, анимации, симуляции и рендеринга. Художники-аниматоры любят Cinema 4D за удобство, простоту использования и гибкость при интеграции с After Effects. У Cinema 4D сильное сообщество пользователей, поэтому легко найти обучающие ресурсы. Начать можно с видео на популярном канале Greyscalegorilla. Adobe Premiere Pro. Приложение для редактирования видео, создаёт динамические связи с After Effects: пользователи могут вносить финальные правки в ролик без предварительного рендеринга. На официальном сайте программы есть коллекция видеоуроков. Adobe Photoshop. Многофункциональный графический редактор. Уроки доступны на любых ресурсах. Основы можно выучить в Нетологии. Adobe Illustrator. Одна из ведущих программ обработки векторной графики и один из главных инструментов любого дизайнера. Начинайте с бесплатного курса Нетологии или официальных материалов. Blender. Бесплатное ПО для 2D и 3D-графики с открытым исходным кодом и каналом на YouTube с руководствами. Популярен в геймдеве. Maya. Конкурент Cinema 4D с более сложным интерфейсом. Его используют многие голливудские студии для 3D-моделирования и анимации. Открыта для сторонних разработчиков. Есть сайт с уроками. Для комфортной работы в этих программах на начало 2022 года нужен компьютер с 32 ГБ оперативки и 4 ГБ GPU. Для большего погружения в профессию приведём ещё несколько ссылок на YouTube-каналы про motion-дизайн: VideoSmile Andrey Sokolov SurfacedStudio School of Motion Arrimus 3D SonduckFilm Blender Guru Eyedesyn Flat Pack FX Чаты: Motion Talk Motion Chat Каналы и сообщества для поиска работы: Motion designer hunter CG Freelance Motion Graphics Jobs Каналы и сообщества для вдохновения и обучения: Motion Graphics & Video Design MOTION GRAPHICS Animation & Visual effects Motion.RAR BDSR DESIGN REFERENCES VimeoInspiration | Motion design | Вольница Официальные ресурсы ПО: Adobe Premiere Pro for beginners Adobe Premiere Pro Intermediate Users Group Adobe After Effects Tutorials After Effects / Motion Design Adobe Illustrator tutorials Blender 3D Artists Blender Artists Community Cinema 4D - Maxon Cinema 4D — канал Cinema 4D — чат Photoshop & Illustrator Photoshop Tutorials Design for Motion: Fundamentals and Techniques of Motion Design, Остин Шоу. Остин Шоу — motion-дизайнер, который более 15 лет делал графику для Ferrari, Fedex, Ralph Lauren, Target. Сейчас — профессор motion-дизайна в Колледже искусств и дизайна Саванны. Преподавал в Школе визуального искусства в Нью-Йорке. В книге — техника иллюстрации, визуальный сторителлинг, работа с 3D-объектами, практические упражнения. Аниматор: набор для выживания. Секреты и методы создания анимации, 3D-графики и компьютерных игр, Уильямс Ричард. Мультипликатор и обладатель премии Оскар за фильм «Кто подставил кролика Роджера» рассказывает о принципах анимации, 3D-графики и компьютерных игр. The Theory and Practice of Motion Design, Брайан Стоун и Лия Уолин. Авторы раскрывают о motion-дизайне через серию познавательных интервью с профессиональными дизайнерами о теории цвета и формы, визуализации, типографике и сторителлинге. Motion-дизайнер компании-разработчика офисного ПО МойОфис На мой взгляд, motion-дизайн сто́ит начать с изучения 12 принципов Disney. Они помогут понять, как оживить статическое изображение, выделить интересные для вас направления, в которых хотелось бы развиваться. После выбора специализации стоит подумать, где можно научиться соответствующим приёмам. Ресурсы, с которыми точно необходимо ознакомиться: Максимально полная документация по After Effects, одной из флагманских программ для motion-дизайнера; Гениальные плагины и уроки по After Effects; Крупнейший ресурс с обучающими курсами, в том числе и Motion Graphics; Ещё уроки и плагины для After Effects. При выборе обучающих ресурсов необходимо отталкиваться от потребностей. Важно уметь ставить цель и искать средства для её достижения. Можно бесконечно проходить различные курсы, но так и не применить знания. Нужно постоянно тренировать насмотренность, изучать лучшие практики и анализировать работы мастеров с именем. Начинающим специалистам я бы посоветовал начать с заказов на фриланс-ресурсах, параллельно продвигая портфолио на таких сайтах, как Artstation или Cgsociety. Продюсер CG-студии Mondlicht Studios Большинство сегодняшних топов индустрии — самоучки. Когда они начинали, контента и готовых курсов просто не было, был плохой интернет и желание научиться. Сегодня выбор куда больше: есть и курсы, и отдельные каналы, и классическое обучение. Важно понимать плюсы и минусы каждого. Например, самостоятельное образование экономит вам деньги, но вы тратите намного больше времени. С готовыми курсами вы экономите время, но расстаётесь с приличной суммой. На мой взгляд, успех в балансе. Идеальный вариант — это курсы для быстрого старта и понимания основ, дополненные максимально возможным количеством туториалов, вебинаров, статей и любого контента, до которого получится добраться. Ещё один важный момент — это сообщество. Оно поможет увидеть, что вы делаете не так, получить обратную связь, найти первые заказы и многое другое. Комьюнити в Computer Generated Imagery — это очень тёплая тусовка, где с пониманием относятся к новичкам. Motion-дизайнер студии Maryco C хорошей самодисциплиной и больши́м желанием можно самостоятельно изучить motion-дизайн. В интернете много бесплатных материалов и уроков. Я рекомендую начинать с пакета Adobe, Cinema 4D, Blender, разобраться в их инструментах. Пробовать анимировать абстрактные композиции, анализировать готовые проекты, смотреть, какими средствами достигается тот или иной эффект в роликах, что в них хорошо, а что плохо и как можно сделать лучше. Ещё советую смотреть туториалы. Мне очень помогали проекты VideoSmile, «Вольница», Greyscalegorilla (у них есть разделы по 3D) и блог AEPlug на Youtube. На Youtube очень много уроков, всегда найдётся англоговорящий индус, который показывает, как сделать что-то невообразимое. Для вдохновения советую смотреть Behance и телеграм-канал Тренд-бюро, здесь рассказывают про разные области дизайна и моды — это помогает понять контекст, с которым вам предстоит работать. Опыт в обычном статичном дизайне тоже необходим. Качество результата будет выше. Хороший дизайн приятен глазу, он строится на гармоничном сочетании шрифтов и цветов, в нём выстроена правильная композиция. Понимая, как это можно сделать, вы визуально улучшите свои работы. Дизайнеры учатся постоянно, особенно в начале карьеры. Чтобы стать востребованным профессионалом, нужно: владеть основными программами; быть насмотренным и хорошо визуализировать; уметь делать раскадровки и объяснять их; чувствовать динамику и ритм ролика; понимать, как удерживать внимание зрителя, как показать большой объём информации так, чтобы она воспринималась легко; иметь развитые гибкие навыки, чтобы общаться с заказчиками; уметь рассчитать время, которое займёт выполнение проекта, и исходя из этого — цену. Редактор Нетологии',\n",
              " 'Специально для тех, кто ищет полноценный отечественный аналог Unity или Unreal Engine, мы продолжаем цикл статей про безболезненный переход на UNIGINE с зарубежных движков. В третьем выпуске рассмотрим миграцию с Unity с точки зрения программиста. Традиционно игровая логика в проекте Unity реализуется через пользовательские компоненты — C# классы, унаследованные от MonoBehaviour. Основная логика компонента определена в событийных методах Start(), Update() и так далее. UNIGINE предлагает очень похожую концепцию — C# Component System — стабильная и высокопроизводительная компонентная система на .NET 5. Компоненты представлены C# классами, унаследованными от Component, их можно назначить любой ноде в сцене. Жизненный цикл каждого компонента определяется набором методов (Init(), Update() и т. д.), вызываемых в основном цикле движка. Программирование в UNIGINE с использованием C# мало чем отличается от программирования в Unity. Например, давайте сравним, как выполняется вращение объекта в Unity: и в UNIGINE: Кнопка для запуска экземпляра приложения в отдельном окне расположена на панели инструментов в UnigineEditor. Также рядом расположены настройки параметров запуска. Вот как мы заставим колесо вращаться с помощью C# Component System и запустим экземпляр, чтобы немедленно его проверить: Более того, системная логика приложения на UNIGINE может быть определена в файлах AppWorldLogic.cs, AppSystemLogic.cs и AppEditorLogic.cs в папке source проекта. Чтобы узнать больше о последовательности выполнения и о том, как создавать компоненты, перейдите по ссылкам ниже: Последовательность выполнения Видеоруководство по C# Component System C# UNIGINE API Для тех, кто предпочитает C++, UNIGINE позволяет создавать приложения C++ с использованием С++ UNIGINE API, и, при необходимости, C++ Component System. Используйте клавишу ~, чтобы открыть консоль в приложении Unity UNIGINE //Исходный код (C#) Debug.Log(\"Text: \" + text); Debug.LogFormat(\"Formatted text: {0}\", text); //Исходный код (C#) Log.Message(\"Debug info:\" + text + \"\\\\n\"); Log.Message(\"Debug info: {0}\\\\n\", new vec3(1, 2, 3)); Дополнительные типы сообщений в API класса Log Видеоруководство, демонстрирующее, как выводить пользовательские сообщения в консоль с помощью C# Component System Unity UNIGINE //Исходный код (C#) GameObject this_go = gameObject; string n = gameObject.name; //Исходный код (C#) Node this_node = node; string n = node.Name; Видеоруководство, демонстрирующее, как получить доступ к нодам из компонентов с помощью C# Component System В Unity компонент Transform отвечает за позицию, вращение и масштаб Game Object, а также за родительско-дочерние связи. Чтобы получить вектор направления по одной из осей с учетом вращения GameObject в мировых координатах, в Unity используется соответствующее свойство компонента Transform. В UNIGINE трансформация ноды в пространстве представлена ее матрицей трансформации (mat4), а все основные свойства и операции с иерархией нод доступны при помощи методов и свойств класса Node. Такой же вектор направления в UNIGINE получается с помощью метода Node.GetWorldDirection(): Unity UNIGINE //Исходный код (C#) Vector3 forward = transform.forward; Vector3 right = transform.right; Vector3 up = transform.up; transform.Translate(forward * speed * Time.deltaTime); //Исходный код (C#) vec3 forward = node.GetWorldDirection(MathLib.AXIS.Y); vec3 right = node.GetWorldDirection(MathLib.AXIS.X); vec3 up = node.GetWorldDirection(MathLib.AXIS.Z); node.Translate(forward * speed * Game.IFps); Система координат в UNIGINE В Unity, чтобы гарантировать, что определенные действия выполняются за одно и то же время независимо от частоты кадров (например, изменение положения один раз в секунду и т. д.), используется множитель Time.deltaTime (время в секундах, которое потребовалось для завершения последнего кадра). То же самое в UNIGINE называется Game.IFps: Unity UNIGINE //Исходный код (C#) transform.Rotate(0, speed * Time.deltaTime, 0, Space.Self); //Исходный код (C#) node.Rotate(0, 0, speed * Game.IFps); Unity: В UNIGINE за вспомогательную отрисовку отвечает синглтон Visualizer: Примечание. Visualizer также можно включить с помощью консольной команды show_visualizer 1. Все типы визуализаций в API класса Visualizer. Unity UNIGINE //Исходный код (C#) SceneManager.LoadScene(\"YourSceneName\",LoadSceneMode.Single); //Исходный код (C#) World.LoadWorld(\"YourSceneName\"); Unity: UNIGINE: Компонентный подход Unity позволяет рассматривать такие стандартные объекты, как MeshRenderer, Rigidbody, Collider, Transform и другие, как обычные компоненты. В UNIGINE доступ к аналогам этих сущностей осуществляется иначе. Классы всех типов нод являются производными от Node, поэтому чтобы получить доступ к функциональности ноды определенного типа (например, ObjectMeshStatic), необходимо провести понижающее приведение типа (downcasting). Рассмотрим эти самые популярные варианты использования: Unity: UNIGINE: Unity: UNIGINE: Downcasting (приведение от базового типа к производному) выполняется одинаково в обоих движках с использованием родной конструкции C# as: Unity UNIGINE //Исходный код (C#) Collider collider = gameObject.GetComponent<Collider>; BoxCollider boxCollider = collider as BoxCollider; //Исходный код (C#) Node node = World.GetNodeByName(\"my_mesh\"); ObjectMeshStatic mesh = node as ObjectMeshStatic; Чтобы выполнить Upcasting (приведение от производного типа к базовому), можно как обычно просто использовать сам экземпляр: Unity UNIGINE //Исходный код (C#) Collider collider = gameObject.GetComponent<Collider>; BoxCollider boxCollider = collider as BoxCollider; Collider coll = boxCollider; //Исходный код (C#) Node node = World.GetNodeByName(\"my_mesh\"); ObjectMeshStatic mesh = node as ObjectMeshStatic; Unigine.Object obj = mesh; Unity UNIGINE //Исходный код (C#) Destroy(myGameObject); // уничтожить объект с задержкой в 1 секунду Destroy(myGameObject, 1); //Исходный код (C#) node.DeleteLater(); // рекомендуемый вариант // нода уничтожается после текущего кадра node.DeleteForce(); // форсировать уничтожение ноды в данный момент, что не всегда безопасно Для выполнения отложенного удаления ноды в UNIGINE можно создать компонент, который будет отвечать за таймер и удаление. В Unity экземпляр префаба или копия уже существующего в сцене GameObject создается с помощью функции Object.Instantiate: Затем вы должны указать префаб, который будет создан, в параметрах компонента скрипта. В UNIGINE получить доступ к уже существующей ноде любого типа можно также через параметр компонента, и клонировать ее при помощи Node.Clone(). Но ассеты не являются нодами, они принадлежат файловой системе. К ассету можно обратиться, используя эти типы параметров: AssetLink — для любых ассетов, AssetLinkNode — для ассетов *.node, содержащих иерархию нод, сохраненную как Node Reference (аналог prefab). В этом случае ссылка на ассет, аналогично Unity, указывается в UnigineEditor: Также можно использовать функцию World.LoadNode для загрузки иерархии нод вручную, указав виртуальный путь к ассету. Еще один способ загрузить содержимое ассета *.node — создать NodeReference и работать с иерархией нод как с одним объектом. Тип Node Reference имеет ряд внутренних оптимизаций и тонких моментов (кэширование нод, распаковка иерархии и т.д.), поэтому важно учитывать специфику работы с этими объектами. Unity позволяет расширять функциональность редактора с помощью C# скриптов. Для этого в скриптах поддерживаются специальные атрибуты: [ExecuteInEditMode] — для выполнения логики скрипта в режиме Edit, когда приложение не запущено. [ExecuteAlways] — для выполнения логики скрипта как в режиме Play, так и при редактировании. Например, так выглядит код компонента, который заставляет GameObject ориентироваться на определенную точку в сцене: UNIGINE не поддерживает выполнение логики C# внутри редактора. Основной способ расширить функциональность редактора — плагины, написанные на C++. Для быстрого тестирования или автоматизации разработки можно написать логику на UnigineScript. UnigineScript API обладает только базовой функциональностью и ограниченной сферой применения, но доступен для любого проекта на UNIGINE, включая проекты на .NET 5. Есть два способа добавить скриптовую логику в проект: Создав скрипт мира: Создайте ассет скрипта .usc. Определите в нем логику. При необходимости добавьте проверку, загружен ли редактор: Выделите текущий мир и укажите для него сценарий мира. Нажмите Apply и перезагрузите мир. Проверьте окно консоли на наличие ошибок. После этого логика скрипта будет выполняться как в редакторе, так и в приложении. Используя WorldExpression. С той же целью можно использовать ноду WorldExpression, выполняющую логику при добавлении в мир: Нажмите Create -> Logic -> Expression и поместите новую ноду WorldExpression в мир. Напишите логику на UnigineScript в поле Source: Проверьте окно Console на наличие ошибок. Логика будет выполнена немедленно. Помимо обнаружения столкновений, компонент Collider в Unity может быть использован как триггер, который срабатывает, когда другой коллайдер попадает в его объем. В UNIGINE Trigger — это специальный тип нод, вызывающих события в определенных ситуациях: NodeTrigger вызывает коллбэк при изменении состояния включен/выключен и позиции самой ноды. WorldTrigger вызывает коллбэк, когда какая-либо нода (независимо от типа) попадает внутрь или за его пределы. PhysicalTrigger вызывает коллбэк, когда физические объекты попадают внутрь или наружу его пределов. Важно! PhysicalTrigger не обрабатывает столкновения, для этого физические тела и сочленения предоставляют свои собственные события. WorldTrigger — наиболее распространенный тип триггера, который можно использовать в игровой логике: Обычный игровой ввод Unity: UNIGINE: Также можно использовать синглтон ControlsApp для обработки привязок элементов управления к состояниям. Чтобы настроить привязки, откройте настройки Controls: Для обнаружения пересечений лучей с объектами в Unity используется Physics.Raycast. GameObject должен иметь прикрепленный компонент Collider для участия в рейкастинге: В UNIGINE то же самое делается с помощью Intersections: Напоминаем, что получить доступ к бесплатной версии UNIGINE 2 Community можно заполнив форму на нашем сайте. Все комплектации UNIGINE: Community — базовая версия для любителей и независимых разработчиков. Достаточна для разработки видеоигр большинства популярных жанров (включая VR). Engineering — расширенная, специализированная версия. Включает множество заготовок для инженерных задач. Sim — максимальная версия платформы под масштабные проекты (размеров планеты и даже больше) с готовыми механизмами симуляции. Подробнее о комплектациях и ценах Пользователь',\n",
              " 'Рассказываю, какими шрифтами можно заменить заблокированные Times New Roman, Arial и Helvetica и где скачать аналоги. В апреле компания Monotype закрыла доступ к своему каталогу шрифтов для российских пользователей. Arial, Times New Roman и Helvetica всё ещё доступны для использования, однако, что будет дальше, предсказать сложно: в худшем случае компания Monotype может заблокировать шрифты во всех сервисах и программах на территории России. Если в документах или фирменном стиле вашей компании используется Arial или Times New Roman — о их замене лучше задуматься уже сейчас. Делюсь подборкой бесплатных аналогов популярных шрифтов Monotype. Calibri Candara Commisioner Constantia Franklin Gothic Georgia IBM Plex Inter Lucida Sans Manrope Mulish Noto Sans Nunito Outfit Poppins Raleway Roboto Rubik Segoe UI Ubuntu Golos Text Literata PT Astra Вместо вывода делимся тремя универсальными правилами типографики, которые будут полезны и недизайнерам: Правило 1. Делайте заголовки в два раза больше основного текста. Так читателю будет проще понять, что в вашей информации важное, а что второстепенное. Правило 2. Если хотите сделать текст контрастным — пропустите одно начертание. Лучше сочетать тонкое начертание с полужирным, а регулярное — с жирным. Правило 3. Чем важнее текст, тем стандартнее шрифт. Не усложняйте витиеватыми шрифтами то, что несёт ключевой смысл текста. Предприниматель',\n",
              " 'Статья ранее публиковалась в нашем блоге на DTF. Если вы планируете переходить с иностранного софта на отечественный и ищете полноценный аналог Unity или Unreal Engine, то одним из вариантов может стать продукция нашей компании, полностью готовая к импортозамещению. UNIGINE использует общепринятые интерфейсы и рабочие процессы, которые могут быть вам знакомы по работе с другими 3D-инструментами. По опыту наших клиентов, для перехода на UNIGINE с других платформ уходит не более 1–2 недель. Одна из таких платформ — платформа разработки в реальном времени Unity. Далее в статье рассмотрим базовую информацию по переходу на UNIGINE. Сначала разберемся с названиями различных сущностей и другими терминами. В таблице ниже приведены термины Unity и их точные или приблизительные эквиваленты в UNIGINE. Категория Unity UNIGINE Управление проектами и SDK Hub SDK Browser Интерфейс редактора Hierarchy Panel Окно World Nodes Inspector Окно Parameters Project Browser Окно Asset Browser Scene View Editor Viewport Сцена Scene World Типы геймплея Component Component System GameObject Node Prefab NodeReference Меши Mesh Renderer Static Mesh Dynamic Mesh Skinned Mesh Renderer Skinned Mesh Blendshapes Morph Targets Эффекты Particle System Particle System Halo Volumetric Objects Lens Flares Lens Flares Billboard Renderer Billboards Projector / Decal Projector (HDRP) Decals Экстерьеры Terrain Terrain Systems Trees / Grass Mesh Clutter Grass аддон Vegetation Wind Zones Animation Field Игровой интерфейс UI (User Interface) GUI (Graphics User Interface) Освещение Light Sources Light Sources Environment Environment Lightmapping LightmappingVoxel GI Reflection Probes Environment Probes Рендеринг Shade Base Material Material User Material Кастомные шейдеры: HLSL Shader Graph HLSL GLSL UUSL (Unified UNIGINE Shader Language) Визуальный редактор материалов Compute Shaders UUSL Compute Shaders Rendering Paths Rendering Sequence Multi-Display Rendering Плагины для рендеринга на нескольких экранах (Multi-Monitor Rendering) Плагин Syncker для многоканальной визуализации Программирование C# C++ C# UnigineScript Scriptable Render Pipeline URP HDRP Rendering Sequence (при полном доступе из API) Scriptable Materials Физика Raycast Intersections Rigid Body Rigid Body Collider Shape Joint Joint Cloth Cloth Body Анимация Timeline Tracker Навигация и нахождение пути NavMesh NavMeshAgent Off-Mesh Link NavMesh Obstacle Navigation Areas Obstacles Пользователи Unity используют Unity Hub — приложение для поиска, загрузки и управления версиями движка и проектами. В UNIGINE для этих целей служит UNIGINE SDK Browser. Помимо управления проектами и установленными SDK, браузер SDK предоставляет доступ к примерам (Samples), базе знаний (Knowledge) и дополнениям (Add-Ons). В последнюю категорию входят различные 3D-модели и материалы, в том числе растительность, спецэффекты, погодные эффекты и другое. Также заметным отличием UNIGINE является возможность создания нового (или редактирование старого) проекта с поддержкой одного из нескольких языков программирования: C++, C# и UnigineScript. Для пользователей Unity рекомендуется использовать C# Component System. Также возможно использование нескольких языков программирования в одном проекте. Например, для выполнения ресурсоемких задач часто используют C++. Нажмите Create New в разделе My Projects. Выберите тип проекта C# (.NET 5) в поле API + IDE. Если требуется поддержка VR-гарнитур, перейдите в раздел Plugins, отметьте необходимые плагины в секции Stereo 3D и нажмите Ok (больше о поддержке VR-устройств здесь). Нажмите Create New Project. После завершения загрузки нажмите Open Editor, чтобы запустить UNIGINE Editor. Элементы интерфейсов Unity Editor и UNIGINE Editor близки по функционалу: на схеме ниже они окрашены в похожие цвета. Расположение элементов UNIGINE Editor можно настраивать, перетаскивая и изменяя их размер. В UNIGINE по умолчанию используется темная тема. Toolbar. Панель инструментов, которая обеспечивает доступ к инструментам позиционирования, а также элементам управления логикой приложения, воспроизведением звука, симуляцией физики, компиляцией шейдеров и запеканием света. World Hierarchy Window. Инструмент для работы с иерархией нод. Позволяет организовывать ноды в иерархию, а также добавлять, удалять, клонировать и переименовывать их. Editor Viewport. Просмотр трехмерной сцены. Позволяет визуально перемещаться и редактировать виртуальный мир. Parameters Window. Окно параметров выбранного элемента виртуального мира. Позволяет просматривать и изменять параметры нод, материалов, свойств и ассетов. Asset Browser Window. Инструмент для организации контента в проекте: создания, импорта, просмотра, переименования ассетов, а также перемещения и управления их иерархией. Инструменты для просмотра виртуальной сцены Unity Scene View и UNIGINE Editor Viewport очень похожи между собой — это непосредственно само окно просмотра и панель инструментов. Вы можете использовать столько окон Editor Viewport, сколько вам необходимо. Есть русские субтитры Camera Panel служит для переключения между камерами и настройки текущей камеры. Rendering Debug Panel требуется для отображения содержимого буферов рендеринга так же, как при использовании Draw Mode в редакторе Unity. Navigation Panel используется для быстрой настройки и переключения между пресетами скорости камеры, а также для изменения положения камеры. Панель Helpers обеспечивает быстрый доступ к вспомогательным визуализаторам, таким как значки, гизмо и каркасы. Навигация внутри Editor Viewport почти такая же, как и в Scene View Unity. Подробнее ознакомиться с навигацией по сцене можно, просмотрев видео ниже (либо прочитав соответствующий раздел в документации): Есть русские субтитры Переключатель Precompile All Shaders (предварительная компиляция всех шейдеров) используется для принудительной компиляции шейдеров; Переключатель Animation (анимации); Переключатель Physics (физики); Переключатель Audio (звука); Кнопка Play для управления воспроизведением. В режиме воспроизведения Game View редактора Unity рендерит финальную сцену с одной или нескольких камер. В UNIGINE кнопка Play используется для запуска экземпляра приложения в отдельном окне. Также есть возможность переключения между режимами воспроизведения для изменения его основных параметров. Так, например, можно включить режим VR, чтобы обеспечить совместимость с одной из поддерживаемых гарнитур виртуальной реальности. Engine Viewport в UNIGINE (аналог Game View), используемый для отладки и оценки производительности, считается избыточным для проектов, разрабатываемых на C# .NET 5. Однако, его можно использовать в других проектах. Как в Unity, так и в UNIGINE есть консоль для стандартного ввода, вывода и регистрации ошибок. Также существует набор консольных команд, позволяющих совершать определенные операции. Консоль доступна как в UNIGINE Editor, так и в работающем приложении. Чтобы открыть окно консоли в редакторе, перейдите в меню Windows -> Console: Во время работы приложения встроенная консоль запускается нажатием кнопки «Тильда» (~). Во встроенную консоль можно выводить сообщения из кода. Так же как и Unity Editor, UNIGINE Editor позволяет выполнить подготовку финальной сборки проекта. Проект в UNIGINE, как и проект на Unity, хранится в отдельной папке, настройки проекта хранятся в файле с расширением *.project. В папке проекта есть различные подпапки с контентом и исходным кодом приложения. Также тут хранятся папки с файлами конфигурации и исполняемыми файлами. Наиболее важные подпапки: data (данных) и source (исходного кода). Каждый проект UNIGINE обязательно включает в себя папку data. Как и в папке Assets проекта на Unity, здесь хранятся ресурсы вашего проекта. Для импорта ассетов достаточно перетащить файлы в папку data — они автоматически импортируются и станут доступны в Asset Browser. Ассеты в UNIGINE Editor будут автоматически обновляться при внесении изменений в соответствующие файлы. Соответствие содержимого папки data в корневой директории проекта и в Asset Browser Unity поддерживает широкий спектр форматов файлов, в то время как UNIGINE поддерживает большинство наиболее популярных, а также ряд специфических: Тип ассетов Поддерживаемые форматы Геометрия .fbx, .obj, .3ds, .dae, .glb/.gltf, .stp/.step, .igs/.iges, .brep, .stl Текстуры .png, .jpeg, .tif, .tga, .rgba, .psd, .hdr, .dds, and more Звук и видео .wav, .mp3, .oga/.ogg, .ogv Шрифты .ttf Меши. Ассеты в формате FBX могут быть легко импортированы из Unity в UNIGINE без искажения масштаба. Подробнее про импорт FBX-моделей читайте здесь. Материалы. Так же как и Unity, UNIGINE работает с PBR-материалами (Physically Based Materials) и поддерживает Metalness и Specular workflow. Материалы, созданные в Unity, можно воссоздать в UNIGINE, благодаря встроенной богатой библиотеке материалов, а также возможности визуально создавать и редактировать материалы в Visual Material Editor. Текстуры. Текстуры можно импортировать либо как часть модели, либо отдельно, а затем назначать их мешу. Но иногда может потребоваться предварительная подготовка. Например, Shading-текстура в UNIGINE хранит карты Metalness, Roughness, Specular и Microfiber в соответствующих каналах. Поэтому сначала нужно изменить Shading-текстуру с помощью GIMP или Photoshop, а затем импортировать ее в UNIGINE. А перед импортом Normal-текстуры нужно инвертировать канал G с помощью соответствующей настройки при импорте. Анимации. Модель со скелетной анимацией, которую вы использовали в проекте Unity, может быть импортирована в UNIGINE, если она хранится в формате FBX. При импорте такой модели, включите опцию Import Animations (импорт анимаций) и настройте дополнительные параметры. Подробнее про импорт разных ассетов читайте здесь. Концепция сцены в обоих движках одинакова. Однако Unity и UNIGINE используют разные системы координат. Unity UNIGINE Unity использует левостороннюю систему координат, в которой вертикальное направление представлено осью +Y. 1 юнит равен 1 метру. Оси и направления:X — вправо (+), влево (-)Y — вверх (+), вниз (-)Z — вперед (+), назад (-)Положительный угол поворота задает вращение по часовой стрелке.Формат файла: *.scene UNIGINE использует правостороннюю систему координат, в которой вертикальное направление представлено осью +Z. 1 юнит равен 1 метру. Оси и направления: X — вправо (+), влево (-) Y — вперед (+), назад (-) Z — вверх (+), вниз (-) Положительный угол поворота задает вращение против часовой стрелки. Формат файла: *.world Как в Unity, так и в UNIGINE, сцена формируется из базовых объектов. С их кратким описанием, а также основными сходствами и различиями можно ознакомиться ниже. Unity UNIGINE Окно Hierarchy Окно World Nodes Базовый объект сцены — GameObject. Базовый тип, от которого наследуются все типы объектов сцены — Node. Некоторые имеют визуальное представление: Objects, Decals и Effects. У каждого из них есть поверхности для представления своей геометрии (меши). Остальные — Light Sources, Players и др. — невидимы. GameObjects являются контейнерами для всех остальных компонентов. Компоненты определяют функционал GameObject. Базовая функциональность ноды определяется ее типом. Дополнительные функции можно добавлять с помощью свойств и компонентной системы. По умолчанию каждый GameObject имеет компонент Transform. У каждой ноды есть матрица преобразования, которая задает ее положение, поворот и масштаб в пространстве. GameObjects могут быть организованы в иерархию типа родитель-потомок. Ноды могут быть организованы в иерархию типа родитель-потомок. Важно. Все объекты, добавляемые в сцену, независимо от их типа, называются нодами. Процесс создания сцены в Unity основан на префабах. Обычно вы собираете сложный объект из GameObjects с определенными компонентами и свойствами и создаете префаб из такого объекта. Затем префабы могут быть размещены в сцене посредством редактора или созданы во время выполнения приложения. Создание сцены в UNIGINE основано на Node Reference, которые очень похожи на префабы. Чтобы создать сложный объект, экземпляры которого затем будут многократно использоваться в сцене, достаточно построить нужную иерархию из нод, назначить им материалы и свойства, а затем сохранить ее как Node Reference. Так же, как и в случае с префабами, вы в любой момент сможете изменить Node Reference, просто изменив любой из ее экземпляров. Подробнее про создание Node Reference и управление смотрите видео ниже (или читайте в документации): Есть русские субтитры В Unity Editor для разрешения конфликтов, возникающих при слиянии рабочих копий проекта, используется инструмент Smart Merge. Также редактор позволяет применять пользовательские инструменты для тех же целей. Для успешного объединения, сцены и другие файлы должны быть в формате YAML. В UNIGINE все исходные форматы файлов по умолчанию являются текстовыми, поэтому вы можете использовать любую привычную систему контроля версий и объединять миры, ноды и другие ассеты. Файловую систему можно расширять с помощью Mount Points, которые позволяют добавлять в проект любые внешние ресурсы, находящиеся в совместном доступе. Кроме того, стандартный подход к работе над проектом заключается в разделении работы разных членов команды с помощью отдельных Node Layers. Это позволяет избежать необходимости разрешения конфликтов при слиянии изменений. Подробнее про совместную работу над проектом читайте здесь. Камеры в Unity и UNIGINE устроены немного по-разному. В Unity компонент Camera отвечает за захват изображения и отправку его на отрисовку. Все включенные камеры, присутствующие в сцене, визуализируются в окне просмотра (Game View) и могут перекрывать друг друга. Для переключения между камерами обычно нужно отключить текущую камеру и включить другую. В UNIGINE камера — это объект, связанный с рендерингом и представленный нодами Player в мире. Для упрощения создания наиболее часто используемых камер, управляемых с помощью устройств ввода (клавиатура, мышь, джойстик), предусмотрено несколько типов Node Player с различным поведением: Dummy — простая статическая камера, которая может быть усовершенствована с помощью пользовательских доработок. Spectator — камера свободного перемещения. Persecutor — камера, которая следует за целевым объектом и может свободно вращаться вокруг него на заданном расстоянии. Это готовое решение для создания камеры от третьего лица. Actor — камера с твердым физическим телом капсульной формы, которая может взаимодействовать с окружением. Это готовое решение для создания вида от первого лица, схожее с Unity Character Controller. Одновременно Editor Viewport показывает вид только с одной камеры. Переключаться между камерами можно с помощью Camera Panel: Чтобы в режиме воспроизведения (когда нажата кнопка Play) определенная камера использовалась по умолчанию, нужно установить флажок Main Player в ее настройках. Настройка общих параметров проекта в Unity Editor обычно выполняется через окно настроек проекта (меню: Edit -> Project Settings). Аудио, графика, физика, уровни качества и другие настройки влияют на весь проект. В UNIGINE общие настройки доступны вменю Windows -> Settings в разделе Runtime. Настройки мира задаются для каждого мира отдельно. В Unity Editor асинхронная компиляция шейдеров включается и выключается в настройках редактора (меню: Edit -> Project Settings -> Editor -> Shader Compilation). В UNIGINE аналогичная функция редактора называется Forced Shader Compilation. Она доступна как через панель инструментов, так и через раздел Editor окна Settings. Вы используете пресеты в редакторе Unity, когда вам нужно повторно использовать настройки свойств, относящиеся к различным задачам, будь то настройки компонентов, настройки импорта или, в особенности, настройки проекта (Project Settings). Вы можете сохранить настройки для определенного раздела Project Settings в качестве *.preset ассета и использовать его в процессе разработки. UNIGINE позволяет сохранять и загружать пресеты для общих настроек физики, звука и рендеринга. Пресеты хранятся в виде ассетов с расширениями *.physics, *.sound и *.render соответственно. Для загрузки и сохранения пресетов используются кнопки Load и Save в соответствующем разделе настроек окна Settings. Сохраненные ассеты отображаются в Asset Browser. Вы можете загрузить настройки рендеринга, дважды щелкнув необходимый ассет с расширением .render. В UNIGINE пресеты доступны не только в редакторе. Вы можете использовать классы Physics, Sound и Render для управления пресетами соответствующих настроек — например, для переключения между уровнями качества во время выполнения приложения. В Unity Editor настройки качества графики в основном собраны в следующих разделах: Раздел Graphics содержит глобальные настройки графики. Настройки уровня (Tier Settings) обеспечивают платформенно-ориентированную настройку рендеринга и компиляции шейдеров. Уровень определяется автоматически в зависимости от используемой платформы. Раздел Quality обрабатывает уровни графического качества, заданные для каждой платформы. В UNIGINE настройки рендеринга мира можно найти в разделе Rendering окна Settings. Также есть возможность включать и выключать самые распространенные функции рендеринга с помощью соответствующего меню: В UNIGINE нет платформенно-зависимых настроек качества, поэтому для управления уровнями качества необходимо написать свою собственную логику. Для этой цели можно использовать пресеты рендеринга (Render Presets). Рассмотрим наиболее часто используемые настройки рендеринга в Unity и соответствующие им аналоги в UNIGINE: Unity UNIGINE HDR Mode Render -> Buffers -> Color 16F Rendering Path см. ниже Shaders Preloading Render -> Streaming -> Preload at World Loading Pixel Light Count Forward Per-Object Limits Texture Quality Render -> Textures -> Quality Anisotropic Textures Render -> Textures -> Anisotropy Anti Aliasing Render -> Antialiasing -> Supersampling Soft Particles particles_base -> Soft Interaction Realtime Reflection Probes Меню: Rendering -> Dynamic Reflections -> Enabled Texture Streaming Render -> настройки Streaming Shadows Render -> настройки Shadows Shadow Cascades устанавливается для каждого источника World Light VSync Count Runtime -> настройки Video В Unity существует два способа рендеринга: Deferred (отложенный) и Forward (прямой) рендеринг. Они определяют точность шейдинга, а также потребление ресурсов при рендеринге и необходимое аппаратное обеспечение. Способ рендеринга можно выбрать в окне Graphics для каждой камеры. UNIGINE имеет фиксированную последовательность рендеринга, представленную комбинацией полного отложенного рендеринга с методами упреждающего рендеринга: Вся непрозрачная геометрия отрисовывается в отложенном проходе (Deferred). Прозрачная геометрия отрисовывается во время прямого прохода (Forward). Вы можете уменьшить вычислительную нагрузку, пропустив определенные этапы рендеринга. Посмотрите специальный видеоурок по использованию инструмента Microprofile для оптимизации рендеринга: В Unity доступность эффектов постобработки определяется используемым конвейером рендеринга. В UNIGINE подобные эффекты не являются частью постобработки, а интегрированы в процесс рендеринга. Таким образом, Unity High Definition Render Pipeline (HDRP) наиболее приближен к процессу рендеринга в UNIGINE по сравнению с другими конвейерами рендеринга. В Unity для определения объемов, в которых параметры и эффекты постобработки локально (или глобально) переопределяются, используется фреймворк Volume. В UNIGINE для плавной перехода между эффектами в различных областях необходимо написать собственную логику. Unity UNIGINE Методы сглаживания: FXAA TAA SMAA MSAA Методы сглаживания: Fast approXimate Anti-Aliasing (FXAA) Temporal Anti-Aliasing (TAA) Subpixel Reconstruction Anti-Aliasing (SRAA) Supersampling Ambient Occlusion Screen-Space Ambient Occlusion Auto Exposure Эффекты камеры: Adaptive Exposure White Balance Tone Mapping Bloom Lens Dirt White Balance Tonemapping Bloom Цветокоррекция: Tone Lookup Texture Color Correction Color Correction LUT Chromatic Aberration Материалы постобработки: post_color_correction Grain Deferred Fog Haze Depth of Field Depth of Field Motion Blur Motion Blur Screen Space Reflection SSR (Screen Space Reflections) Contact Shadows Screen Space Shadows Micro Shadows Cavity of SSAO (Screen Space Ambient Occlusion) Материал получился объемный, но это лишь первый, обобщенный выпуск из запланированных трех по миграции с Unity. Следующий выпуск будет более специализированным и расскажет про миграцию на UNIGINE с точки зрения 3D-художника. А в последнем разберем все важные моменты по этому вопросу для программистов. Чтобы получить доступ к бесплатной версии UNIGINE 2 Community заполните форму на нашем сайте. Все комплектации UNIGINE: Community — базовая версия для любителей и независимых разработчиков. Достаточна для разработки видеоигр большинства популярных жанров (включая VR). Engineering — расширенная, специализированная версия. Включает множество заготовок для инженерных задач. Sim — максимальная версия платформы под масштабные проекты (размеров планеты и даже больше) с готовыми механизмами симуляции. Подробнее о комплектациях и ценах Пользователь',\n",
              " 'Проведенный нами тест NVIDIA A4000 почти подтвердил, что она способна вытянуть на энкодинге до 16 независимых видеопотоков FullHD в формате H264. Удастся ли кратно увеличить производительность с профессиональной видеокартой, которая стоит в два раза дороже? Попробуем проверить. В нашей второй статье про энкодинг (с тестом А4000) мы упустили, что видеопоток бывает и большего разрешения, поэтому стоит протестировать энкодинг файлов в формате 4К. Для полноты картины мы также сравним энкодинг на решениях от NVIDIA с встроенным GPU от Intel. Некоторые профессионалы полагают, будто достаточно собрать тот же FFmpeg с включенным QuickSync и внешняя видеокарта станет не нужна. Проверим и это утверждение. Мы не будем подробно расписывать процесс тестирования для видеокарт от NVIDIA и зачем нам FFmpeg, поскольку информация об этом есть в предыдущих статьях (первая и вторая части). Лучше сосредоточимся на новых результатах и полезных лайфхаках. Используем тот же самый тестовый стенд из имеющихся в наличии серверов HOSTKEY, но установим в него видеокарту NVIDIA A5000 с большим количеством блоков энкодинга, 24 ГБ видеопамяти и более высоким энергопотреблением. Для начала проверим ее работу на количестве потоков, оказавшемся предельным для А4000 по результатам предыдущего теста:14 потоков gpu pwr gtemp mtemp sm mem enc dec mclk pclk fb bar1 Idx W C C % % % % MHz MHz MB MB 0 97 47 - 92 3 100 0 7600 1920 3502 33 frame=1015 fps=31 q=28.0 Lsize= 9056kB time=00:00:33.80 bitrate=2194.8kbits/s speed=1.02x Удивительно! Мы получили сравнимые с результатом A4000 цифры. Несмотря на большую частоту работы чипа, больший объем используемой видеопамяти и большее энергопотребление, A5000 осилила энкодинг только 14 потоков и спасовала на пятнадцатом. Это фиаско еще раз доказывает, что профессиональные видеоадаптеры предназначены для других целей. Теперь попробуем запустить трансляцию потока с разрешением 3840x2160 (оно же 4K), благо есть и такая версия файла про кролика. Энкодинг силами только центрального процессора захлебнулся уже на одном потоке, когда объем данных кратно увеличился: frame= 2902 fps=27 q=29.0 size=104448kB time=00:01:33.56 bitrate=9144.7kbits/s dup=436 drop=0 speed=0.878x Каковы возможности GPU (помним, результаты у A4000 и A5000 сравнимы)? Это 3 потока. gpu pwr gtemp mtemp sm mem enc dec mclk pclk fb bar1 Idx W C C % % % % MHz MHz MB MB 0 96 46 - 100 3 96 0 7600 1920 1112 9 Как видим, по потребляемой мощности и загрузке блоков энкодинга видеочип работает явно не в режиме повышенного комфорта, хотя при этом расходуется лишь около 1 ГБ видеопамяти.Вывод FFmpeg подтверждает, что видеокарта справляется: frame= 1465 fps=33 q=35.0 Lsize=12584kB time=00:00:48.80 bitrate=2112.4kbits/s dup=159 drop=0 speed=1.09x А вот 4 потока адаптер уже не переваривает. Хотя загрузка железа остается примерно на тех же значениях, начинаются просадки по кадрам: frame= 614 fps= 26 q=35.0 Lsize=4978kB time=00:00:20.43 bitrate=1995.6kbits/s speed=0.858x Если верить заявлению компании-разработчика, технология QuickSync должна «используя специальные возможности обработки мультимедийных данных графических технологий Intel® для ускорения декодирования и кодирования, позволить процессору параллельно выполнять другие задачи и повышая быстродействие системы». Для тестов понадобился подходящий процессор Intel (мы нашли машину с Core i9-9900K CPU @ 3.60GHz) и собранная с поддержкой Quick Sync утилита FFmpeg. С первым проблем не возникло (достаточно чипа старше 6-го поколения и наличия в нем GPU, что несложно проверить), но сборка FFmpeg под тестовую Ubuntu 20.04 вызвала стойкие ассоциации с практическим освоением Камасутры. Чтобы не заставлять вас тратить драгоценное время, опишем, как нам удалось решить проблему.Поскольку пакеты в репозиториях сломаны, первым делом нужно собрать и установить в систему библиотеки gmmlib и libva, а также последние версии Intel media driver и Media SDK. Для этого в домашней директории создадим папку GIT, зайдем в нее и выполним последовательно следующие команды (если будет не хватать каких-то зависимостей, установим их из репозитория; мы рекомендуем сделать sudo apt install autoconf automake build-essential cmake pkg-config): Затем нужно собрать FFmpeg с помощью нескольких магических команд: Стоит убедиться, что у нас появилась поддержка Quick Sync: Вывод команды должен быть примерно таким: Ура! Все готово к тестам. Для начала проверим, как справляется с энкодингом видео в FullHD процессор без Quick Sync: он выдерживает максимум 4 потока, при которых все ядра загружены под 100% frame= 1461 fps= 33 q=29.0 size=24064kB time=00:00:46.33 bitrate=4254.7kbits/s speed=1.05x Пятый поток процессор уже не осиливает, поэтому можно смело приступать к тесту с Quick Sync. В скрипте из предыдущей статьи для этого нужно будет заменить энкодер на h264_qsv, и он примет следующий вид (подробнее об использовании QuickSync с FFmpeg можно почитать тут): Сразу делаем проверку на 6 потоках (+2 к тесту на чистом CPU): frame=291 fps=55 q=29.0 size=1280kB time=00:00:10.13 bitrate=1034.8kbits/s dup=2 drop=0 speed=1.93x Разница очевидна: загрузка процессора не превышает 50%, а имеющийся запас вычислительных ресурсов позволяет прогнозировать 11 – 12 итоговых потоков.Ставим 11 потоков: frame=157 fps=30 q=38.0 Lsize=628kB time=00:00:05.69 bitrate=903.0kbits/s dup=2 drop=0 speed=1.09x Загрузка процессора возрастает незначительно, но GPU уже подходит к пределу возможностей. Двенадцатый поток роняет битрейт и скорость обработки до 24 – 28 кадров.Теперь проверяем потоки в 4K. В отличие от AMD, наш процессор Intel спокойно обрабатывает один поток в таком разрешении и без аппаратного ускорения:frame=655 fps=31 q=-1.0 Lsize=30637kB time=00:00:21.73 bitrate=11547.9kbits/s speed=1.03xНа большее он, увы, не способен. С включенным Quick Sync тестовый компьютер смог вытянуть три потока с разрешением 4K:frame= 509 fps=31 q=33.0 Lsize=8010kB time=00:00:17.42 bitrate=3764.7kbits/s dup=2 drop=0 speed=1.07xСпасовал он только на четвертом, но столько же у нас выдержала и видеокарта Nvidia A5000. Недостатки у решения, увы, тоже есть. При использовании модуля BMC (к примеру, при управлении машиной через IPMI), вы не получите доступ ко всем возможностям аппаратного ускорения, даже если GPU процессора будет определяться в системе. Придется выбирать между удобством удаленного управления или получением всех плюсов от использования Quick Sync. Выводы вы можете сделать самостоятельно. Мы лишь отметим, что для энкодинга видео разница в мощности видеокарт не всегда определяется их ценой, а для решения некоторых задач стоит обратить внимание на специализированные технологии внутри центральных процессоров. Также мы использовали для тестов H264, но кодеки HEVC (H265) или VP1 в теории должны дать лучшие результаты, особенно на разрешениях 4K. Если вы самостоятельно проведете подобные тесты с первым (VP1 пока что представлен аппаратно и массово только для декодинга), поделитесь результатами в комментариях. ____________ Стоимость описанных выше экспериментов измерить просто: воспользуйтесь нашим калькулятором-конфигуратором на этой странице. Например, в самой простой конфигурации она следующая: машина с A4000 обойдется в 22 000р, 12 потоков - 1800р на поток в месяц; машина с A5000 обойдется в 31 000р, 14 потоков - 2214р на поток в месяц; сервер на i9-9900K с QuickSync (QSV) обойдется в 5000-6000р, 11 потоков, 450р на поток. Серверы для такого необходимо собирать на материнских платах без удаленного управления, что мы умеем. Обращайтесь! Кстати, все серверы HOSTKEY предоставляются с нашим модулем полного удаленного управления сервером IPMI и панелью управления серверами и API. Об устройстве последней мы рассказали в этой статье. Пользователь',\n",
              " 'Привет! Перевод пятой лекции о создании Super Mario Bros. В этом видео: Тайловые карты. 2D-анимация. Процедурная генерация уровней. Физика платформера. Пользователь',\n",
              " 'Профессиональные GPU в серверах позиционируются как устройства для высокопроизводительных вычислений, систем искусственного интеллекта и рендеринговых ферм для 3D-графики. Стоит ли их применять для энкодинга, или это стрельба из пушки по воробьям? Попробуем разобраться. Для работы с многопоточным видео достаточно мощностей современных CPU и решений наподобие Intel Quick Sync. Более того, некоторые специалисты считают, будто загрузка профессиональных GPU декодингом и энкодингом — пустая трата ресурсов. Для потребительских видеокарт количество входящих потоков специально ограничивают до двух-трех, хотя мы уже убедились, что небольшое шаманство с драйвером позволяет это ограничение обойти. В предыдущей статье тестировались бытовые видеокарты, а сейчас мы займемся более серьезными — NVIDIA RTX A4000. Что делать, если вывод lscpu выдает вам что-то вроде AMD Ryzen 9 5950X 16-Core Processor, но в компьютер вставлена NVIDIA RTX A4000 с 16 ГБ оперативной памяти, а вы хотите перекодировать и записать поток с нескольких сетевых камер? Информация с них обычно поступает через http, rtp или rtsp, и наша задача — поймать эти потоки, перекодировать их в нужный формат и записать каждый в отдельный файл. Для проверки мы в HOSTKEY создали небольшой тестовый стенд из имеющихся выделенных серверов с указанной выше конфигурацией CPU/GPU без специальной оптимизации и 32 ГБ оперативной памяти. На нем через FFmpeg мы будем принимать мультикаст-вещание в форматах http и rtsp (использован видеофайл bbb_sunflower_1080p_30fps_normal.mp4 из деморепозитория Blender), декодировать его в разном количестве потоков FFmpeg и записывать каждый из них в отдельный файл. Как видно из названия, мы принимаем поток в формате 1080p (30 кадров в секунду). Энкодинг будет применяться только к видео, а звуковые потоки пойдут без изменения. Также несущественно, берем мы один входящий поток и имитируем его мультипоточность или параллельно обрабатываем несколько потоков. Работа с сетью и текущие процессы на тестовом стенде отнимают менее 1% ресурсов CPU, поэтому можно считать, что основную нагрузку на процессор и дисковую подсистему даст именно энкодинг. Все дальнейшее повествование будет вестись для вещания через http, поскольку результаты для потока rtsp оказались сравнимыми. Чтобы не плодить множество консолей терминала на сервере, для теста были созданы простые bash-скрипты, в которые при запуске передается требуемое количество инстансов FFmpeg, перекодирующих видеопоток в h264. Энкодинг на голом CPU: На GPU мы будем использовать возможности видеокарты через NVENC (как собрать FFmpeg с его поддержкой, мы рассказывали в первой статье цикла): Скрипты запускают в цикле мультикаста и ловят в сети нашего кролика. Предварительно стоит проверить через тот же vlc или ffplay, что поток реально вещается. Результат мы будем оценивать по загрузке CPU/GPU, утилизации памяти и качеству записываемого видео, где главными для нас будут два параметра: fps (он должен быть стабильным и не опускаться ниже 30 кадров в секунду) и speed (показывает, успеваем ли мы обрабатывать видео на лету). Для realtime параметр speed должен быть больше 1.00x. Проседания этих двух параметров приводят к выпадению кадров, артефактам, проблемам кодировки и другим повреждениям картинки, которые не хотелось бы видеть на записях с камер видеонаблюдения. Запуск одной копии FFmpeg дает нам такую начальную картину: Загрузка по ядрам процессора в среднем на уровне 18–20%, а вывод FFmpeg показывает следующее: Запас есть, и можно попробовать сразу три потока: Четыре потока выбирают почти все мощности CPU и «отъедают» 13 ГБ оперативной памяти. При этом вывод FFmpeg показывает, что резервы не исчерпаны: Увеличиваем количество потоков до пяти. Процессор держится на пределе, местами начинаются просадки скорости кадров и битрейта на 5–10%: Запуск шести потоков показывает, что предел достигнут. Мы все больше и больше отстаем от реального времени и начинаем пропускать кадры: Запускаем один поток FFmpeg с энкодингом через h264_nvenc. Убеждаемся через вывод nvidia-smi, что у нас задействована именно видеокарта: Поскольку вывод достаточно громоздкий, мы будем отслеживать параметры GPU с помощью следующей команды: Расшифруем обозначения: pwr — потребляемая видеокартой мощность в ваттах; gtemp — температура видеоядра (в градусах Цельсия); sm — SM, mem — память, enc — энкодер, dec — декодер (утилизация их ресурсов указана в процентах); mclk — текущая частота памяти (в МГц), pclk — текущая частота процессора (в МГц); fb — использование кадрового буфера (в Мб). gpu pwr gtemp mtemp sm mem enc dec mclk pclk fb bar1 Idx W C C % % % % MHz MHz MB MB 0 35 48 – 1 0 6 0 6500 1560 213 5 Нас в этом выводе будут интересовать значения загрузки энкодеров GPU и утилизации видеопамяти. Вывод FFmpeg дает следующие результаты: Запускаем сразу пять потоков. Как видно из вывода htop, в случае энкодинга на GPU загрузка процессора минимальна, а большая часть работы ложится именно на видеокарту. Дисковая подсистема также загружена гораздо меньше. gpu pwr gtemp mtemp sm mem enc dec mclk pclk fb bar1 Idx W C C % % % % MHz MHz MB MB 0 36 48 – 8 2 40 0 6500 1560 1035 14 Загрузка блоков энкодинга увеличилась до 40%, память мы заняли почти на гигабайт, но видеокарта по факту загружена не сильно. Вывод FFmpeg подтверждает это, показывая, что у нас есть ресурсы для увеличения количества потоков минимум в 2 раза: Ставим десять потоков. Утилизация CPU на уровне 15–20%. Параметры видеокарты: gpu pwr gtemp mtemp sm mem enc dec mclk pclk fb bar1 Idx W C C % % % % MHz MHz MB MB 0 55 48 – 14 4 61 0 6500 1920 2064 24 Потребление электроэнергии возросло, видеокарта вынуждена была разогнать частоту видеоядра, но мощности энкодинга и видеопамять позволяют увеличивать нагрузку. Проверяем вывод FFmpeg, чтобы в этом убедиться: Пробуем добавить еще четыре потока и получаем загрузку блоков энкодинга в 100%. gpu pwr gtemp mtemp sm mem enc dec mclk pclk fb bar1 Idx W C C % % % % MHz MHz MB MB 0 68 59 – 18 7 100 0 6500 1920 2886 33 Вывод FFmpeg подтверждает, что мы достигли предела. Утилизация CPU при этом все еще не превышает 20%. Контрольные 15 потоков показывают, что GPU начинает сдавать, так как блоки энкодинга работают с перегрузкой, а также наблюдается рост температуры и потребляемой мощности. gpu pwr gtemp mtemp sm mem enc dec mclk pclk fb bar1 Idx W C C % % % % MHz MHz MB MB 0 70 63 – 18 7 100 0 6500 1920 3092 35 FFmpeg также подтверждает, что видеокарте становится тяжеловато. Частота обработки и пропуск кадров уже не внушают оптимизма: Подытожим: применение GPU в такой конфигурации можно назвать оправданным, поскольку максимальное количество обрабатываемых видеокартой потоков в 3 раза превышает возможности далеко не самых слабых процессоров (особенно без поддержки технологий аппаратного кодирования). С другой стороны, мы используем только минимальную часть возможностей видеоадаптера. Поскольку остальные его блоки и видеопамять не сильно нагружены, ресурсы дорогостоящего устройства утилизируются неэффективно.Искушенные читатели могут заметить, что мы не проверили работу в режимах 2K/4K, не использовали возможности современных кодеков (наподобие h265 и VP8/9), а также установили в тестовый стенд видеоадаптер на архитектуре предыдущего поколения. Тот же A5000 должен показать лучший результат: его работу мы проверили в следующей статье, где немного препарировали и Intel Quick Sync. Оправдались ли надежды, можно узнать здесь. Напишите в комментариях, какие еще нюансы стоит учесть при тестировании, какие моменты мы упустили и что бы вы хотели узнать по этой теме. Стоимость описанных выше экспериментов измерить просто: можно воспользоваться нашим калькулятором-конфигуратором на этой странице. На, например, современных Xeon она следующая: машина с A4000 в самой простой конфигурации обойдется в 22000р, 12 потоков - 1800р на поток в месяц; машина с A5000 в самой простой конфигурации обойдется в 31000р, 14 потоков - 2214р на поток в месяц; сервер на i9-9900K в самой простой конфигурации с QuickSync (QSV) обойдется в 5000-6000р, 11 потоков, 450р на поток. Серверы для такого необходимо собирать на материнских платах без удаленного управления, что мы умеем. Обращайтесь! Кстати, все серверы HOSTKEY предоставляются с нашим модулем полного удаленного управления сервером IPMI и панелью управления серверами и API. Об устройстве последней мы рассказали в этой статье. Пользователь',\n",
              " 'В виду того, что мне срезали подписку на Medium решил поддерживать отечественные IT ресурсы. Попробую кидать интересные статьи с переводом на русском, а правообладатели пусть сами разбираются, я честно платил за подписку. На текущий момент VS Code остается средой разработки, которая доступна в период санкций, когда JetBrains отказался продавать лицензии, про Visual Studio даже не узнавал. Сам использую VS Code много лет в разных стеках. VS Code предоставляет возможности разработки практически во всех направлениях: веб-разработка, мобильные приложения, часто встречаются приложения для встраиваемых систем. Ниже перечислены наиболее популярные расширения, которые облегчают разработку приложений. Atom One Dark Theme При всем изобилии тем в VS Code тема Atome One Dark наиболее популярная, потому-что имеет наиболее удачный контраст и прекрасно выглядит. Установка ext install akamud.vscode-theme-onedark VSCode Great Icons Популярное расширение для иконок. Кому как красивее и удобнее решайте сами. Установка ext install emmanuelbeziat.vscode-great-icons Hungry Delete Очень простое, но очень полезное расширение. Помогает при удалении нескольких пустых строк. Позволяет удалить все пустые строки клавишами Ctrl-Backspace для Windows, Linux и Alt+Backspace для Mac. Чтобы удалить строки снизу служит комбинация клавиш Ctrl+]. Поддерживает удаление в режиме мультикурсор. Функция Smart Backspace позволяет выравнивать код при нажатии клавиши Backspace. ext install jasonlhy.hungry-delete Live Server Простое и удобное расширение для веб-разработки. Позволяет запускать статические веб-страницы в режиме локального сервера. Поддерживается перезагрузка страниц при изменении исходных файлов. Поддерживает команды контекстного меню в Проводнике и в редакторе кода. ext install ritwickdey.LiveServer TabOut Расширение, похожее на Hungry Delete, но в отличии от него запускается через меню команд. ext install albert.TabOut Если вы никогда не использовали сниппеты, стоит о них подумать, они делают нашу жизнь легче и упрощают работу с часто используемыми блоками. Сниппеты - небольшие преднастроенные строки, которые позволяют заполнять большие куски кода. Удобно использовать в React компонентах, где большое количество повторяемого шаблонного кода. Установка React сниппетов ext install runningcoder.react-snippets Список расширений, который может заинтересовать Vim - эмулятор Vim редактора в VS Code. Auto Close Tag - автоматически добавляет закрывающие теги для HTML/XML. Git Graph - визуальное представление для веток Git репозитория. Проще один раз увидеть. Таблица горячих клавиш для VS Code Кидайте в комментарии расширения, которые используете вы... Пользователь',\n",
              " 'В этой статье я покажу простой способ генерации видео программами на Python и C/C++ без использования стороннего API. Вам так же потребуется ffmpeg, без него вы не сможете конвертировать файлы в читаемые форматы! Можно экспериментировать, например вы можете создать видео максимального качества и проверять как оно будет эффективно сжиматься тем или иным видео кодеком. Можете даже создать картинку с градиентом в 64-битном цвете и с дизерингом, мало ли какие ещё извращения можно придумать. Можно ещё делать видео с быстро движущимися объектами и сохранять его в 1000 кадров в секунду и потом тестировать всякие интерполяторы движения и моушн блюры. С помощью скрипта на Python можно создать видео. Просто сохраните этот код в какой-нибудь \"main.py\" Далее исполняете команду в консоли: python main.py | ffmpeg -y -f rawvideo -pixel_format gray -video_size 320x240 -framerate 25 -i pipe: out.mkvВ результате у вас получится двухсекундное видео с узором out.mkv. В командную строку в Windows и Linux можно выводить не только текст, но и бинарные данные файлов, а так же эти данные можно перенаправлять в другую программу, в данном случае это ffmpeg который принимает RAW кадры и конвертирует их в видео. И в коде и в команде вызова должны совпадать fps/framerate и video_size/w/h иначе всё разъедется. Нельзя просто взять и написать данные пикселей в консоль через print, нужно записывать их в stdout как в файл через os.write. Если в коде изменить duration на 1, то создастся только один кадр с узором и его можно сохранить как картинку так:python main.py | ffmpeg -y -f rawvideo -pixel_format gray -video_size 320x240 -i pipe: out.png Конечно Питон это медленно и я покажу как сделать это на C и C++, в этих языках стандартный поток вывода stdout тоже считается файлом и в него можно записывать бинарные данные. Сборка и запуск:g++ -Wall -O2 main.cpp -o progprog | ffmpeg -y -f rawvideo -pixel_format gray -video_size 320x240 -framerate 25 -i pipe: out.mkv Сборка и запуск::gcc -Wall -O2 main.c -o progprog | ffmpeg -y -f rawvideo -pixel_format gray -video_size 320x240 -framerate 25 -i pipe: out.mkv Упрощённый вариант от @staticmain: Cборка и запуск:gcc -Wall -O2 main.c -o progprog | ffmpeg -y -f rawvideo -pixel_format gray -video_size 320x240 -framerate 25 -i pipe: out.mkv Я специально не указывал выходной видео кодек для упрощения команд, но вы можете добавить в ffmpeg опции -vcodec libx264rgb -crf 0 для сохранения видео в lossless качестве. Если вы модернизируете программу и добавите в неё поддержку RGBA цвета, то помните что h264 не умеет сохранять прозрачность в кадрах и вам лучше использовать кодек FFV1. Можно сгенерировать видео на любом языке программирования, если на нём можно переключить стандартный вывод в бинарный режим. По такой же логике можно и перенастроить поток ввода stdin в бинарный режим и передать в программу бинарные данные из ffmpeg, таким образом можно будет смастерить видео-фильтр. В общем надо сделать что-то типа того:ffmpeg | фильтр | ffmpeg. Вообще можно просто написать Frei0r фильтр на Си и использовать его в ffmpeg, но мой способ просто не требует никакого стороннего API. Поток можно перенаправлять и в файл и потом этот файл скармливать ffmpeg\\'у, но учтите что видео будет совсем без сжатия и несколько секунд видео 1280x720 будут весить гигабайты. Сделать это можно так:prog > video.datfmpeg -y -f rawvideo -pixel_format gray -video_size 320x240 -framerate 25 -i video.dat out.mkv Раз можно сгенерировать сырое видео, то можно и создать сырой PCM звук и конвертировать его в аудио форматы. Можно например генерировать мелодии и сохранять их в pcm_s16le поток. Опять же переключив stdin в pipe режим вы можете получать аудио поток извне, обрабатывать его своей программой и передавать далее, таким образом у вас получится аудио фильтр и не надо никакого VST/LADSPA API. Это очень простой способ создания видео (для программиста). Если что, в ffmpeg уже встроены некоторые генераторы тестовых видео. Сохраняются ли гигабайты сырых кадров в оперативной памяти при использовании такого способа передачи или же на диске - мне это неизвестно, возможно что у такого способа есть какие-то ограничения на размер передаваемых данных. Помните что в передаваемом потоке данных нет никаких меток синхронизации и если что-то где-то потеряется в пути, то видео всё станет кашей, так что не пытайтесь передавать такой поток через net cat (я не пробовал). Разработчик игр',\n",
              " 'В 2014 году вместе с релизом Android 5.0 Lollipop Google представил миру концепцию Material Design. Каждый элемент в системе состоит из «материала», идею которого хорошо описал дизайнер Матиас Дуарте: «В отличие от настоящей бумаги цифровой материал может разумно расширяться и преобразовываться. Материал имеет физические поверхности и края. Швы и тени придают смысл тому, к чему можно прикоснуться». В 2018 году увидела свет вторая версия Material. В ней сделали больше возможностей для кастомизации: обновили цветовую схему, обновили гайдлайны по работе со шрифтами, добавили поддержку форм (не форм ввода данных, а shapes у компонентов). Появилось больше способов выразить через стандартные компоненты Material айдентику — внешний визуальный интферфейс бренда. Но Google и на этом не остановился: именно поэтому сейчас вы читаете эту статью. В 2021 году на Google I/O представили концепцию Material You — новую версию Material под номером 3. По сравнению с прошлым обновлением изменений действительно много. Цель новой концепции — персонализировать пользовательский опыт. Меня зовут Тимур Задворнов, я Android-разработчик в Surf. В статье обсудим: обновление цветовой палитры Material, Dynamic Color, обновление UI-компонентов. Но сначала — вводная часть: разберём базовое устройство цветовой палитры Material. Это поможет лучше понять обновления в Material 3: что они означают и как с ними работать. Дисклеймер: эта статья — больше про дизайн, чем про разработку и использование компонентов в коде. Material-палитра состоит из шести ключевых цветов: Primary Secondary Background Surface Error Outline Primary и Secondary — первичный и вторичный цвета, основные акцентные цвета приложения, цвета бренда. Здесь всё очевидно. Например, у YouTube Primary цвет — #ff0000 (красный), у Twitter — #1d9bf0 (синий). Background и Surface — цвета поверхностей, на которых располагается контент. Background-цвет — цвет фона приложения, а Surface — цвет поверхностей компонентов в приложении. Самый яркий пример — карточки (Card View). У Card View стандартный цвет фона — Surface. Давайте вспомним базу Material. Как располагаются компоненты в приложении относительно друг друга? В гайдлайнах Material это описано подробно, но мы пробежимся очень кратко. Компоненты в приложении находятся на разных высотах относительно оси Z. В светлой теме высота показывается с помощью тени под компонентом. В тёмной теме это не сработает: тени не будет видно. Решение простое и элегантное: чем выше контент по оси Z, тем ближе он будет к источнику света (поверхности экрана) и тем светлее будет компонент. Тут-то и приходит на помощь Surface-цвет! Если задать цвет Surface, при изменении elevation цвет контента будет меняться автоматически без лишних строк кода. Маппинг значений elevation в значение яркости поверхности хорошо описан в документации и хорошо отображен на визуализации ниже. Этот момент достаточно сложный для понимания, поэтому вопросы по цветам жду в комментариях, подискутируем :) Цвет Error — цвет для отображения ошибок. В объяснении, думаю, не нуждается. Outline — цвет для обводки различных компонентов. Самый яркий пример — Outlined Text Field. С ключевыми цветами покончили. Остаются только их вариации — on-цвета. On-цвета — цвета, которые будут идеально смотреться на «поверхности», окрашенной в основной или второстепенный цвета, цвета поверхности, фона или ошибки. Сразу привожу пример: у красного Error-цвета OnError-цвет логично будет белым, потому что он хорошо читается на красном фоне. У каждого цвета, кроме Outline, есть соответствующий ему on-цвет: у Primary есть OnPrimary, у Surface есть OnSurface и так далее. Базу цветовой схемы Material разобрали. Перейдём к нововведениям. В палитру добавили Tertiary-цвет и все его вариации. Tertiary — третий цвет для айдентики бренда наряду с Primary и Secondary: иногда двумя цветами бренду ограничиться непросто. Появился новый Surface-цвет — SurfaceVariant (вместе с OnSurfaceVariant). Это второй вариант для цветов поверхностей. Можно использовать, например, в качестве цвета текста на поверхностях или цвета дивайдеров. Ещё одна новинка палитры Material — Container-цвета. Container-цвета — новая вариация цветов, которая используется в контейнерах с компонентами. Яркий пример — Floating Action Button. Начиная с Material 3, цвет фона у этой кнопки стал PrimaryContainer, а цвет контента на этой кнопке — OnPrimaryContainer. У Container вариаций также есть злой двойник — On-цвет. Как Google собирается делать девайсы более персональными с Material You? С помощью Dynamic Color — одного из главных нововведений Material 3! Dynamic Color (динамический цвет) — фича, которая генерирует цветовую палитру по обоям пользователя и распространяет её на все приложения в системе (которые, естественно, поддерживают Dynamic Color). Как генерируется цвет? Цветовую палитру создаёт встроенный в Android 12 Monet Engine: он извлекает из обоев так называемый seed color и по нему генерирует палитру. Тональная палитра состоит из тринадцати тонов, включая белый и черный. Значение тона 100 эквивалентно представлению о максимальном освещении и даёт белый цвет. Значение тона 0 — чистый чёрный цвет. Каждое значение тона от 0 до 100 выражает количество света, присутствующего в цвете. В Android генерируется пять ключевых цветов: Accent1 (используется для Primary), Accent2 (для Secondary), Accent3 (для Tertiary), Neutral1 (для Background и Surface), Neutral2 (для SurfaceVariant и Outline). Плюс 13 их вариантов с разной тональностью. Сгенерированную палитру можно посмотреть с помощью виджета-пасхалки в Android 12. Теперь сопоставим все данные вместе: у нас есть большая сгенерированная палитра цветов и система цветов Material. На картинке ниже — готовая цветовая схема приложения, сгенерированная лишь по одному seed color. Сгенерировать свою палитру по канонам Material 3 можно с помощью Material Theme Builder. Также оттуда можно выгружать темы в виде стилей XML и стилей Jetpack Compose. В Material 3 обновили гайдлайны по UI-компонентам: кнопкам, чипам, диалогам, карточкам и панели навигации. Сolor mapping у всех компонентов соответствует гайдлайнам Material 3 и поддерживает Dynamic Color. Поговорим подробнее про каждый из компонентов. Обновили всё: обычные кнопки, FAB (floating action button) и Extended FAB. Новое в обычных кнопках: Полностью закруглили углы. Поменяли размеры кнопок: стандартную высоту подняли с 36dp до 40dp, размер иконки в кнопке увеличили до 18dp. Текст в кнопках теперь пишется не капсом, а с большой буквы (sentence case). Добавили 3 типа кнопок: filled — с бэкграундом primary, secondary, tertiary или какого угодно цвета, filled tonal — с бэкграундом container цвета) и elevated кнопки — с тенью. Вот они слева направо: Filled, Filled Tonal, Elevated, Outlined, Text. Новое в FAB: Изменили форму: теперь FAB — квадратные с закругленными углами, а не круглые. Добавили новый тип — Large FAB. Обновили цветовую палитру кнопки: теперь бэкграунд по гайдлайнам должен иметь Container-цвет (Primary, Secondary или Tertiary), а контент на кнопке — соответствующий On-Container цвет. Новое в Extended FAB: Изменили форму: Extended FAB теперь тоже стали квадратные с закругленными углами. Обновили цветовую схему по аналогии с обычными FAB. Обновили размеры кнопки, если в ней есть текст: теперь по высоте она точно такая же, как и обычный FAB. Чипы — компоненты, которые помогают пользователю вводить и фильтровать информацию. Что нового: Обновили форму компонента. Теперь они все одинаковые: прямоугольные с закруглениями по углам. Разделили чипы на четыре типа: Assist, Filter, Input, Suggestion. Assist — для «умных» или автоматизированных действий: например, добавить событие в календарь. Ближайший визуальный аналог — обычная кнопка. Filter — кнопка для фильтрации данных. Input — данные, которые были введены пользователем. Яркий пример: ввод адреса электронной почты, когда данные из текстового поля преобразуются в данные в чипе. Suggestion-чипы помогают сузить намерения пользователя: предлагают динамические предположения о возможных действиях пользователя — например, варианты ответа на сообщение в мессенджере. Обновления в диалогах: Увеличили паддинг контента. Увеличили радиус закругления углов. Обновили шрифты. В стандартный диалог добавили иконку над заголовком диалога. Также Google выкатил гайдлайны по реализации полноэкранных диалогов. Их можно использовать для ввода данных на экранах мобильных устройств. Правда, на планшетах этот диалог будет не полноэкранным, а обычным. В Android всю жизнь было два способа построить user-friendly навигацию: боковой бар и нижний. С Material 3 в Android унифицировали нейминг баров навигации и добавили новый вид — Navigation Rail. Navigation Bar — переименованный Bottom Navigation. Navigation Drawer — боковая панель навигации. Можно вызвать по свайпу с левой стороны экрана или, если экран большой, закрепить в левой части. Navigation Rail — тоже боковая панель навигации, но более узкая: как вертикальный Navigation Bar. Обновлений по барам навигации не так много: обновили цветовую схему, добавили закругления, изменили размеры некоторых компонентов. Хочу остановиться только на Navigation Rail. По гайдлайнам его советуют использовать для больших экранов вместо Navigation Bar, который неопрятно растягивается на всю ширину внизу экрана. Изменения коснулись и больших экранов. В преддверии выхода Android 12L Google показал гайдлайны по дизайну приложений, которые адаптированы для разных экранов: мобильного, складного и большого. Обновление затронуло много компонентов, о которых нет смысла рассказывать отдельно. А вот карточки сильно перерабатывать не стали. Помимо цветовой схемы, изменений минимум: : У карточки убрали elevation. Карточки разделили на 3 типа: Elevated (с тенью), Filled (залитая цветом) и Outlined (с обводкой). Та же ситуация и с тулбарами: немного изменили цветовую схему, позиционирование текста для разных видов тулбара, обновили шрифты, убрали elevation. Третье обновление концепции Material выдалось весьма объемным и принесло много нового, в частности, в дизайн Android. Тезисно: Много нового появилось в палитре Material (надеюсь, вам помог мой краткий экскурс в палитру). Dynamic Color — интересная вещь. Мне нравится, что с Android 13 все вендоры обязаны будут поддержать эту фичу. Но есть сомнения, что все сторонние приложения в ближайшее время начнут поддерживать динамические цвета. Обновили компоненты, API для работы с ними в Material Design Components и обновляют API для работы с ними на других платформах (Jetpack Compose, Flutter, Web). К сожалению, в Material You пока что есть недоработки. По состоянию на февраль 2022-го: Обновлены не все компоненты. На текущий момент Material You-гайдлайны полностью поддерживает только Material Design Components — старый подход к разработке Android-приложений. Для Jetpack Compose вышла альфа-версия библиотеки Material 3. Для Flutter поддержка новых гайдлайнов находится в активной разработке. Поддержка для Web только в планах. Пользователь']"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JA5gZgn-4O9E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e63b704a-f37b-4525-cf08-1eb6e97dc6fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Если в 2018 году люди тратили на просмотр видео 1,5 часа в день, то в 2022 году вовлечённость выросла до 2,5 часов. Пользователи делятся видео в два раза чаще, чем любым другим контентом, а motion-графика почти так же популярна, как простые записи. Сделали для вас подборку обучающих ресурсов, программ и инструментов для самостоятельного обучения. В декабре 2021 года английская анимационная студия Wyzowl провела исследование, согласно которому motion-графика занимает второе место по популярности среди всех разновидностей видеоконтента (33%), уступая лишь 9% формату обычной видеозаписи (42%). Видео помогает компаниям привлекать новых клиентов, увеличивать объёмы продаж, повышать узнаваемость бренда, сокращать количество обращений в службу поддержки. Это подтверждают и сами потребители: 88% говорят, что именно просмотр видео убедил их совершить покупку, 72% предпочитают узнавать о новых продуктах и услугах из видеороликов. Рассказываем, как сделать motion-дизайн профессией. Требования работодателей к motion-дизайнерам в 2022 году меняются в зависимости от уровня компании. Мы приведём в качестве примера две вакансии, которые были актуальны на начало мая 2022 года. Это топовые предложения для специалистов высокого класса, на которые следует ориентироваться. В конце марта Apple опубликовала вакансию: от кандидата ждут, что он сможет создавать анимацию, заниматься графическим дизайном и делать видеоролики для рекламных и образовательных проектов компании. Разработка креативной концепции также ложится на специалиста. Кандидат должен работать в After Effects, Illustrator, Photoshop, Premiere Pro, Cinema 4D, Maya и Final Cut Pro. Рассматривают бакалавров в области графического дизайна, медиаискусства или другой смежной специальности. Требования к опыту: 4–10 лет работы по специальности. Про доход ничего не пишут, но на сторонних ресурсах говорят, что средняя зарплата motion-дизайнера в Apple составляет около 80 тысяч долларов в год. Социальная сеть VK опубликовала вакансию motion-дизайнера в команду игрового бренда MY.GAMES. Как и Apple, VK ищет универсального специалиста, который будет не только рисовать и монтировать, но и создавать концепцию роликов и сценарии. Кандидат также должен самостоятельно выставлять свет, строить кадр, записывать качественный звук и подбирать аудиоконтент. Поскольку вакансия в геймдеве, нужно немного работать на базе движка Unity. Требуется портфолио, а про образование не сказано ничего. Набор программ, в которых надо уметь работать, классический: Adobe Premiere, Adobe Photoshop, Adobe After Effects, Photoshop. Про деньги скажут на собеседовании. На hh.ru в вакансиях со схожими функциями указывают зарплаты от 150 до 200 тысяч рублей в месяц. При этом специалисты уровня джун, работающие по чёткому техническому заданию со знанием основных инструментов, могут рассчитывать на 70 тысяч в месяц. Анимация включает в себя множество этапов от рисования эскиза до создания трёхмерных моделей и объединения их в сложную динамическую сцену. Выбор инструментов зависит от специфики работы. Иногда для выполнения задачи достаточно одной программы, а порой приходится задействовать целый набор инструментов. Перечислим основные: Adobe After Effects. Позволяет создавать анимированную графику и визуальные эффекты, а также редактировать видеоряд, в том числе видео 4K и 360/VR. Хорошо работает с другими системами нелинейного монтажа, такими как Avid Media Composer и Final Cut Pro X. Гибко интегрируется с 3D-приложениями: 3ds Max, Maya и Cinema 4D. Доступен в экосистеме Creative Cloud. На сайте Adobe выложены обучающие видео. У Нетологии есть бесплатный курс для освоения базы, начать обучение мжно в любое время. Cinema 4D. Программное решение для 3D-моделирования, анимации, симуляции и рендеринга. Художники-аниматоры любят Cinema 4D за удобство, простоту использования и гибкость при интеграции с After Effects. У Cinema 4D сильное сообщество пользователей, поэтому легко найти обучающие ресурсы. Начать можно с видео на популярном канале Greyscalegorilla. Adobe Premiere Pro. Приложение для редактирования видео, создаёт динамические связи с After Effects: пользователи могут вносить финальные правки в ролик без предварительного рендеринга. На официальном сайте программы есть коллекция видеоуроков. Adobe Photoshop. Многофункциональный графический редактор. Уроки доступны на любых ресурсах. Основы можно выучить в Нетологии. Adobe Illustrator. Одна из ведущих программ обработки векторной графики и один из главных инструментов любого дизайнера. Начинайте с бесплатного курса Нетологии или официальных материалов. Blender. Бесплатное ПО для 2D и 3D-графики с открытым исходным кодом и каналом на YouTube с руководствами. Популярен в геймдеве. Maya. Конкурент Cinema 4D с более сложным интерфейсом. Его используют многие голливудские студии для 3D-моделирования и анимации. Открыта для сторонних разработчиков. Есть сайт с уроками. Для комфортной работы в этих программах на начало 2022 года нужен компьютер с 32 ГБ оперативки и 4 ГБ GPU. Для большего погружения в профессию приведём ещё несколько ссылок на YouTube-каналы про motion-дизайн: VideoSmile Andrey Sokolov SurfacedStudio School of Motion Arrimus 3D SonduckFilm Blender Guru Eyedesyn Flat Pack FX Чаты: Motion Talk Motion Chat Каналы и сообщества для поиска работы: Motion designer hunter CG Freelance Motion Graphics Jobs Каналы и сообщества для вдохновения и обучения: Motion Graphics & Video Design MOTION GRAPHICS Animation & Visual effects Motion.RAR BDSR DESIGN REFERENCES VimeoInspiration | Motion design | Вольница Официальные ресурсы ПО: Adobe Premiere Pro for beginners Adobe Premiere Pro Intermediate Users Group Adobe After Effects Tutorials After Effects / Motion Design Adobe Illustrator tutorials Blender 3D Artists Blender Artists Community Cinema 4D - Maxon Cinema 4D — канал Cinema 4D — чат Photoshop & Illustrator Photoshop Tutorials Design for Motion: Fundamentals and Techniques of Motion Design, Остин Шоу. Остин Шоу — motion-дизайнер, который более 15 лет делал графику для Ferrari, Fedex, Ralph Lauren, Target. Сейчас — профессор motion-дизайна в Колледже искусств и дизайна Саванны. Преподавал в Школе визуального искусства в Нью-Йорке. В книге — техника иллюстрации, визуальный сторителлинг, работа с 3D-объектами, практические упражнения. Аниматор: набор для выживания. Секреты и методы создания анимации, 3D-графики и компьютерных игр, Уильямс Ричард. Мультипликатор и обладатель премии Оскар за фильм «Кто подставил кролика Роджера» рассказывает о принципах анимации, 3D-графики и компьютерных игр. The Theory and Practice of Motion Design, Брайан Стоун и Лия Уолин. Авторы раскрывают о motion-дизайне через серию познавательных интервью с профессиональными дизайнерами о теории цвета и формы, визуализации, типографике и сторителлинге. Motion-дизайнер компании-разработчика офисного ПО МойОфис На мой взгляд, motion-дизайн сто́ит начать с изучения 12 принципов Disney. Они помогут понять, как оживить статическое изображение, выделить интересные для вас направления, в которых хотелось бы развиваться. После выбора специализации стоит подумать, где можно научиться соответствующим приёмам. Ресурсы, с которыми точно необходимо ознакомиться: Максимально полная документация по After Effects, одной из флагманских программ для motion-дизайнера; Гениальные плагины и уроки по After Effects; Крупнейший ресурс с обучающими курсами, в том числе и Motion Graphics; Ещё уроки и плагины для After Effects. При выборе обучающих ресурсов необходимо отталкиваться от потребностей. Важно уметь ставить цель и искать средства для её достижения. Можно бесконечно проходить различные курсы, но так и не применить знания. Нужно постоянно тренировать насмотренность, изучать лучшие практики и анализировать работы мастеров с именем. Начинающим специалистам я бы посоветовал начать с заказов на фриланс-ресурсах, параллельно продвигая портфолио на таких сайтах, как Artstation или Cgsociety. Продюсер CG-студии Mondlicht Studios Большинство сегодняшних топов индустрии — самоучки. Когда они начинали, контента и готовых курсов просто не было, был плохой интернет и желание научиться. Сегодня выбор куда больше: есть и курсы, и отдельные каналы, и классическое обучение. Важно понимать плюсы и минусы каждого. Например, самостоятельное образование экономит вам деньги, но вы тратите намного больше времени. С готовыми курсами вы экономите время, но расстаётесь с приличной суммой. На мой взгляд, успех в балансе. Идеальный вариант — это курсы для быстрого старта и понимания основ, дополненные максимально возможным количеством туториалов, вебинаров, статей и любого контента, до которого получится добраться. Ещё один важный момент — это сообщество. Оно поможет увидеть, что вы делаете не так, получить обратную связь, найти первые заказы и многое другое. Комьюнити в Computer Generated Imagery — это очень тёплая тусовка, где с пониманием относятся к новичкам. Motion-дизайнер студии Maryco C хорошей самодисциплиной и больши́м желанием можно самостоятельно изучить motion-дизайн. В интернете много бесплатных материалов и уроков. Я рекомендую начинать с пакета Adobe, Cinema 4D, Blender, разобраться в их инструментах. Пробовать анимировать абстрактные композиции, анализировать готовые проекты, смотреть, какими средствами достигается тот или иной эффект в роликах, что в них хорошо, а что плохо и как можно сделать лучше. Ещё советую смотреть туториалы. Мне очень помогали проекты VideoSmile, «Вольница», Greyscalegorilla (у них есть разделы по 3D) и блог AEPlug на Youtube. На Youtube очень много уроков, всегда найдётся англоговорящий индус, который показывает, как сделать что-то невообразимое. Для вдохновения советую смотреть Behance и телеграм-канал Тренд-бюро, здесь рассказывают про разные области дизайна и моды — это помогает понять контекст, с которым вам предстоит работать. Опыт в обычном статичном дизайне тоже необходим. Качество результата будет выше. Хороший дизайн приятен глазу, он строится на гармоничном сочетании шрифтов и цветов, в нём выстроена правильная композиция. Понимая, как это можно сделать, вы визуально улучшите свои работы. Дизайнеры учатся постоянно, особенно в начале карьеры. Чтобы стать востребованным профессионалом, нужно: владеть основными программами; быть насмотренным и хорошо визуализировать; уметь делать раскадровки и объяснять их; чувствовать динамику и ритм ролика; понимать, как удерживать внимание зрителя, как показать большой объём информации так, чтобы она воспринималась легко; иметь развитые гибкие навыки, чтобы общаться с заказчиками; уметь рассчитать время, которое займёт выполнение проекта, и исходя из этого — цену. Редактор Нетологии',\n",
              " 'Специально для тех, кто ищет полноценный отечественный аналог Unity или Unreal Engine, мы продолжаем цикл статей про безболезненный переход на UNIGINE с зарубежных движков. В третьем выпуске рассмотрим миграцию с Unity с точки зрения программиста. Традиционно игровая логика в проекте Unity реализуется через пользовательские компоненты — C# классы, унаследованные от MonoBehaviour. Основная логика компонента определена в событийных методах Start(), Update() и так далее. UNIGINE предлагает очень похожую концепцию — C# Component System — стабильная и высокопроизводительная компонентная система на .NET 5. Компоненты представлены C# классами, унаследованными от Component, их можно назначить любой ноде в сцене. Жизненный цикл каждого компонента определяется набором методов (Init(), Update() и т. д.), вызываемых в основном цикле движка. Программирование в UNIGINE с использованием C# мало чем отличается от программирования в Unity. Например, давайте сравним, как выполняется вращение объекта в Unity: и в UNIGINE: Кнопка для запуска экземпляра приложения в отдельном окне расположена на панели инструментов в UnigineEditor. Также рядом расположены настройки параметров запуска. Вот как мы заставим колесо вращаться с помощью C# Component System и запустим экземпляр, чтобы немедленно его проверить: Более того, системная логика приложения на UNIGINE может быть определена в файлах AppWorldLogic.cs, AppSystemLogic.cs и AppEditorLogic.cs в папке source проекта. Чтобы узнать больше о последовательности выполнения и о том, как создавать компоненты, перейдите по ссылкам ниже: Последовательность выполнения Видеоруководство по C# Component System C# UNIGINE API Для тех, кто предпочитает C++, UNIGINE позволяет создавать приложения C++ с использованием С++ UNIGINE API, и, при необходимости, C++ Component System. Используйте клавишу ~, чтобы открыть консоль в приложении Unity UNIGINE //Исходный код (C#) Debug.Log(\"Text: \" + text); Debug.LogFormat(\"Formatted text: {0}\", text); //Исходный код (C#) Log.Message(\"Debug info:\" + text + \"\\\\n\"); Log.Message(\"Debug info: {0}\\\\n\", new vec3(1, 2, 3)); Дополнительные типы сообщений в API класса Log Видеоруководство, демонстрирующее, как выводить пользовательские сообщения в консоль с помощью C# Component System Unity UNIGINE //Исходный код (C#) GameObject this_go = gameObject; string n = gameObject.name; //Исходный код (C#) Node this_node = node; string n = node.Name; Видеоруководство, демонстрирующее, как получить доступ к нодам из компонентов с помощью C# Component System В Unity компонент Transform отвечает за позицию, вращение и масштаб Game Object, а также за родительско-дочерние связи. Чтобы получить вектор направления по одной из осей с учетом вращения GameObject в мировых координатах, в Unity используется соответствующее свойство компонента Transform. В UNIGINE трансформация ноды в пространстве представлена ее матрицей трансформации (mat4), а все основные свойства и операции с иерархией нод доступны при помощи методов и свойств класса Node. Такой же вектор направления в UNIGINE получается с помощью метода Node.GetWorldDirection(): Unity UNIGINE //Исходный код (C#) Vector3 forward = transform.forward; Vector3 right = transform.right; Vector3 up = transform.up; transform.Translate(forward * speed * Time.deltaTime); //Исходный код (C#) vec3 forward = node.GetWorldDirection(MathLib.AXIS.Y); vec3 right = node.GetWorldDirection(MathLib.AXIS.X); vec3 up = node.GetWorldDirection(MathLib.AXIS.Z); node.Translate(forward * speed * Game.IFps); Система координат в UNIGINE В Unity, чтобы гарантировать, что определенные действия выполняются за одно и то же время независимо от частоты кадров (например, изменение положения один раз в секунду и т. д.), используется множитель Time.deltaTime (время в секундах, которое потребовалось для завершения последнего кадра). То же самое в UNIGINE называется Game.IFps: Unity UNIGINE //Исходный код (C#) transform.Rotate(0, speed * Time.deltaTime, 0, Space.Self); //Исходный код (C#) node.Rotate(0, 0, speed * Game.IFps); Unity: В UNIGINE за вспомогательную отрисовку отвечает синглтон Visualizer: Примечание. Visualizer также можно включить с помощью консольной команды show_visualizer 1. Все типы визуализаций в API класса Visualizer. Unity UNIGINE //Исходный код (C#) SceneManager.LoadScene(\"YourSceneName\",LoadSceneMode.Single); //Исходный код (C#) World.LoadWorld(\"YourSceneName\"); Unity: UNIGINE: Компонентный подход Unity позволяет рассматривать такие стандартные объекты, как MeshRenderer, Rigidbody, Collider, Transform и другие, как обычные компоненты. В UNIGINE доступ к аналогам этих сущностей осуществляется иначе. Классы всех типов нод являются производными от Node, поэтому чтобы получить доступ к функциональности ноды определенного типа (например, ObjectMeshStatic), необходимо провести понижающее приведение типа (downcasting). Рассмотрим эти самые популярные варианты использования: Unity: UNIGINE: Unity: UNIGINE: Downcasting (приведение от базового типа к производному) выполняется одинаково в обоих движках с использованием родной конструкции C# as: Unity UNIGINE //Исходный код (C#) Collider collider = gameObject.GetComponent<Collider>; BoxCollider boxCollider = collider as BoxCollider; //Исходный код (C#) Node node = World.GetNodeByName(\"my_mesh\"); ObjectMeshStatic mesh = node as ObjectMeshStatic; Чтобы выполнить Upcasting (приведение от производного типа к базовому), можно как обычно просто использовать сам экземпляр: Unity UNIGINE //Исходный код (C#) Collider collider = gameObject.GetComponent<Collider>; BoxCollider boxCollider = collider as BoxCollider; Collider coll = boxCollider; //Исходный код (C#) Node node = World.GetNodeByName(\"my_mesh\"); ObjectMeshStatic mesh = node as ObjectMeshStatic; Unigine.Object obj = mesh; Unity UNIGINE //Исходный код (C#) Destroy(myGameObject); // уничтожить объект с задержкой в 1 секунду Destroy(myGameObject, 1); //Исходный код (C#) node.DeleteLater(); // рекомендуемый вариант // нода уничтожается после текущего кадра node.DeleteForce(); // форсировать уничтожение ноды в данный момент, что не всегда безопасно Для выполнения отложенного удаления ноды в UNIGINE можно создать компонент, который будет отвечать за таймер и удаление. В Unity экземпляр префаба или копия уже существующего в сцене GameObject создается с помощью функции Object.Instantiate: Затем вы должны указать префаб, который будет создан, в параметрах компонента скрипта. В UNIGINE получить доступ к уже существующей ноде любого типа можно также через параметр компонента, и клонировать ее при помощи Node.Clone(). Но ассеты не являются нодами, они принадлежат файловой системе. К ассету можно обратиться, используя эти типы параметров: AssetLink — для любых ассетов, AssetLinkNode — для ассетов *.node, содержащих иерархию нод, сохраненную как Node Reference (аналог prefab). В этом случае ссылка на ассет, аналогично Unity, указывается в UnigineEditor: Также можно использовать функцию World.LoadNode для загрузки иерархии нод вручную, указав виртуальный путь к ассету. Еще один способ загрузить содержимое ассета *.node — создать NodeReference и работать с иерархией нод как с одним объектом. Тип Node Reference имеет ряд внутренних оптимизаций и тонких моментов (кэширование нод, распаковка иерархии и т.д.), поэтому важно учитывать специфику работы с этими объектами. Unity позволяет расширять функциональность редактора с помощью C# скриптов. Для этого в скриптах поддерживаются специальные атрибуты: [ExecuteInEditMode] — для выполнения логики скрипта в режиме Edit, когда приложение не запущено. [ExecuteAlways] — для выполнения логики скрипта как в режиме Play, так и при редактировании. Например, так выглядит код компонента, который заставляет GameObject ориентироваться на определенную точку в сцене: UNIGINE не поддерживает выполнение логики C# внутри редактора. Основной способ расширить функциональность редактора — плагины, написанные на C++. Для быстрого тестирования или автоматизации разработки можно написать логику на UnigineScript. UnigineScript API обладает только базовой функциональностью и ограниченной сферой применения, но доступен для любого проекта на UNIGINE, включая проекты на .NET 5. Есть два способа добавить скриптовую логику в проект: Создав скрипт мира: Создайте ассет скрипта .usc. Определите в нем логику. При необходимости добавьте проверку, загружен ли редактор: Выделите текущий мир и укажите для него сценарий мира. Нажмите Apply и перезагрузите мир. Проверьте окно консоли на наличие ошибок. После этого логика скрипта будет выполняться как в редакторе, так и в приложении. Используя WorldExpression. С той же целью можно использовать ноду WorldExpression, выполняющую логику при добавлении в мир: Нажмите Create -> Logic -> Expression и поместите новую ноду WorldExpression в мир. Напишите логику на UnigineScript в поле Source: Проверьте окно Console на наличие ошибок. Логика будет выполнена немедленно. Помимо обнаружения столкновений, компонент Collider в Unity может быть использован как триггер, который срабатывает, когда другой коллайдер попадает в его объем. В UNIGINE Trigger — это специальный тип нод, вызывающих события в определенных ситуациях: NodeTrigger вызывает коллбэк при изменении состояния включен/выключен и позиции самой ноды. WorldTrigger вызывает коллбэк, когда какая-либо нода (независимо от типа) попадает внутрь или за его пределы. PhysicalTrigger вызывает коллбэк, когда физические объекты попадают внутрь или наружу его пределов. Важно! PhysicalTrigger не обрабатывает столкновения, для этого физические тела и сочленения предоставляют свои собственные события. WorldTrigger — наиболее распространенный тип триггера, который можно использовать в игровой логике: Обычный игровой ввод Unity: UNIGINE: Также можно использовать синглтон ControlsApp для обработки привязок элементов управления к состояниям. Чтобы настроить привязки, откройте настройки Controls: Для обнаружения пересечений лучей с объектами в Unity используется Physics.Raycast. GameObject должен иметь прикрепленный компонент Collider для участия в рейкастинге: В UNIGINE то же самое делается с помощью Intersections: Напоминаем, что получить доступ к бесплатной версии UNIGINE 2 Community можно заполнив форму на нашем сайте. Все комплектации UNIGINE: Community — базовая версия для любителей и независимых разработчиков. Достаточна для разработки видеоигр большинства популярных жанров (включая VR). Engineering — расширенная, специализированная версия. Включает множество заготовок для инженерных задач. Sim — максимальная версия платформы под масштабные проекты (размеров планеты и даже больше) с готовыми механизмами симуляции. Подробнее о комплектациях и ценах Пользователь',\n",
              " 'Рассказываю, какими шрифтами можно заменить заблокированные Times New Roman, Arial и Helvetica и где скачать аналоги. В апреле компания Monotype закрыла доступ к своему каталогу шрифтов для российских пользователей. Arial, Times New Roman и Helvetica всё ещё доступны для использования, однако, что будет дальше, предсказать сложно: в худшем случае компания Monotype может заблокировать шрифты во всех сервисах и программах на территории России. Если в документах или фирменном стиле вашей компании используется Arial или Times New Roman — о их замене лучше задуматься уже сейчас. Делюсь подборкой бесплатных аналогов популярных шрифтов Monotype. Calibri Candara Commisioner Constantia Franklin Gothic Georgia IBM Plex Inter Lucida Sans Manrope Mulish Noto Sans Nunito Outfit Poppins Raleway Roboto Rubik Segoe UI Ubuntu Golos Text Literata PT Astra Вместо вывода делимся тремя универсальными правилами типографики, которые будут полезны и недизайнерам: Правило 1. Делайте заголовки в два раза больше основного текста. Так читателю будет проще понять, что в вашей информации важное, а что второстепенное. Правило 2. Если хотите сделать текст контрастным — пропустите одно начертание. Лучше сочетать тонкое начертание с полужирным, а регулярное — с жирным. Правило 3. Чем важнее текст, тем стандартнее шрифт. Не усложняйте витиеватыми шрифтами то, что несёт ключевой смысл текста. Предприниматель',\n",
              " 'Статья ранее публиковалась в нашем блоге на DTF. Если вы планируете переходить с иностранного софта на отечественный и ищете полноценный аналог Unity или Unreal Engine, то одним из вариантов может стать продукция нашей компании, полностью готовая к импортозамещению. UNIGINE использует общепринятые интерфейсы и рабочие процессы, которые могут быть вам знакомы по работе с другими 3D-инструментами. По опыту наших клиентов, для перехода на UNIGINE с других платформ уходит не более 1–2 недель. Одна из таких платформ — платформа разработки в реальном времени Unity. Далее в статье рассмотрим базовую информацию по переходу на UNIGINE. Сначала разберемся с названиями различных сущностей и другими терминами. В таблице ниже приведены термины Unity и их точные или приблизительные эквиваленты в UNIGINE. Категория Unity UNIGINE Управление проектами и SDK Hub SDK Browser Интерфейс редактора Hierarchy Panel Окно World Nodes Inspector Окно Parameters Project Browser Окно Asset Browser Scene View Editor Viewport Сцена Scene World Типы геймплея Component Component System GameObject Node Prefab NodeReference Меши Mesh Renderer Static Mesh Dynamic Mesh Skinned Mesh Renderer Skinned Mesh Blendshapes Morph Targets Эффекты Particle System Particle System Halo Volumetric Objects Lens Flares Lens Flares Billboard Renderer Billboards Projector / Decal Projector (HDRP) Decals Экстерьеры Terrain Terrain Systems Trees / Grass Mesh Clutter Grass аддон Vegetation Wind Zones Animation Field Игровой интерфейс UI (User Interface) GUI (Graphics User Interface) Освещение Light Sources Light Sources Environment Environment Lightmapping LightmappingVoxel GI Reflection Probes Environment Probes Рендеринг Shade Base Material Material User Material Кастомные шейдеры: HLSL Shader Graph HLSL GLSL UUSL (Unified UNIGINE Shader Language) Визуальный редактор материалов Compute Shaders UUSL Compute Shaders Rendering Paths Rendering Sequence Multi-Display Rendering Плагины для рендеринга на нескольких экранах (Multi-Monitor Rendering) Плагин Syncker для многоканальной визуализации Программирование C# C++ C# UnigineScript Scriptable Render Pipeline URP HDRP Rendering Sequence (при полном доступе из API) Scriptable Materials Физика Raycast Intersections Rigid Body Rigid Body Collider Shape Joint Joint Cloth Cloth Body Анимация Timeline Tracker Навигация и нахождение пути NavMesh NavMeshAgent Off-Mesh Link NavMesh Obstacle Navigation Areas Obstacles Пользователи Unity используют Unity Hub — приложение для поиска, загрузки и управления версиями движка и проектами. В UNIGINE для этих целей служит UNIGINE SDK Browser. Помимо управления проектами и установленными SDK, браузер SDK предоставляет доступ к примерам (Samples), базе знаний (Knowledge) и дополнениям (Add-Ons). В последнюю категорию входят различные 3D-модели и материалы, в том числе растительность, спецэффекты, погодные эффекты и другое. Также заметным отличием UNIGINE является возможность создания нового (или редактирование старого) проекта с поддержкой одного из нескольких языков программирования: C++, C# и UnigineScript. Для пользователей Unity рекомендуется использовать C# Component System. Также возможно использование нескольких языков программирования в одном проекте. Например, для выполнения ресурсоемких задач часто используют C++. Нажмите Create New в разделе My Projects. Выберите тип проекта C# (.NET 5) в поле API + IDE. Если требуется поддержка VR-гарнитур, перейдите в раздел Plugins, отметьте необходимые плагины в секции Stereo 3D и нажмите Ok (больше о поддержке VR-устройств здесь). Нажмите Create New Project. После завершения загрузки нажмите Open Editor, чтобы запустить UNIGINE Editor. Элементы интерфейсов Unity Editor и UNIGINE Editor близки по функционалу: на схеме ниже они окрашены в похожие цвета. Расположение элементов UNIGINE Editor можно настраивать, перетаскивая и изменяя их размер. В UNIGINE по умолчанию используется темная тема. Toolbar. Панель инструментов, которая обеспечивает доступ к инструментам позиционирования, а также элементам управления логикой приложения, воспроизведением звука, симуляцией физики, компиляцией шейдеров и запеканием света. World Hierarchy Window. Инструмент для работы с иерархией нод. Позволяет организовывать ноды в иерархию, а также добавлять, удалять, клонировать и переименовывать их. Editor Viewport. Просмотр трехмерной сцены. Позволяет визуально перемещаться и редактировать виртуальный мир. Parameters Window. Окно параметров выбранного элемента виртуального мира. Позволяет просматривать и изменять параметры нод, материалов, свойств и ассетов. Asset Browser Window. Инструмент для организации контента в проекте: создания, импорта, просмотра, переименования ассетов, а также перемещения и управления их иерархией. Инструменты для просмотра виртуальной сцены Unity Scene View и UNIGINE Editor Viewport очень похожи между собой — это непосредственно само окно просмотра и панель инструментов. Вы можете использовать столько окон Editor Viewport, сколько вам необходимо. Есть русские субтитры Camera Panel служит для переключения между камерами и настройки текущей камеры. Rendering Debug Panel требуется для отображения содержимого буферов рендеринга так же, как при использовании Draw Mode в редакторе Unity. Navigation Panel используется для быстрой настройки и переключения между пресетами скорости камеры, а также для изменения положения камеры. Панель Helpers обеспечивает быстрый доступ к вспомогательным визуализаторам, таким как значки, гизмо и каркасы. Навигация внутри Editor Viewport почти такая же, как и в Scene View Unity. Подробнее ознакомиться с навигацией по сцене можно, просмотрев видео ниже (либо прочитав соответствующий раздел в документации): Есть русские субтитры Переключатель Precompile All Shaders (предварительная компиляция всех шейдеров) используется для принудительной компиляции шейдеров; Переключатель Animation (анимации); Переключатель Physics (физики); Переключатель Audio (звука); Кнопка Play для управления воспроизведением. В режиме воспроизведения Game View редактора Unity рендерит финальную сцену с одной или нескольких камер. В UNIGINE кнопка Play используется для запуска экземпляра приложения в отдельном окне. Также есть возможность переключения между режимами воспроизведения для изменения его основных параметров. Так, например, можно включить режим VR, чтобы обеспечить совместимость с одной из поддерживаемых гарнитур виртуальной реальности. Engine Viewport в UNIGINE (аналог Game View), используемый для отладки и оценки производительности, считается избыточным для проектов, разрабатываемых на C# .NET 5. Однако, его можно использовать в других проектах. Как в Unity, так и в UNIGINE есть консоль для стандартного ввода, вывода и регистрации ошибок. Также существует набор консольных команд, позволяющих совершать определенные операции. Консоль доступна как в UNIGINE Editor, так и в работающем приложении. Чтобы открыть окно консоли в редакторе, перейдите в меню Windows -> Console: Во время работы приложения встроенная консоль запускается нажатием кнопки «Тильда» (~). Во встроенную консоль можно выводить сообщения из кода. Так же как и Unity Editor, UNIGINE Editor позволяет выполнить подготовку финальной сборки проекта. Проект в UNIGINE, как и проект на Unity, хранится в отдельной папке, настройки проекта хранятся в файле с расширением *.project. В папке проекта есть различные подпапки с контентом и исходным кодом приложения. Также тут хранятся папки с файлами конфигурации и исполняемыми файлами. Наиболее важные подпапки: data (данных) и source (исходного кода). Каждый проект UNIGINE обязательно включает в себя папку data. Как и в папке Assets проекта на Unity, здесь хранятся ресурсы вашего проекта. Для импорта ассетов достаточно перетащить файлы в папку data — они автоматически импортируются и станут доступны в Asset Browser. Ассеты в UNIGINE Editor будут автоматически обновляться при внесении изменений в соответствующие файлы. Соответствие содержимого папки data в корневой директории проекта и в Asset Browser Unity поддерживает широкий спектр форматов файлов, в то время как UNIGINE поддерживает большинство наиболее популярных, а также ряд специфических: Тип ассетов Поддерживаемые форматы Геометрия .fbx, .obj, .3ds, .dae, .glb/.gltf, .stp/.step, .igs/.iges, .brep, .stl Текстуры .png, .jpeg, .tif, .tga, .rgba, .psd, .hdr, .dds, and more Звук и видео .wav, .mp3, .oga/.ogg, .ogv Шрифты .ttf Меши. Ассеты в формате FBX могут быть легко импортированы из Unity в UNIGINE без искажения масштаба. Подробнее про импорт FBX-моделей читайте здесь. Материалы. Так же как и Unity, UNIGINE работает с PBR-материалами (Physically Based Materials) и поддерживает Metalness и Specular workflow. Материалы, созданные в Unity, можно воссоздать в UNIGINE, благодаря встроенной богатой библиотеке материалов, а также возможности визуально создавать и редактировать материалы в Visual Material Editor. Текстуры. Текстуры можно импортировать либо как часть модели, либо отдельно, а затем назначать их мешу. Но иногда может потребоваться предварительная подготовка. Например, Shading-текстура в UNIGINE хранит карты Metalness, Roughness, Specular и Microfiber в соответствующих каналах. Поэтому сначала нужно изменить Shading-текстуру с помощью GIMP или Photoshop, а затем импортировать ее в UNIGINE. А перед импортом Normal-текстуры нужно инвертировать канал G с помощью соответствующей настройки при импорте. Анимации. Модель со скелетной анимацией, которую вы использовали в проекте Unity, может быть импортирована в UNIGINE, если она хранится в формате FBX. При импорте такой модели, включите опцию Import Animations (импорт анимаций) и настройте дополнительные параметры. Подробнее про импорт разных ассетов читайте здесь. Концепция сцены в обоих движках одинакова. Однако Unity и UNIGINE используют разные системы координат. Unity UNIGINE Unity использует левостороннюю систему координат, в которой вертикальное направление представлено осью +Y. 1 юнит равен 1 метру. Оси и направления:X — вправо (+), влево (-)Y — вверх (+), вниз (-)Z — вперед (+), назад (-)Положительный угол поворота задает вращение по часовой стрелке.Формат файла: *.scene UNIGINE использует правостороннюю систему координат, в которой вертикальное направление представлено осью +Z. 1 юнит равен 1 метру. Оси и направления: X — вправо (+), влево (-) Y — вперед (+), назад (-) Z — вверх (+), вниз (-) Положительный угол поворота задает вращение против часовой стрелки. Формат файла: *.world Как в Unity, так и в UNIGINE, сцена формируется из базовых объектов. С их кратким описанием, а также основными сходствами и различиями можно ознакомиться ниже. Unity UNIGINE Окно Hierarchy Окно World Nodes Базовый объект сцены — GameObject. Базовый тип, от которого наследуются все типы объектов сцены — Node. Некоторые имеют визуальное представление: Objects, Decals и Effects. У каждого из них есть поверхности для представления своей геометрии (меши). Остальные — Light Sources, Players и др. — невидимы. GameObjects являются контейнерами для всех остальных компонентов. Компоненты определяют функционал GameObject. Базовая функциональность ноды определяется ее типом. Дополнительные функции можно добавлять с помощью свойств и компонентной системы. По умолчанию каждый GameObject имеет компонент Transform. У каждой ноды есть матрица преобразования, которая задает ее положение, поворот и масштаб в пространстве. GameObjects могут быть организованы в иерархию типа родитель-потомок. Ноды могут быть организованы в иерархию типа родитель-потомок. Важно. Все объекты, добавляемые в сцену, независимо от их типа, называются нодами. Процесс создания сцены в Unity основан на префабах. Обычно вы собираете сложный объект из GameObjects с определенными компонентами и свойствами и создаете префаб из такого объекта. Затем префабы могут быть размещены в сцене посредством редактора или созданы во время выполнения приложения. Создание сцены в UNIGINE основано на Node Reference, которые очень похожи на префабы. Чтобы создать сложный объект, экземпляры которого затем будут многократно использоваться в сцене, достаточно построить нужную иерархию из нод, назначить им материалы и свойства, а затем сохранить ее как Node Reference. Так же, как и в случае с префабами, вы в любой момент сможете изменить Node Reference, просто изменив любой из ее экземпляров. Подробнее про создание Node Reference и управление смотрите видео ниже (или читайте в документации): Есть русские субтитры В Unity Editor для разрешения конфликтов, возникающих при слиянии рабочих копий проекта, используется инструмент Smart Merge. Также редактор позволяет применять пользовательские инструменты для тех же целей. Для успешного объединения, сцены и другие файлы должны быть в формате YAML. В UNIGINE все исходные форматы файлов по умолчанию являются текстовыми, поэтому вы можете использовать любую привычную систему контроля версий и объединять миры, ноды и другие ассеты. Файловую систему можно расширять с помощью Mount Points, которые позволяют добавлять в проект любые внешние ресурсы, находящиеся в совместном доступе. Кроме того, стандартный подход к работе над проектом заключается в разделении работы разных членов команды с помощью отдельных Node Layers. Это позволяет избежать необходимости разрешения конфликтов при слиянии изменений. Подробнее про совместную работу над проектом читайте здесь. Камеры в Unity и UNIGINE устроены немного по-разному. В Unity компонент Camera отвечает за захват изображения и отправку его на отрисовку. Все включенные камеры, присутствующие в сцене, визуализируются в окне просмотра (Game View) и могут перекрывать друг друга. Для переключения между камерами обычно нужно отключить текущую камеру и включить другую. В UNIGINE камера — это объект, связанный с рендерингом и представленный нодами Player в мире. Для упрощения создания наиболее часто используемых камер, управляемых с помощью устройств ввода (клавиатура, мышь, джойстик), предусмотрено несколько типов Node Player с различным поведением: Dummy — простая статическая камера, которая может быть усовершенствована с помощью пользовательских доработок. Spectator — камера свободного перемещения. Persecutor — камера, которая следует за целевым объектом и может свободно вращаться вокруг него на заданном расстоянии. Это готовое решение для создания камеры от третьего лица. Actor — камера с твердым физическим телом капсульной формы, которая может взаимодействовать с окружением. Это готовое решение для создания вида от первого лица, схожее с Unity Character Controller. Одновременно Editor Viewport показывает вид только с одной камеры. Переключаться между камерами можно с помощью Camera Panel: Чтобы в режиме воспроизведения (когда нажата кнопка Play) определенная камера использовалась по умолчанию, нужно установить флажок Main Player в ее настройках. Настройка общих параметров проекта в Unity Editor обычно выполняется через окно настроек проекта (меню: Edit -> Project Settings). Аудио, графика, физика, уровни качества и другие настройки влияют на весь проект. В UNIGINE общие настройки доступны вменю Windows -> Settings в разделе Runtime. Настройки мира задаются для каждого мира отдельно. В Unity Editor асинхронная компиляция шейдеров включается и выключается в настройках редактора (меню: Edit -> Project Settings -> Editor -> Shader Compilation). В UNIGINE аналогичная функция редактора называется Forced Shader Compilation. Она доступна как через панель инструментов, так и через раздел Editor окна Settings. Вы используете пресеты в редакторе Unity, когда вам нужно повторно использовать настройки свойств, относящиеся к различным задачам, будь то настройки компонентов, настройки импорта или, в особенности, настройки проекта (Project Settings). Вы можете сохранить настройки для определенного раздела Project Settings в качестве *.preset ассета и использовать его в процессе разработки. UNIGINE позволяет сохранять и загружать пресеты для общих настроек физики, звука и рендеринга. Пресеты хранятся в виде ассетов с расширениями *.physics, *.sound и *.render соответственно. Для загрузки и сохранения пресетов используются кнопки Load и Save в соответствующем разделе настроек окна Settings. Сохраненные ассеты отображаются в Asset Browser. Вы можете загрузить настройки рендеринга, дважды щелкнув необходимый ассет с расширением .render. В UNIGINE пресеты доступны не только в редакторе. Вы можете использовать классы Physics, Sound и Render для управления пресетами соответствующих настроек — например, для переключения между уровнями качества во время выполнения приложения. В Unity Editor настройки качества графики в основном собраны в следующих разделах: Раздел Graphics содержит глобальные настройки графики. Настройки уровня (Tier Settings) обеспечивают платформенно-ориентированную настройку рендеринга и компиляции шейдеров. Уровень определяется автоматически в зависимости от используемой платформы. Раздел Quality обрабатывает уровни графического качества, заданные для каждой платформы. В UNIGINE настройки рендеринга мира можно найти в разделе Rendering окна Settings. Также есть возможность включать и выключать самые распространенные функции рендеринга с помощью соответствующего меню: В UNIGINE нет платформенно-зависимых настроек качества, поэтому для управления уровнями качества необходимо написать свою собственную логику. Для этой цели можно использовать пресеты рендеринга (Render Presets). Рассмотрим наиболее часто используемые настройки рендеринга в Unity и соответствующие им аналоги в UNIGINE: Unity UNIGINE HDR Mode Render -> Buffers -> Color 16F Rendering Path см. ниже Shaders Preloading Render -> Streaming -> Preload at World Loading Pixel Light Count Forward Per-Object Limits Texture Quality Render -> Textures -> Quality Anisotropic Textures Render -> Textures -> Anisotropy Anti Aliasing Render -> Antialiasing -> Supersampling Soft Particles particles_base -> Soft Interaction Realtime Reflection Probes Меню: Rendering -> Dynamic Reflections -> Enabled Texture Streaming Render -> настройки Streaming Shadows Render -> настройки Shadows Shadow Cascades устанавливается для каждого источника World Light VSync Count Runtime -> настройки Video В Unity существует два способа рендеринга: Deferred (отложенный) и Forward (прямой) рендеринг. Они определяют точность шейдинга, а также потребление ресурсов при рендеринге и необходимое аппаратное обеспечение. Способ рендеринга можно выбрать в окне Graphics для каждой камеры. UNIGINE имеет фиксированную последовательность рендеринга, представленную комбинацией полного отложенного рендеринга с методами упреждающего рендеринга: Вся непрозрачная геометрия отрисовывается в отложенном проходе (Deferred). Прозрачная геометрия отрисовывается во время прямого прохода (Forward). Вы можете уменьшить вычислительную нагрузку, пропустив определенные этапы рендеринга. Посмотрите специальный видеоурок по использованию инструмента Microprofile для оптимизации рендеринга: В Unity доступность эффектов постобработки определяется используемым конвейером рендеринга. В UNIGINE подобные эффекты не являются частью постобработки, а интегрированы в процесс рендеринга. Таким образом, Unity High Definition Render Pipeline (HDRP) наиболее приближен к процессу рендеринга в UNIGINE по сравнению с другими конвейерами рендеринга. В Unity для определения объемов, в которых параметры и эффекты постобработки локально (или глобально) переопределяются, используется фреймворк Volume. В UNIGINE для плавной перехода между эффектами в различных областях необходимо написать собственную логику. Unity UNIGINE Методы сглаживания: FXAA TAA SMAA MSAA Методы сглаживания: Fast approXimate Anti-Aliasing (FXAA) Temporal Anti-Aliasing (TAA) Subpixel Reconstruction Anti-Aliasing (SRAA) Supersampling Ambient Occlusion Screen-Space Ambient Occlusion Auto Exposure Эффекты камеры: Adaptive Exposure White Balance Tone Mapping Bloom Lens Dirt White Balance Tonemapping Bloom Цветокоррекция: Tone Lookup Texture Color Correction Color Correction LUT Chromatic Aberration Материалы постобработки: post_color_correction Grain Deferred Fog Haze Depth of Field Depth of Field Motion Blur Motion Blur Screen Space Reflection SSR (Screen Space Reflections) Contact Shadows Screen Space Shadows Micro Shadows Cavity of SSAO (Screen Space Ambient Occlusion) Материал получился объемный, но это лишь первый, обобщенный выпуск из запланированных трех по миграции с Unity. Следующий выпуск будет более специализированным и расскажет про миграцию на UNIGINE с точки зрения 3D-художника. А в последнем разберем все важные моменты по этому вопросу для программистов. Чтобы получить доступ к бесплатной версии UNIGINE 2 Community заполните форму на нашем сайте. Все комплектации UNIGINE: Community — базовая версия для любителей и независимых разработчиков. Достаточна для разработки видеоигр большинства популярных жанров (включая VR). Engineering — расширенная, специализированная версия. Включает множество заготовок для инженерных задач. Sim — максимальная версия платформы под масштабные проекты (размеров планеты и даже больше) с готовыми механизмами симуляции. Подробнее о комплектациях и ценах Пользователь',\n",
              " 'Проведенный нами тест NVIDIA A4000 почти подтвердил, что она способна вытянуть на энкодинге до 16 независимых видеопотоков FullHD в формате H264. Удастся ли кратно увеличить производительность с профессиональной видеокартой, которая стоит в два раза дороже? Попробуем проверить. В нашей второй статье про энкодинг (с тестом А4000) мы упустили, что видеопоток бывает и большего разрешения, поэтому стоит протестировать энкодинг файлов в формате 4К. Для полноты картины мы также сравним энкодинг на решениях от NVIDIA с встроенным GPU от Intel. Некоторые профессионалы полагают, будто достаточно собрать тот же FFmpeg с включенным QuickSync и внешняя видеокарта станет не нужна. Проверим и это утверждение. Мы не будем подробно расписывать процесс тестирования для видеокарт от NVIDIA и зачем нам FFmpeg, поскольку информация об этом есть в предыдущих статьях (первая и вторая части). Лучше сосредоточимся на новых результатах и полезных лайфхаках. Используем тот же самый тестовый стенд из имеющихся в наличии серверов HOSTKEY, но установим в него видеокарту NVIDIA A5000 с большим количеством блоков энкодинга, 24 ГБ видеопамяти и более высоким энергопотреблением. Для начала проверим ее работу на количестве потоков, оказавшемся предельным для А4000 по результатам предыдущего теста:14 потоков gpu pwr gtemp mtemp sm mem enc dec mclk pclk fb bar1 Idx W C C % % % % MHz MHz MB MB 0 97 47 - 92 3 100 0 7600 1920 3502 33 frame=1015 fps=31 q=28.0 Lsize= 9056kB time=00:00:33.80 bitrate=2194.8kbits/s speed=1.02x Удивительно! Мы получили сравнимые с результатом A4000 цифры. Несмотря на большую частоту работы чипа, больший объем используемой видеопамяти и большее энергопотребление, A5000 осилила энкодинг только 14 потоков и спасовала на пятнадцатом. Это фиаско еще раз доказывает, что профессиональные видеоадаптеры предназначены для других целей. Теперь попробуем запустить трансляцию потока с разрешением 3840x2160 (оно же 4K), благо есть и такая версия файла про кролика. Энкодинг силами только центрального процессора захлебнулся уже на одном потоке, когда объем данных кратно увеличился: frame= 2902 fps=27 q=29.0 size=104448kB time=00:01:33.56 bitrate=9144.7kbits/s dup=436 drop=0 speed=0.878x Каковы возможности GPU (помним, результаты у A4000 и A5000 сравнимы)? Это 3 потока. gpu pwr gtemp mtemp sm mem enc dec mclk pclk fb bar1 Idx W C C % % % % MHz MHz MB MB 0 96 46 - 100 3 96 0 7600 1920 1112 9 Как видим, по потребляемой мощности и загрузке блоков энкодинга видеочип работает явно не в режиме повышенного комфорта, хотя при этом расходуется лишь около 1 ГБ видеопамяти.Вывод FFmpeg подтверждает, что видеокарта справляется: frame= 1465 fps=33 q=35.0 Lsize=12584kB time=00:00:48.80 bitrate=2112.4kbits/s dup=159 drop=0 speed=1.09x А вот 4 потока адаптер уже не переваривает. Хотя загрузка железа остается примерно на тех же значениях, начинаются просадки по кадрам: frame= 614 fps= 26 q=35.0 Lsize=4978kB time=00:00:20.43 bitrate=1995.6kbits/s speed=0.858x Если верить заявлению компании-разработчика, технология QuickSync должна «используя специальные возможности обработки мультимедийных данных графических технологий Intel® для ускорения декодирования и кодирования, позволить процессору параллельно выполнять другие задачи и повышая быстродействие системы». Для тестов понадобился подходящий процессор Intel (мы нашли машину с Core i9-9900K CPU @ 3.60GHz) и собранная с поддержкой Quick Sync утилита FFmpeg. С первым проблем не возникло (достаточно чипа старше 6-го поколения и наличия в нем GPU, что несложно проверить), но сборка FFmpeg под тестовую Ubuntu 20.04 вызвала стойкие ассоциации с практическим освоением Камасутры. Чтобы не заставлять вас тратить драгоценное время, опишем, как нам удалось решить проблему.Поскольку пакеты в репозиториях сломаны, первым делом нужно собрать и установить в систему библиотеки gmmlib и libva, а также последние версии Intel media driver и Media SDK. Для этого в домашней директории создадим папку GIT, зайдем в нее и выполним последовательно следующие команды (если будет не хватать каких-то зависимостей, установим их из репозитория; мы рекомендуем сделать sudo apt install autoconf automake build-essential cmake pkg-config): Затем нужно собрать FFmpeg с помощью нескольких магических команд: Стоит убедиться, что у нас появилась поддержка Quick Sync: Вывод команды должен быть примерно таким: Ура! Все готово к тестам. Для начала проверим, как справляется с энкодингом видео в FullHD процессор без Quick Sync: он выдерживает максимум 4 потока, при которых все ядра загружены под 100% frame= 1461 fps= 33 q=29.0 size=24064kB time=00:00:46.33 bitrate=4254.7kbits/s speed=1.05x Пятый поток процессор уже не осиливает, поэтому можно смело приступать к тесту с Quick Sync. В скрипте из предыдущей статьи для этого нужно будет заменить энкодер на h264_qsv, и он примет следующий вид (подробнее об использовании QuickSync с FFmpeg можно почитать тут): Сразу делаем проверку на 6 потоках (+2 к тесту на чистом CPU): frame=291 fps=55 q=29.0 size=1280kB time=00:00:10.13 bitrate=1034.8kbits/s dup=2 drop=0 speed=1.93x Разница очевидна: загрузка процессора не превышает 50%, а имеющийся запас вычислительных ресурсов позволяет прогнозировать 11 – 12 итоговых потоков.Ставим 11 потоков: frame=157 fps=30 q=38.0 Lsize=628kB time=00:00:05.69 bitrate=903.0kbits/s dup=2 drop=0 speed=1.09x Загрузка процессора возрастает незначительно, но GPU уже подходит к пределу возможностей. Двенадцатый поток роняет битрейт и скорость обработки до 24 – 28 кадров.Теперь проверяем потоки в 4K. В отличие от AMD, наш процессор Intel спокойно обрабатывает один поток в таком разрешении и без аппаратного ускорения:frame=655 fps=31 q=-1.0 Lsize=30637kB time=00:00:21.73 bitrate=11547.9kbits/s speed=1.03xНа большее он, увы, не способен. С включенным Quick Sync тестовый компьютер смог вытянуть три потока с разрешением 4K:frame= 509 fps=31 q=33.0 Lsize=8010kB time=00:00:17.42 bitrate=3764.7kbits/s dup=2 drop=0 speed=1.07xСпасовал он только на четвертом, но столько же у нас выдержала и видеокарта Nvidia A5000. Недостатки у решения, увы, тоже есть. При использовании модуля BMC (к примеру, при управлении машиной через IPMI), вы не получите доступ ко всем возможностям аппаратного ускорения, даже если GPU процессора будет определяться в системе. Придется выбирать между удобством удаленного управления или получением всех плюсов от использования Quick Sync. Выводы вы можете сделать самостоятельно. Мы лишь отметим, что для энкодинга видео разница в мощности видеокарт не всегда определяется их ценой, а для решения некоторых задач стоит обратить внимание на специализированные технологии внутри центральных процессоров. Также мы использовали для тестов H264, но кодеки HEVC (H265) или VP1 в теории должны дать лучшие результаты, особенно на разрешениях 4K. Если вы самостоятельно проведете подобные тесты с первым (VP1 пока что представлен аппаратно и массово только для декодинга), поделитесь результатами в комментариях. ____________ Стоимость описанных выше экспериментов измерить просто: воспользуйтесь нашим калькулятором-конфигуратором на этой странице. Например, в самой простой конфигурации она следующая: машина с A4000 обойдется в 22 000р, 12 потоков - 1800р на поток в месяц; машина с A5000 обойдется в 31 000р, 14 потоков - 2214р на поток в месяц; сервер на i9-9900K с QuickSync (QSV) обойдется в 5000-6000р, 11 потоков, 450р на поток. Серверы для такого необходимо собирать на материнских платах без удаленного управления, что мы умеем. Обращайтесь! Кстати, все серверы HOSTKEY предоставляются с нашим модулем полного удаленного управления сервером IPMI и панелью управления серверами и API. Об устройстве последней мы рассказали в этой статье. Пользователь',\n",
              " 'Привет! Перевод пятой лекции о создании Super Mario Bros. В этом видео: Тайловые карты. 2D-анимация. Процедурная генерация уровней. Физика платформера. Пользователь',\n",
              " 'Профессиональные GPU в серверах позиционируются как устройства для высокопроизводительных вычислений, систем искусственного интеллекта и рендеринговых ферм для 3D-графики. Стоит ли их применять для энкодинга, или это стрельба из пушки по воробьям? Попробуем разобраться. Для работы с многопоточным видео достаточно мощностей современных CPU и решений наподобие Intel Quick Sync. Более того, некоторые специалисты считают, будто загрузка профессиональных GPU декодингом и энкодингом — пустая трата ресурсов. Для потребительских видеокарт количество входящих потоков специально ограничивают до двух-трех, хотя мы уже убедились, что небольшое шаманство с драйвером позволяет это ограничение обойти. В предыдущей статье тестировались бытовые видеокарты, а сейчас мы займемся более серьезными — NVIDIA RTX A4000. Что делать, если вывод lscpu выдает вам что-то вроде AMD Ryzen 9 5950X 16-Core Processor, но в компьютер вставлена NVIDIA RTX A4000 с 16 ГБ оперативной памяти, а вы хотите перекодировать и записать поток с нескольких сетевых камер? Информация с них обычно поступает через http, rtp или rtsp, и наша задача — поймать эти потоки, перекодировать их в нужный формат и записать каждый в отдельный файл. Для проверки мы в HOSTKEY создали небольшой тестовый стенд из имеющихся выделенных серверов с указанной выше конфигурацией CPU/GPU без специальной оптимизации и 32 ГБ оперативной памяти. На нем через FFmpeg мы будем принимать мультикаст-вещание в форматах http и rtsp (использован видеофайл bbb_sunflower_1080p_30fps_normal.mp4 из деморепозитория Blender), декодировать его в разном количестве потоков FFmpeg и записывать каждый из них в отдельный файл. Как видно из названия, мы принимаем поток в формате 1080p (30 кадров в секунду). Энкодинг будет применяться только к видео, а звуковые потоки пойдут без изменения. Также несущественно, берем мы один входящий поток и имитируем его мультипоточность или параллельно обрабатываем несколько потоков. Работа с сетью и текущие процессы на тестовом стенде отнимают менее 1% ресурсов CPU, поэтому можно считать, что основную нагрузку на процессор и дисковую подсистему даст именно энкодинг. Все дальнейшее повествование будет вестись для вещания через http, поскольку результаты для потока rtsp оказались сравнимыми. Чтобы не плодить множество консолей терминала на сервере, для теста были созданы простые bash-скрипты, в которые при запуске передается требуемое количество инстансов FFmpeg, перекодирующих видеопоток в h264. Энкодинг на голом CPU: На GPU мы будем использовать возможности видеокарты через NVENC (как собрать FFmpeg с его поддержкой, мы рассказывали в первой статье цикла): Скрипты запускают в цикле мультикаста и ловят в сети нашего кролика. Предварительно стоит проверить через тот же vlc или ffplay, что поток реально вещается. Результат мы будем оценивать по загрузке CPU/GPU, утилизации памяти и качеству записываемого видео, где главными для нас будут два параметра: fps (он должен быть стабильным и не опускаться ниже 30 кадров в секунду) и speed (показывает, успеваем ли мы обрабатывать видео на лету). Для realtime параметр speed должен быть больше 1.00x. Проседания этих двух параметров приводят к выпадению кадров, артефактам, проблемам кодировки и другим повреждениям картинки, которые не хотелось бы видеть на записях с камер видеонаблюдения. Запуск одной копии FFmpeg дает нам такую начальную картину: Загрузка по ядрам процессора в среднем на уровне 18–20%, а вывод FFmpeg показывает следующее: Запас есть, и можно попробовать сразу три потока: Четыре потока выбирают почти все мощности CPU и «отъедают» 13 ГБ оперативной памяти. При этом вывод FFmpeg показывает, что резервы не исчерпаны: Увеличиваем количество потоков до пяти. Процессор держится на пределе, местами начинаются просадки скорости кадров и битрейта на 5–10%: Запуск шести потоков показывает, что предел достигнут. Мы все больше и больше отстаем от реального времени и начинаем пропускать кадры: Запускаем один поток FFmpeg с энкодингом через h264_nvenc. Убеждаемся через вывод nvidia-smi, что у нас задействована именно видеокарта: Поскольку вывод достаточно громоздкий, мы будем отслеживать параметры GPU с помощью следующей команды: Расшифруем обозначения: pwr — потребляемая видеокартой мощность в ваттах; gtemp — температура видеоядра (в градусах Цельсия); sm — SM, mem — память, enc — энкодер, dec — декодер (утилизация их ресурсов указана в процентах); mclk — текущая частота памяти (в МГц), pclk — текущая частота процессора (в МГц); fb — использование кадрового буфера (в Мб). gpu pwr gtemp mtemp sm mem enc dec mclk pclk fb bar1 Idx W C C % % % % MHz MHz MB MB 0 35 48 – 1 0 6 0 6500 1560 213 5 Нас в этом выводе будут интересовать значения загрузки энкодеров GPU и утилизации видеопамяти. Вывод FFmpeg дает следующие результаты: Запускаем сразу пять потоков. Как видно из вывода htop, в случае энкодинга на GPU загрузка процессора минимальна, а большая часть работы ложится именно на видеокарту. Дисковая подсистема также загружена гораздо меньше. gpu pwr gtemp mtemp sm mem enc dec mclk pclk fb bar1 Idx W C C % % % % MHz MHz MB MB 0 36 48 – 8 2 40 0 6500 1560 1035 14 Загрузка блоков энкодинга увеличилась до 40%, память мы заняли почти на гигабайт, но видеокарта по факту загружена не сильно. Вывод FFmpeg подтверждает это, показывая, что у нас есть ресурсы для увеличения количества потоков минимум в 2 раза: Ставим десять потоков. Утилизация CPU на уровне 15–20%. Параметры видеокарты: gpu pwr gtemp mtemp sm mem enc dec mclk pclk fb bar1 Idx W C C % % % % MHz MHz MB MB 0 55 48 – 14 4 61 0 6500 1920 2064 24 Потребление электроэнергии возросло, видеокарта вынуждена была разогнать частоту видеоядра, но мощности энкодинга и видеопамять позволяют увеличивать нагрузку. Проверяем вывод FFmpeg, чтобы в этом убедиться: Пробуем добавить еще четыре потока и получаем загрузку блоков энкодинга в 100%. gpu pwr gtemp mtemp sm mem enc dec mclk pclk fb bar1 Idx W C C % % % % MHz MHz MB MB 0 68 59 – 18 7 100 0 6500 1920 2886 33 Вывод FFmpeg подтверждает, что мы достигли предела. Утилизация CPU при этом все еще не превышает 20%. Контрольные 15 потоков показывают, что GPU начинает сдавать, так как блоки энкодинга работают с перегрузкой, а также наблюдается рост температуры и потребляемой мощности. gpu pwr gtemp mtemp sm mem enc dec mclk pclk fb bar1 Idx W C C % % % % MHz MHz MB MB 0 70 63 – 18 7 100 0 6500 1920 3092 35 FFmpeg также подтверждает, что видеокарте становится тяжеловато. Частота обработки и пропуск кадров уже не внушают оптимизма: Подытожим: применение GPU в такой конфигурации можно назвать оправданным, поскольку максимальное количество обрабатываемых видеокартой потоков в 3 раза превышает возможности далеко не самых слабых процессоров (особенно без поддержки технологий аппаратного кодирования). С другой стороны, мы используем только минимальную часть возможностей видеоадаптера. Поскольку остальные его блоки и видеопамять не сильно нагружены, ресурсы дорогостоящего устройства утилизируются неэффективно.Искушенные читатели могут заметить, что мы не проверили работу в режимах 2K/4K, не использовали возможности современных кодеков (наподобие h265 и VP8/9), а также установили в тестовый стенд видеоадаптер на архитектуре предыдущего поколения. Тот же A5000 должен показать лучший результат: его работу мы проверили в следующей статье, где немного препарировали и Intel Quick Sync. Оправдались ли надежды, можно узнать здесь. Напишите в комментариях, какие еще нюансы стоит учесть при тестировании, какие моменты мы упустили и что бы вы хотели узнать по этой теме. Стоимость описанных выше экспериментов измерить просто: можно воспользоваться нашим калькулятором-конфигуратором на этой странице. На, например, современных Xeon она следующая: машина с A4000 в самой простой конфигурации обойдется в 22000р, 12 потоков - 1800р на поток в месяц; машина с A5000 в самой простой конфигурации обойдется в 31000р, 14 потоков - 2214р на поток в месяц; сервер на i9-9900K в самой простой конфигурации с QuickSync (QSV) обойдется в 5000-6000р, 11 потоков, 450р на поток. Серверы для такого необходимо собирать на материнских платах без удаленного управления, что мы умеем. Обращайтесь! Кстати, все серверы HOSTKEY предоставляются с нашим модулем полного удаленного управления сервером IPMI и панелью управления серверами и API. Об устройстве последней мы рассказали в этой статье. Пользователь',\n",
              " 'В виду того, что мне срезали подписку на Medium решил поддерживать отечественные IT ресурсы. Попробую кидать интересные статьи с переводом на русском, а правообладатели пусть сами разбираются, я честно платил за подписку. На текущий момент VS Code остается средой разработки, которая доступна в период санкций, когда JetBrains отказался продавать лицензии, про Visual Studio даже не узнавал. Сам использую VS Code много лет в разных стеках. VS Code предоставляет возможности разработки практически во всех направлениях: веб-разработка, мобильные приложения, часто встречаются приложения для встраиваемых систем. Ниже перечислены наиболее популярные расширения, которые облегчают разработку приложений. Atom One Dark Theme При всем изобилии тем в VS Code тема Atome One Dark наиболее популярная, потому-что имеет наиболее удачный контраст и прекрасно выглядит. Установка ext install akamud.vscode-theme-onedark VSCode Great Icons Популярное расширение для иконок. Кому как красивее и удобнее решайте сами. Установка ext install emmanuelbeziat.vscode-great-icons Hungry Delete Очень простое, но очень полезное расширение. Помогает при удалении нескольких пустых строк. Позволяет удалить все пустые строки клавишами Ctrl-Backspace для Windows, Linux и Alt+Backspace для Mac. Чтобы удалить строки снизу служит комбинация клавиш Ctrl+]. Поддерживает удаление в режиме мультикурсор. Функция Smart Backspace позволяет выравнивать код при нажатии клавиши Backspace. ext install jasonlhy.hungry-delete Live Server Простое и удобное расширение для веб-разработки. Позволяет запускать статические веб-страницы в режиме локального сервера. Поддерживается перезагрузка страниц при изменении исходных файлов. Поддерживает команды контекстного меню в Проводнике и в редакторе кода. ext install ritwickdey.LiveServer TabOut Расширение, похожее на Hungry Delete, но в отличии от него запускается через меню команд. ext install albert.TabOut Если вы никогда не использовали сниппеты, стоит о них подумать, они делают нашу жизнь легче и упрощают работу с часто используемыми блоками. Сниппеты - небольшие преднастроенные строки, которые позволяют заполнять большие куски кода. Удобно использовать в React компонентах, где большое количество повторяемого шаблонного кода. Установка React сниппетов ext install runningcoder.react-snippets Список расширений, который может заинтересовать Vim - эмулятор Vim редактора в VS Code. Auto Close Tag - автоматически добавляет закрывающие теги для HTML/XML. Git Graph - визуальное представление для веток Git репозитория. Проще один раз увидеть. Таблица горячих клавиш для VS Code Кидайте в комментарии расширения, которые используете вы... Пользователь',\n",
              " 'В этой статье я покажу простой способ генерации видео программами на Python и C/C++ без использования стороннего API. Вам так же потребуется ffmpeg, без него вы не сможете конвертировать файлы в читаемые форматы! Можно экспериментировать, например вы можете создать видео максимального качества и проверять как оно будет эффективно сжиматься тем или иным видео кодеком. Можете даже создать картинку с градиентом в 64-битном цвете и с дизерингом, мало ли какие ещё извращения можно придумать. Можно ещё делать видео с быстро движущимися объектами и сохранять его в 1000 кадров в секунду и потом тестировать всякие интерполяторы движения и моушн блюры. С помощью скрипта на Python можно создать видео. Просто сохраните этот код в какой-нибудь \"main.py\" Далее исполняете команду в консоли: python main.py | ffmpeg -y -f rawvideo -pixel_format gray -video_size 320x240 -framerate 25 -i pipe: out.mkvВ результате у вас получится двухсекундное видео с узором out.mkv. В командную строку в Windows и Linux можно выводить не только текст, но и бинарные данные файлов, а так же эти данные можно перенаправлять в другую программу, в данном случае это ffmpeg который принимает RAW кадры и конвертирует их в видео. И в коде и в команде вызова должны совпадать fps/framerate и video_size/w/h иначе всё разъедется. Нельзя просто взять и написать данные пикселей в консоль через print, нужно записывать их в stdout как в файл через os.write. Если в коде изменить duration на 1, то создастся только один кадр с узором и его можно сохранить как картинку так:python main.py | ffmpeg -y -f rawvideo -pixel_format gray -video_size 320x240 -i pipe: out.png Конечно Питон это медленно и я покажу как сделать это на C и C++, в этих языках стандартный поток вывода stdout тоже считается файлом и в него можно записывать бинарные данные. Сборка и запуск:g++ -Wall -O2 main.cpp -o progprog | ffmpeg -y -f rawvideo -pixel_format gray -video_size 320x240 -framerate 25 -i pipe: out.mkv Сборка и запуск::gcc -Wall -O2 main.c -o progprog | ffmpeg -y -f rawvideo -pixel_format gray -video_size 320x240 -framerate 25 -i pipe: out.mkv Упрощённый вариант от @staticmain: Cборка и запуск:gcc -Wall -O2 main.c -o progprog | ffmpeg -y -f rawvideo -pixel_format gray -video_size 320x240 -framerate 25 -i pipe: out.mkv Я специально не указывал выходной видео кодек для упрощения команд, но вы можете добавить в ffmpeg опции -vcodec libx264rgb -crf 0 для сохранения видео в lossless качестве. Если вы модернизируете программу и добавите в неё поддержку RGBA цвета, то помните что h264 не умеет сохранять прозрачность в кадрах и вам лучше использовать кодек FFV1. Можно сгенерировать видео на любом языке программирования, если на нём можно переключить стандартный вывод в бинарный режим. По такой же логике можно и перенастроить поток ввода stdin в бинарный режим и передать в программу бинарные данные из ffmpeg, таким образом можно будет смастерить видео-фильтр. В общем надо сделать что-то типа того:ffmpeg | фильтр | ffmpeg. Вообще можно просто написать Frei0r фильтр на Си и использовать его в ffmpeg, но мой способ просто не требует никакого стороннего API. Поток можно перенаправлять и в файл и потом этот файл скармливать ffmpeg\\'у, но учтите что видео будет совсем без сжатия и несколько секунд видео 1280x720 будут весить гигабайты. Сделать это можно так:prog > video.datfmpeg -y -f rawvideo -pixel_format gray -video_size 320x240 -framerate 25 -i video.dat out.mkv Раз можно сгенерировать сырое видео, то можно и создать сырой PCM звук и конвертировать его в аудио форматы. Можно например генерировать мелодии и сохранять их в pcm_s16le поток. Опять же переключив stdin в pipe режим вы можете получать аудио поток извне, обрабатывать его своей программой и передавать далее, таким образом у вас получится аудио фильтр и не надо никакого VST/LADSPA API. Это очень простой способ создания видео (для программиста). Если что, в ffmpeg уже встроены некоторые генераторы тестовых видео. Сохраняются ли гигабайты сырых кадров в оперативной памяти при использовании такого способа передачи или же на диске - мне это неизвестно, возможно что у такого способа есть какие-то ограничения на размер передаваемых данных. Помните что в передаваемом потоке данных нет никаких меток синхронизации и если что-то где-то потеряется в пути, то видео всё станет кашей, так что не пытайтесь передавать такой поток через net cat (я не пробовал). Разработчик игр',\n",
              " 'В 2014 году вместе с релизом Android 5.0 Lollipop Google представил миру концепцию Material Design. Каждый элемент в системе состоит из «материала», идею которого хорошо описал дизайнер Матиас Дуарте: «В отличие от настоящей бумаги цифровой материал может разумно расширяться и преобразовываться. Материал имеет физические поверхности и края. Швы и тени придают смысл тому, к чему можно прикоснуться». В 2018 году увидела свет вторая версия Material. В ней сделали больше возможностей для кастомизации: обновили цветовую схему, обновили гайдлайны по работе со шрифтами, добавили поддержку форм (не форм ввода данных, а shapes у компонентов). Появилось больше способов выразить через стандартные компоненты Material айдентику — внешний визуальный интферфейс бренда. Но Google и на этом не остановился: именно поэтому сейчас вы читаете эту статью. В 2021 году на Google I/O представили концепцию Material You — новую версию Material под номером 3. По сравнению с прошлым обновлением изменений действительно много. Цель новой концепции — персонализировать пользовательский опыт. Меня зовут Тимур Задворнов, я Android-разработчик в Surf. В статье обсудим: обновление цветовой палитры Material, Dynamic Color, обновление UI-компонентов. Но сначала — вводная часть: разберём базовое устройство цветовой палитры Material. Это поможет лучше понять обновления в Material 3: что они означают и как с ними работать. Дисклеймер: эта статья — больше про дизайн, чем про разработку и использование компонентов в коде. Material-палитра состоит из шести ключевых цветов: Primary Secondary Background Surface Error Outline Primary и Secondary — первичный и вторичный цвета, основные акцентные цвета приложения, цвета бренда. Здесь всё очевидно. Например, у YouTube Primary цвет — #ff0000 (красный), у Twitter — #1d9bf0 (синий). Background и Surface — цвета поверхностей, на которых располагается контент. Background-цвет — цвет фона приложения, а Surface — цвет поверхностей компонентов в приложении. Самый яркий пример — карточки (Card View). У Card View стандартный цвет фона — Surface. Давайте вспомним базу Material. Как располагаются компоненты в приложении относительно друг друга? В гайдлайнах Material это описано подробно, но мы пробежимся очень кратко. Компоненты в приложении находятся на разных высотах относительно оси Z. В светлой теме высота показывается с помощью тени под компонентом. В тёмной теме это не сработает: тени не будет видно. Решение простое и элегантное: чем выше контент по оси Z, тем ближе он будет к источнику света (поверхности экрана) и тем светлее будет компонент. Тут-то и приходит на помощь Surface-цвет! Если задать цвет Surface, при изменении elevation цвет контента будет меняться автоматически без лишних строк кода. Маппинг значений elevation в значение яркости поверхности хорошо описан в документации и хорошо отображен на визуализации ниже. Этот момент достаточно сложный для понимания, поэтому вопросы по цветам жду в комментариях, подискутируем :) Цвет Error — цвет для отображения ошибок. В объяснении, думаю, не нуждается. Outline — цвет для обводки различных компонентов. Самый яркий пример — Outlined Text Field. С ключевыми цветами покончили. Остаются только их вариации — on-цвета. On-цвета — цвета, которые будут идеально смотреться на «поверхности», окрашенной в основной или второстепенный цвета, цвета поверхности, фона или ошибки. Сразу привожу пример: у красного Error-цвета OnError-цвет логично будет белым, потому что он хорошо читается на красном фоне. У каждого цвета, кроме Outline, есть соответствующий ему on-цвет: у Primary есть OnPrimary, у Surface есть OnSurface и так далее. Базу цветовой схемы Material разобрали. Перейдём к нововведениям. В палитру добавили Tertiary-цвет и все его вариации. Tertiary — третий цвет для айдентики бренда наряду с Primary и Secondary: иногда двумя цветами бренду ограничиться непросто. Появился новый Surface-цвет — SurfaceVariant (вместе с OnSurfaceVariant). Это второй вариант для цветов поверхностей. Можно использовать, например, в качестве цвета текста на поверхностях или цвета дивайдеров. Ещё одна новинка палитры Material — Container-цвета. Container-цвета — новая вариация цветов, которая используется в контейнерах с компонентами. Яркий пример — Floating Action Button. Начиная с Material 3, цвет фона у этой кнопки стал PrimaryContainer, а цвет контента на этой кнопке — OnPrimaryContainer. У Container вариаций также есть злой двойник — On-цвет. Как Google собирается делать девайсы более персональными с Material You? С помощью Dynamic Color — одного из главных нововведений Material 3! Dynamic Color (динамический цвет) — фича, которая генерирует цветовую палитру по обоям пользователя и распространяет её на все приложения в системе (которые, естественно, поддерживают Dynamic Color). Как генерируется цвет? Цветовую палитру создаёт встроенный в Android 12 Monet Engine: он извлекает из обоев так называемый seed color и по нему генерирует палитру. Тональная палитра состоит из тринадцати тонов, включая белый и черный. Значение тона 100 эквивалентно представлению о максимальном освещении и даёт белый цвет. Значение тона 0 — чистый чёрный цвет. Каждое значение тона от 0 до 100 выражает количество света, присутствующего в цвете. В Android генерируется пять ключевых цветов: Accent1 (используется для Primary), Accent2 (для Secondary), Accent3 (для Tertiary), Neutral1 (для Background и Surface), Neutral2 (для SurfaceVariant и Outline). Плюс 13 их вариантов с разной тональностью. Сгенерированную палитру можно посмотреть с помощью виджета-пасхалки в Android 12. Теперь сопоставим все данные вместе: у нас есть большая сгенерированная палитра цветов и система цветов Material. На картинке ниже — готовая цветовая схема приложения, сгенерированная лишь по одному seed color. Сгенерировать свою палитру по канонам Material 3 можно с помощью Material Theme Builder. Также оттуда можно выгружать темы в виде стилей XML и стилей Jetpack Compose. В Material 3 обновили гайдлайны по UI-компонентам: кнопкам, чипам, диалогам, карточкам и панели навигации. Сolor mapping у всех компонентов соответствует гайдлайнам Material 3 и поддерживает Dynamic Color. Поговорим подробнее про каждый из компонентов. Обновили всё: обычные кнопки, FAB (floating action button) и Extended FAB. Новое в обычных кнопках: Полностью закруглили углы. Поменяли размеры кнопок: стандартную высоту подняли с 36dp до 40dp, размер иконки в кнопке увеличили до 18dp. Текст в кнопках теперь пишется не капсом, а с большой буквы (sentence case). Добавили 3 типа кнопок: filled — с бэкграундом primary, secondary, tertiary или какого угодно цвета, filled tonal — с бэкграундом container цвета) и elevated кнопки — с тенью. Вот они слева направо: Filled, Filled Tonal, Elevated, Outlined, Text. Новое в FAB: Изменили форму: теперь FAB — квадратные с закругленными углами, а не круглые. Добавили новый тип — Large FAB. Обновили цветовую палитру кнопки: теперь бэкграунд по гайдлайнам должен иметь Container-цвет (Primary, Secondary или Tertiary), а контент на кнопке — соответствующий On-Container цвет. Новое в Extended FAB: Изменили форму: Extended FAB теперь тоже стали квадратные с закругленными углами. Обновили цветовую схему по аналогии с обычными FAB. Обновили размеры кнопки, если в ней есть текст: теперь по высоте она точно такая же, как и обычный FAB. Чипы — компоненты, которые помогают пользователю вводить и фильтровать информацию. Что нового: Обновили форму компонента. Теперь они все одинаковые: прямоугольные с закруглениями по углам. Разделили чипы на четыре типа: Assist, Filter, Input, Suggestion. Assist — для «умных» или автоматизированных действий: например, добавить событие в календарь. Ближайший визуальный аналог — обычная кнопка. Filter — кнопка для фильтрации данных. Input — данные, которые были введены пользователем. Яркий пример: ввод адреса электронной почты, когда данные из текстового поля преобразуются в данные в чипе. Suggestion-чипы помогают сузить намерения пользователя: предлагают динамические предположения о возможных действиях пользователя — например, варианты ответа на сообщение в мессенджере. Обновления в диалогах: Увеличили паддинг контента. Увеличили радиус закругления углов. Обновили шрифты. В стандартный диалог добавили иконку над заголовком диалога. Также Google выкатил гайдлайны по реализации полноэкранных диалогов. Их можно использовать для ввода данных на экранах мобильных устройств. Правда, на планшетах этот диалог будет не полноэкранным, а обычным. В Android всю жизнь было два способа построить user-friendly навигацию: боковой бар и нижний. С Material 3 в Android унифицировали нейминг баров навигации и добавили новый вид — Navigation Rail. Navigation Bar — переименованный Bottom Navigation. Navigation Drawer — боковая панель навигации. Можно вызвать по свайпу с левой стороны экрана или, если экран большой, закрепить в левой части. Navigation Rail — тоже боковая панель навигации, но более узкая: как вертикальный Navigation Bar. Обновлений по барам навигации не так много: обновили цветовую схему, добавили закругления, изменили размеры некоторых компонентов. Хочу остановиться только на Navigation Rail. По гайдлайнам его советуют использовать для больших экранов вместо Navigation Bar, который неопрятно растягивается на всю ширину внизу экрана. Изменения коснулись и больших экранов. В преддверии выхода Android 12L Google показал гайдлайны по дизайну приложений, которые адаптированы для разных экранов: мобильного, складного и большого. Обновление затронуло много компонентов, о которых нет смысла рассказывать отдельно. А вот карточки сильно перерабатывать не стали. Помимо цветовой схемы, изменений минимум: : У карточки убрали elevation. Карточки разделили на 3 типа: Elevated (с тенью), Filled (залитая цветом) и Outlined (с обводкой). Та же ситуация и с тулбарами: немного изменили цветовую схему, позиционирование текста для разных видов тулбара, обновили шрифты, убрали elevation. Третье обновление концепции Material выдалось весьма объемным и принесло много нового, в частности, в дизайн Android. Тезисно: Много нового появилось в палитре Material (надеюсь, вам помог мой краткий экскурс в палитру). Dynamic Color — интересная вещь. Мне нравится, что с Android 13 все вендоры обязаны будут поддержать эту фичу. Но есть сомнения, что все сторонние приложения в ближайшее время начнут поддерживать динамические цвета. Обновили компоненты, API для работы с ними в Material Design Components и обновляют API для работы с ними на других платформах (Jetpack Compose, Flutter, Web). К сожалению, в Material You пока что есть недоработки. По состоянию на февраль 2022-го: Обновлены не все компоненты. На текущий момент Material You-гайдлайны полностью поддерживает только Material Design Components — старый подход к разработке Android-приложений. Для Jetpack Compose вышла альфа-версия библиотеки Material 3. Для Flutter поддержка новых гайдлайнов находится в активной разработке. Поддержка для Web только в планах. Пользователь']"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "new_p"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_li = []\n",
        "for article in new_p:\n",
        "    res = ''\n",
        "    for word in article.split():\n",
        "        res += re.sub(r'([?!.])$',r' \\1 ',word) + ' '\n",
        "    new_li.append(res)"
      ],
      "metadata": {
        "id": "aU01C1OGrxE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_li"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFKfVG0fsmuf",
        "outputId": "3ac5bafe-64ed-4648-9d21-432afe5d65d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Если в 2018 году люди тратили на просмотр видео 1,5 часа в день, то в 2022 году вовлечённость выросла до 2,5 часов .  Пользователи делятся видео в два раза чаще, чем любым другим контентом, а motion-графика почти так же популярна, как простые записи .  Сделали для вас подборку обучающих ресурсов, программ и инструментов для самостоятельного обучения .  В декабре 2021 года английская анимационная студия Wyzowl провела исследование, согласно которому motion-графика занимает второе место по популярности среди всех разновидностей видеоконтента (33%), уступая лишь 9% формату обычной видеозаписи (42%) .  Видео помогает компаниям привлекать новых клиентов, увеличивать объёмы продаж, повышать узнаваемость бренда, сокращать количество обращений в службу поддержки .  Это подтверждают и сами потребители: 88% говорят, что именно просмотр видео убедил их совершить покупку, 72% предпочитают узнавать о новых продуктах и услугах из видеороликов .  Рассказываем, как сделать motion-дизайн профессией .  Требования работодателей к motion-дизайнерам в 2022 году меняются в зависимости от уровня компании .  Мы приведём в качестве примера две вакансии, которые были актуальны на начало мая 2022 года .  Это топовые предложения для специалистов высокого класса, на которые следует ориентироваться .  В конце марта Apple опубликовала вакансию: от кандидата ждут, что он сможет создавать анимацию, заниматься графическим дизайном и делать видеоролики для рекламных и образовательных проектов компании .  Разработка креативной концепции также ложится на специалиста .  Кандидат должен работать в After Effects, Illustrator, Photoshop, Premiere Pro, Cinema 4D, Maya и Final Cut Pro .  Рассматривают бакалавров в области графического дизайна, медиаискусства или другой смежной специальности .  Требования к опыту: 4–10 лет работы по специальности .  Про доход ничего не пишут, но на сторонних ресурсах говорят, что средняя зарплата motion-дизайнера в Apple составляет около 80 тысяч долларов в год .  Социальная сеть VK опубликовала вакансию motion-дизайнера в команду игрового бренда MY.GAMES .  Как и Apple, VK ищет универсального специалиста, который будет не только рисовать и монтировать, но и создавать концепцию роликов и сценарии .  Кандидат также должен самостоятельно выставлять свет, строить кадр, записывать качественный звук и подбирать аудиоконтент .  Поскольку вакансия в геймдеве, нужно немного работать на базе движка Unity .  Требуется портфолио, а про образование не сказано ничего .  Набор программ, в которых надо уметь работать, классический: Adobe Premiere, Adobe Photoshop, Adobe After Effects, Photoshop .  Про деньги скажут на собеседовании .  На hh.ru в вакансиях со схожими функциями указывают зарплаты от 150 до 200 тысяч рублей в месяц .  При этом специалисты уровня джун, работающие по чёткому техническому заданию со знанием основных инструментов, могут рассчитывать на 70 тысяч в месяц .  Анимация включает в себя множество этапов от рисования эскиза до создания трёхмерных моделей и объединения их в сложную динамическую сцену .  Выбор инструментов зависит от специфики работы .  Иногда для выполнения задачи достаточно одной программы, а порой приходится задействовать целый набор инструментов .  Перечислим основные: Adobe After Effects .  Позволяет создавать анимированную графику и визуальные эффекты, а также редактировать видеоряд, в том числе видео 4K и 360/VR .  Хорошо работает с другими системами нелинейного монтажа, такими как Avid Media Composer и Final Cut Pro X .  Гибко интегрируется с 3D-приложениями: 3ds Max, Maya и Cinema 4D .  Доступен в экосистеме Creative Cloud .  На сайте Adobe выложены обучающие видео .  У Нетологии есть бесплатный курс для освоения базы, начать обучение мжно в любое время .  Cinema 4D .  Программное решение для 3D-моделирования, анимации, симуляции и рендеринга .  Художники-аниматоры любят Cinema 4D за удобство, простоту использования и гибкость при интеграции с After Effects .  У Cinema 4D сильное сообщество пользователей, поэтому легко найти обучающие ресурсы .  Начать можно с видео на популярном канале Greyscalegorilla .  Adobe Premiere Pro .  Приложение для редактирования видео, создаёт динамические связи с After Effects: пользователи могут вносить финальные правки в ролик без предварительного рендеринга .  На официальном сайте программы есть коллекция видеоуроков .  Adobe Photoshop .  Многофункциональный графический редактор .  Уроки доступны на любых ресурсах .  Основы можно выучить в Нетологии .  Adobe Illustrator .  Одна из ведущих программ обработки векторной графики и один из главных инструментов любого дизайнера .  Начинайте с бесплатного курса Нетологии или официальных материалов .  Blender .  Бесплатное ПО для 2D и 3D-графики с открытым исходным кодом и каналом на YouTube с руководствами .  Популярен в геймдеве .  Maya .  Конкурент Cinema 4D с более сложным интерфейсом .  Его используют многие голливудские студии для 3D-моделирования и анимации .  Открыта для сторонних разработчиков .  Есть сайт с уроками .  Для комфортной работы в этих программах на начало 2022 года нужен компьютер с 32 ГБ оперативки и 4 ГБ GPU .  Для большего погружения в профессию приведём ещё несколько ссылок на YouTube-каналы про motion-дизайн: VideoSmile Andrey Sokolov SurfacedStudio School of Motion Arrimus 3D SonduckFilm Blender Guru Eyedesyn Flat Pack FX Чаты: Motion Talk Motion Chat Каналы и сообщества для поиска работы: Motion designer hunter CG Freelance Motion Graphics Jobs Каналы и сообщества для вдохновения и обучения: Motion Graphics & Video Design MOTION GRAPHICS Animation & Visual effects Motion.RAR BDSR DESIGN REFERENCES VimeoInspiration | Motion design | Вольница Официальные ресурсы ПО: Adobe Premiere Pro for beginners Adobe Premiere Pro Intermediate Users Group Adobe After Effects Tutorials After Effects / Motion Design Adobe Illustrator tutorials Blender 3D Artists Blender Artists Community Cinema 4D - Maxon Cinema 4D — канал Cinema 4D — чат Photoshop & Illustrator Photoshop Tutorials Design for Motion: Fundamentals and Techniques of Motion Design, Остин Шоу .  Остин Шоу — motion-дизайнер, который более 15 лет делал графику для Ferrari, Fedex, Ralph Lauren, Target .  Сейчас — профессор motion-дизайна в Колледже искусств и дизайна Саванны .  Преподавал в Школе визуального искусства в Нью-Йорке .  В книге — техника иллюстрации, визуальный сторителлинг, работа с 3D-объектами, практические упражнения .  Аниматор: набор для выживания .  Секреты и методы создания анимации, 3D-графики и компьютерных игр, Уильямс Ричард .  Мультипликатор и обладатель премии Оскар за фильм «Кто подставил кролика Роджера» рассказывает о принципах анимации, 3D-графики и компьютерных игр .  The Theory and Practice of Motion Design, Брайан Стоун и Лия Уолин .  Авторы раскрывают о motion-дизайне через серию познавательных интервью с профессиональными дизайнерами о теории цвета и формы, визуализации, типографике и сторителлинге .  Motion-дизайнер компании-разработчика офисного ПО МойОфис На мой взгляд, motion-дизайн сто́ит начать с изучения 12 принципов Disney .  Они помогут понять, как оживить статическое изображение, выделить интересные для вас направления, в которых хотелось бы развиваться .  После выбора специализации стоит подумать, где можно научиться соответствующим приёмам .  Ресурсы, с которыми точно необходимо ознакомиться: Максимально полная документация по After Effects, одной из флагманских программ для motion-дизайнера; Гениальные плагины и уроки по After Effects; Крупнейший ресурс с обучающими курсами, в том числе и Motion Graphics; Ещё уроки и плагины для After Effects .  При выборе обучающих ресурсов необходимо отталкиваться от потребностей .  Важно уметь ставить цель и искать средства для её достижения .  Можно бесконечно проходить различные курсы, но так и не применить знания .  Нужно постоянно тренировать насмотренность, изучать лучшие практики и анализировать работы мастеров с именем .  Начинающим специалистам я бы посоветовал начать с заказов на фриланс-ресурсах, параллельно продвигая портфолио на таких сайтах, как Artstation или Cgsociety .  Продюсер CG-студии Mondlicht Studios Большинство сегодняшних топов индустрии — самоучки .  Когда они начинали, контента и готовых курсов просто не было, был плохой интернет и желание научиться .  Сегодня выбор куда больше: есть и курсы, и отдельные каналы, и классическое обучение .  Важно понимать плюсы и минусы каждого .  Например, самостоятельное образование экономит вам деньги, но вы тратите намного больше времени .  С готовыми курсами вы экономите время, но расстаётесь с приличной суммой .  На мой взгляд, успех в балансе .  Идеальный вариант — это курсы для быстрого старта и понимания основ, дополненные максимально возможным количеством туториалов, вебинаров, статей и любого контента, до которого получится добраться .  Ещё один важный момент — это сообщество .  Оно поможет увидеть, что вы делаете не так, получить обратную связь, найти первые заказы и многое другое .  Комьюнити в Computer Generated Imagery — это очень тёплая тусовка, где с пониманием относятся к новичкам .  Motion-дизайнер студии Maryco C хорошей самодисциплиной и больши́м желанием можно самостоятельно изучить motion-дизайн .  В интернете много бесплатных материалов и уроков .  Я рекомендую начинать с пакета Adobe, Cinema 4D, Blender, разобраться в их инструментах .  Пробовать анимировать абстрактные композиции, анализировать готовые проекты, смотреть, какими средствами достигается тот или иной эффект в роликах, что в них хорошо, а что плохо и как можно сделать лучше .  Ещё советую смотреть туториалы .  Мне очень помогали проекты VideoSmile, «Вольница», Greyscalegorilla (у них есть разделы по 3D) и блог AEPlug на Youtube .  На Youtube очень много уроков, всегда найдётся англоговорящий индус, который показывает, как сделать что-то невообразимое .  Для вдохновения советую смотреть Behance и телеграм-канал Тренд-бюро, здесь рассказывают про разные области дизайна и моды — это помогает понять контекст, с которым вам предстоит работать .  Опыт в обычном статичном дизайне тоже необходим .  Качество результата будет выше .  Хороший дизайн приятен глазу, он строится на гармоничном сочетании шрифтов и цветов, в нём выстроена правильная композиция .  Понимая, как это можно сделать, вы визуально улучшите свои работы .  Дизайнеры учатся постоянно, особенно в начале карьеры .  Чтобы стать востребованным профессионалом, нужно: владеть основными программами; быть насмотренным и хорошо визуализировать; уметь делать раскадровки и объяснять их; чувствовать динамику и ритм ролика; понимать, как удерживать внимание зрителя, как показать большой объём информации так, чтобы она воспринималась легко; иметь развитые гибкие навыки, чтобы общаться с заказчиками; уметь рассчитать время, которое займёт выполнение проекта, и исходя из этого — цену .  Редактор Нетологии ',\n",
              " 'Специально для тех, кто ищет полноценный отечественный аналог Unity или Unreal Engine, мы продолжаем цикл статей про безболезненный переход на UNIGINE с зарубежных движков .  В третьем выпуске рассмотрим миграцию с Unity с точки зрения программиста .  Традиционно игровая логика в проекте Unity реализуется через пользовательские компоненты — C# классы, унаследованные от MonoBehaviour .  Основная логика компонента определена в событийных методах Start(), Update() и так далее .  UNIGINE предлагает очень похожую концепцию — C# Component System — стабильная и высокопроизводительная компонентная система на .NET 5 .  Компоненты представлены C# классами, унаследованными от Component, их можно назначить любой ноде в сцене .  Жизненный цикл каждого компонента определяется набором методов (Init(), Update() и т .  д.), вызываемых в основном цикле движка .  Программирование в UNIGINE с использованием C# мало чем отличается от программирования в Unity .  Например, давайте сравним, как выполняется вращение объекта в Unity: и в UNIGINE: Кнопка для запуска экземпляра приложения в отдельном окне расположена на панели инструментов в UnigineEditor .  Также рядом расположены настройки параметров запуска .  Вот как мы заставим колесо вращаться с помощью C# Component System и запустим экземпляр, чтобы немедленно его проверить: Более того, системная логика приложения на UNIGINE может быть определена в файлах AppWorldLogic.cs, AppSystemLogic.cs и AppEditorLogic.cs в папке source проекта .  Чтобы узнать больше о последовательности выполнения и о том, как создавать компоненты, перейдите по ссылкам ниже: Последовательность выполнения Видеоруководство по C# Component System C# UNIGINE API Для тех, кто предпочитает C++, UNIGINE позволяет создавать приложения C++ с использованием С++ UNIGINE API, и, при необходимости, C++ Component System .  Используйте клавишу ~, чтобы открыть консоль в приложении Unity UNIGINE //Исходный код (C#) Debug.Log(\"Text: \" + text); Debug.LogFormat(\"Formatted text: {0}\", text); //Исходный код (C#) Log.Message(\"Debug info:\" + text + \"\\\\n\"); Log.Message(\"Debug info: {0}\\\\n\", new vec3(1, 2, 3)); Дополнительные типы сообщений в API класса Log Видеоруководство, демонстрирующее, как выводить пользовательские сообщения в консоль с помощью C# Component System Unity UNIGINE //Исходный код (C#) GameObject this_go = gameObject; string n = gameObject.name; //Исходный код (C#) Node this_node = node; string n = node.Name; Видеоруководство, демонстрирующее, как получить доступ к нодам из компонентов с помощью C# Component System В Unity компонент Transform отвечает за позицию, вращение и масштаб Game Object, а также за родительско-дочерние связи .  Чтобы получить вектор направления по одной из осей с учетом вращения GameObject в мировых координатах, в Unity используется соответствующее свойство компонента Transform .  В UNIGINE трансформация ноды в пространстве представлена ее матрицей трансформации (mat4), а все основные свойства и операции с иерархией нод доступны при помощи методов и свойств класса Node .  Такой же вектор направления в UNIGINE получается с помощью метода Node.GetWorldDirection(): Unity UNIGINE //Исходный код (C#) Vector3 forward = transform.forward; Vector3 right = transform.right; Vector3 up = transform.up; transform.Translate(forward * speed * Time.deltaTime); //Исходный код (C#) vec3 forward = node.GetWorldDirection(MathLib.AXIS.Y); vec3 right = node.GetWorldDirection(MathLib.AXIS.X); vec3 up = node.GetWorldDirection(MathLib.AXIS.Z); node.Translate(forward * speed * Game.IFps); Система координат в UNIGINE В Unity, чтобы гарантировать, что определенные действия выполняются за одно и то же время независимо от частоты кадров (например, изменение положения один раз в секунду и т .  д.), используется множитель Time.deltaTime (время в секундах, которое потребовалось для завершения последнего кадра) .  То же самое в UNIGINE называется Game.IFps: Unity UNIGINE //Исходный код (C#) transform.Rotate(0, speed * Time.deltaTime, 0, Space.Self); //Исходный код (C#) node.Rotate(0, 0, speed * Game.IFps); Unity: В UNIGINE за вспомогательную отрисовку отвечает синглтон Visualizer: Примечание .  Visualizer также можно включить с помощью консольной команды show_visualizer 1 .  Все типы визуализаций в API класса Visualizer .  Unity UNIGINE //Исходный код (C#) SceneManager.LoadScene(\"YourSceneName\",LoadSceneMode.Single); //Исходный код (C#) World.LoadWorld(\"YourSceneName\"); Unity: UNIGINE: Компонентный подход Unity позволяет рассматривать такие стандартные объекты, как MeshRenderer, Rigidbody, Collider, Transform и другие, как обычные компоненты .  В UNIGINE доступ к аналогам этих сущностей осуществляется иначе .  Классы всех типов нод являются производными от Node, поэтому чтобы получить доступ к функциональности ноды определенного типа (например, ObjectMeshStatic), необходимо провести понижающее приведение типа (downcasting) .  Рассмотрим эти самые популярные варианты использования: Unity: UNIGINE: Unity: UNIGINE: Downcasting (приведение от базового типа к производному) выполняется одинаково в обоих движках с использованием родной конструкции C# as: Unity UNIGINE //Исходный код (C#) Collider collider = gameObject.GetComponent<Collider>; BoxCollider boxCollider = collider as BoxCollider; //Исходный код (C#) Node node = World.GetNodeByName(\"my_mesh\"); ObjectMeshStatic mesh = node as ObjectMeshStatic; Чтобы выполнить Upcasting (приведение от производного типа к базовому), можно как обычно просто использовать сам экземпляр: Unity UNIGINE //Исходный код (C#) Collider collider = gameObject.GetComponent<Collider>; BoxCollider boxCollider = collider as BoxCollider; Collider coll = boxCollider; //Исходный код (C#) Node node = World.GetNodeByName(\"my_mesh\"); ObjectMeshStatic mesh = node as ObjectMeshStatic; Unigine.Object obj = mesh; Unity UNIGINE //Исходный код (C#) Destroy(myGameObject); // уничтожить объект с задержкой в 1 секунду Destroy(myGameObject, 1); //Исходный код (C#) node.DeleteLater(); // рекомендуемый вариант // нода уничтожается после текущего кадра node.DeleteForce(); // форсировать уничтожение ноды в данный момент, что не всегда безопасно Для выполнения отложенного удаления ноды в UNIGINE можно создать компонент, который будет отвечать за таймер и удаление .  В Unity экземпляр префаба или копия уже существующего в сцене GameObject создается с помощью функции Object.Instantiate: Затем вы должны указать префаб, который будет создан, в параметрах компонента скрипта .  В UNIGINE получить доступ к уже существующей ноде любого типа можно также через параметр компонента, и клонировать ее при помощи Node.Clone() .  Но ассеты не являются нодами, они принадлежат файловой системе .  К ассету можно обратиться, используя эти типы параметров: AssetLink — для любых ассетов, AssetLinkNode — для ассетов *.node, содержащих иерархию нод, сохраненную как Node Reference (аналог prefab) .  В этом случае ссылка на ассет, аналогично Unity, указывается в UnigineEditor: Также можно использовать функцию World.LoadNode для загрузки иерархии нод вручную, указав виртуальный путь к ассету .  Еще один способ загрузить содержимое ассета *.node — создать NodeReference и работать с иерархией нод как с одним объектом .  Тип Node Reference имеет ряд внутренних оптимизаций и тонких моментов (кэширование нод, распаковка иерархии и т.д.), поэтому важно учитывать специфику работы с этими объектами .  Unity позволяет расширять функциональность редактора с помощью C# скриптов .  Для этого в скриптах поддерживаются специальные атрибуты: [ExecuteInEditMode] — для выполнения логики скрипта в режиме Edit, когда приложение не запущено .  [ExecuteAlways] — для выполнения логики скрипта как в режиме Play, так и при редактировании .  Например, так выглядит код компонента, который заставляет GameObject ориентироваться на определенную точку в сцене: UNIGINE не поддерживает выполнение логики C# внутри редактора .  Основной способ расширить функциональность редактора — плагины, написанные на C++ .  Для быстрого тестирования или автоматизации разработки можно написать логику на UnigineScript .  UnigineScript API обладает только базовой функциональностью и ограниченной сферой применения, но доступен для любого проекта на UNIGINE, включая проекты на .NET 5 .  Есть два способа добавить скриптовую логику в проект: Создав скрипт мира: Создайте ассет скрипта .usc .  Определите в нем логику .  При необходимости добавьте проверку, загружен ли редактор: Выделите текущий мир и укажите для него сценарий мира .  Нажмите Apply и перезагрузите мир .  Проверьте окно консоли на наличие ошибок .  После этого логика скрипта будет выполняться как в редакторе, так и в приложении .  Используя WorldExpression .  С той же целью можно использовать ноду WorldExpression, выполняющую логику при добавлении в мир: Нажмите Create -> Logic -> Expression и поместите новую ноду WorldExpression в мир .  Напишите логику на UnigineScript в поле Source: Проверьте окно Console на наличие ошибок .  Логика будет выполнена немедленно .  Помимо обнаружения столкновений, компонент Collider в Unity может быть использован как триггер, который срабатывает, когда другой коллайдер попадает в его объем .  В UNIGINE Trigger — это специальный тип нод, вызывающих события в определенных ситуациях: NodeTrigger вызывает коллбэк при изменении состояния включен/выключен и позиции самой ноды .  WorldTrigger вызывает коллбэк, когда какая-либо нода (независимо от типа) попадает внутрь или за его пределы .  PhysicalTrigger вызывает коллбэк, когда физические объекты попадают внутрь или наружу его пределов .  Важно !  PhysicalTrigger не обрабатывает столкновения, для этого физические тела и сочленения предоставляют свои собственные события .  WorldTrigger — наиболее распространенный тип триггера, который можно использовать в игровой логике: Обычный игровой ввод Unity: UNIGINE: Также можно использовать синглтон ControlsApp для обработки привязок элементов управления к состояниям .  Чтобы настроить привязки, откройте настройки Controls: Для обнаружения пересечений лучей с объектами в Unity используется Physics.Raycast .  GameObject должен иметь прикрепленный компонент Collider для участия в рейкастинге: В UNIGINE то же самое делается с помощью Intersections: Напоминаем, что получить доступ к бесплатной версии UNIGINE 2 Community можно заполнив форму на нашем сайте .  Все комплектации UNIGINE: Community — базовая версия для любителей и независимых разработчиков .  Достаточна для разработки видеоигр большинства популярных жанров (включая VR) .  Engineering — расширенная, специализированная версия .  Включает множество заготовок для инженерных задач .  Sim — максимальная версия платформы под масштабные проекты (размеров планеты и даже больше) с готовыми механизмами симуляции .  Подробнее о комплектациях и ценах Пользователь ',\n",
              " 'Рассказываю, какими шрифтами можно заменить заблокированные Times New Roman, Arial и Helvetica и где скачать аналоги .  В апреле компания Monotype закрыла доступ к своему каталогу шрифтов для российских пользователей .  Arial, Times New Roman и Helvetica всё ещё доступны для использования, однако, что будет дальше, предсказать сложно: в худшем случае компания Monotype может заблокировать шрифты во всех сервисах и программах на территории России .  Если в документах или фирменном стиле вашей компании используется Arial или Times New Roman — о их замене лучше задуматься уже сейчас .  Делюсь подборкой бесплатных аналогов популярных шрифтов Monotype .  Calibri Candara Commisioner Constantia Franklin Gothic Georgia IBM Plex Inter Lucida Sans Manrope Mulish Noto Sans Nunito Outfit Poppins Raleway Roboto Rubik Segoe UI Ubuntu Golos Text Literata PT Astra Вместо вывода делимся тремя универсальными правилами типографики, которые будут полезны и недизайнерам: Правило 1 .  Делайте заголовки в два раза больше основного текста .  Так читателю будет проще понять, что в вашей информации важное, а что второстепенное .  Правило 2 .  Если хотите сделать текст контрастным — пропустите одно начертание .  Лучше сочетать тонкое начертание с полужирным, а регулярное — с жирным .  Правило 3 .  Чем важнее текст, тем стандартнее шрифт .  Не усложняйте витиеватыми шрифтами то, что несёт ключевой смысл текста .  Предприниматель ',\n",
              " 'Статья ранее публиковалась в нашем блоге на DTF .  Если вы планируете переходить с иностранного софта на отечественный и ищете полноценный аналог Unity или Unreal Engine, то одним из вариантов может стать продукция нашей компании, полностью готовая к импортозамещению .  UNIGINE использует общепринятые интерфейсы и рабочие процессы, которые могут быть вам знакомы по работе с другими 3D-инструментами .  По опыту наших клиентов, для перехода на UNIGINE с других платформ уходит не более 1–2 недель .  Одна из таких платформ — платформа разработки в реальном времени Unity .  Далее в статье рассмотрим базовую информацию по переходу на UNIGINE .  Сначала разберемся с названиями различных сущностей и другими терминами .  В таблице ниже приведены термины Unity и их точные или приблизительные эквиваленты в UNIGINE .  Категория Unity UNIGINE Управление проектами и SDK Hub SDK Browser Интерфейс редактора Hierarchy Panel Окно World Nodes Inspector Окно Parameters Project Browser Окно Asset Browser Scene View Editor Viewport Сцена Scene World Типы геймплея Component Component System GameObject Node Prefab NodeReference Меши Mesh Renderer Static Mesh Dynamic Mesh Skinned Mesh Renderer Skinned Mesh Blendshapes Morph Targets Эффекты Particle System Particle System Halo Volumetric Objects Lens Flares Lens Flares Billboard Renderer Billboards Projector / Decal Projector (HDRP) Decals Экстерьеры Terrain Terrain Systems Trees / Grass Mesh Clutter Grass аддон Vegetation Wind Zones Animation Field Игровой интерфейс UI (User Interface) GUI (Graphics User Interface) Освещение Light Sources Light Sources Environment Environment Lightmapping LightmappingVoxel GI Reflection Probes Environment Probes Рендеринг Shade Base Material Material User Material Кастомные шейдеры: HLSL Shader Graph HLSL GLSL UUSL (Unified UNIGINE Shader Language) Визуальный редактор материалов Compute Shaders UUSL Compute Shaders Rendering Paths Rendering Sequence Multi-Display Rendering Плагины для рендеринга на нескольких экранах (Multi-Monitor Rendering) Плагин Syncker для многоканальной визуализации Программирование C# C++ C# UnigineScript Scriptable Render Pipeline URP HDRP Rendering Sequence (при полном доступе из API) Scriptable Materials Физика Raycast Intersections Rigid Body Rigid Body Collider Shape Joint Joint Cloth Cloth Body Анимация Timeline Tracker Навигация и нахождение пути NavMesh NavMeshAgent Off-Mesh Link NavMesh Obstacle Navigation Areas Obstacles Пользователи Unity используют Unity Hub — приложение для поиска, загрузки и управления версиями движка и проектами .  В UNIGINE для этих целей служит UNIGINE SDK Browser .  Помимо управления проектами и установленными SDK, браузер SDK предоставляет доступ к примерам (Samples), базе знаний (Knowledge) и дополнениям (Add-Ons) .  В последнюю категорию входят различные 3D-модели и материалы, в том числе растительность, спецэффекты, погодные эффекты и другое .  Также заметным отличием UNIGINE является возможность создания нового (или редактирование старого) проекта с поддержкой одного из нескольких языков программирования: C++, C# и UnigineScript .  Для пользователей Unity рекомендуется использовать C# Component System .  Также возможно использование нескольких языков программирования в одном проекте .  Например, для выполнения ресурсоемких задач часто используют C++ .  Нажмите Create New в разделе My Projects .  Выберите тип проекта C# (.NET 5) в поле API + IDE .  Если требуется поддержка VR-гарнитур, перейдите в раздел Plugins, отметьте необходимые плагины в секции Stereo 3D и нажмите Ok (больше о поддержке VR-устройств здесь) .  Нажмите Create New Project .  После завершения загрузки нажмите Open Editor, чтобы запустить UNIGINE Editor .  Элементы интерфейсов Unity Editor и UNIGINE Editor близки по функционалу: на схеме ниже они окрашены в похожие цвета .  Расположение элементов UNIGINE Editor можно настраивать, перетаскивая и изменяя их размер .  В UNIGINE по умолчанию используется темная тема .  Toolbar .  Панель инструментов, которая обеспечивает доступ к инструментам позиционирования, а также элементам управления логикой приложения, воспроизведением звука, симуляцией физики, компиляцией шейдеров и запеканием света .  World Hierarchy Window .  Инструмент для работы с иерархией нод .  Позволяет организовывать ноды в иерархию, а также добавлять, удалять, клонировать и переименовывать их .  Editor Viewport .  Просмотр трехмерной сцены .  Позволяет визуально перемещаться и редактировать виртуальный мир .  Parameters Window .  Окно параметров выбранного элемента виртуального мира .  Позволяет просматривать и изменять параметры нод, материалов, свойств и ассетов .  Asset Browser Window .  Инструмент для организации контента в проекте: создания, импорта, просмотра, переименования ассетов, а также перемещения и управления их иерархией .  Инструменты для просмотра виртуальной сцены Unity Scene View и UNIGINE Editor Viewport очень похожи между собой — это непосредственно само окно просмотра и панель инструментов .  Вы можете использовать столько окон Editor Viewport, сколько вам необходимо .  Есть русские субтитры Camera Panel служит для переключения между камерами и настройки текущей камеры .  Rendering Debug Panel требуется для отображения содержимого буферов рендеринга так же, как при использовании Draw Mode в редакторе Unity .  Navigation Panel используется для быстрой настройки и переключения между пресетами скорости камеры, а также для изменения положения камеры .  Панель Helpers обеспечивает быстрый доступ к вспомогательным визуализаторам, таким как значки, гизмо и каркасы .  Навигация внутри Editor Viewport почти такая же, как и в Scene View Unity .  Подробнее ознакомиться с навигацией по сцене можно, просмотрев видео ниже (либо прочитав соответствующий раздел в документации): Есть русские субтитры Переключатель Precompile All Shaders (предварительная компиляция всех шейдеров) используется для принудительной компиляции шейдеров; Переключатель Animation (анимации); Переключатель Physics (физики); Переключатель Audio (звука); Кнопка Play для управления воспроизведением .  В режиме воспроизведения Game View редактора Unity рендерит финальную сцену с одной или нескольких камер .  В UNIGINE кнопка Play используется для запуска экземпляра приложения в отдельном окне .  Также есть возможность переключения между режимами воспроизведения для изменения его основных параметров .  Так, например, можно включить режим VR, чтобы обеспечить совместимость с одной из поддерживаемых гарнитур виртуальной реальности .  Engine Viewport в UNIGINE (аналог Game View), используемый для отладки и оценки производительности, считается избыточным для проектов, разрабатываемых на C# .NET 5 .  Однако, его можно использовать в других проектах .  Как в Unity, так и в UNIGINE есть консоль для стандартного ввода, вывода и регистрации ошибок .  Также существует набор консольных команд, позволяющих совершать определенные операции .  Консоль доступна как в UNIGINE Editor, так и в работающем приложении .  Чтобы открыть окно консоли в редакторе, перейдите в меню Windows -> Console: Во время работы приложения встроенная консоль запускается нажатием кнопки «Тильда» (~) .  Во встроенную консоль можно выводить сообщения из кода .  Так же как и Unity Editor, UNIGINE Editor позволяет выполнить подготовку финальной сборки проекта .  Проект в UNIGINE, как и проект на Unity, хранится в отдельной папке, настройки проекта хранятся в файле с расширением *.project .  В папке проекта есть различные подпапки с контентом и исходным кодом приложения .  Также тут хранятся папки с файлами конфигурации и исполняемыми файлами .  Наиболее важные подпапки: data (данных) и source (исходного кода) .  Каждый проект UNIGINE обязательно включает в себя папку data .  Как и в папке Assets проекта на Unity, здесь хранятся ресурсы вашего проекта .  Для импорта ассетов достаточно перетащить файлы в папку data — они автоматически импортируются и станут доступны в Asset Browser .  Ассеты в UNIGINE Editor будут автоматически обновляться при внесении изменений в соответствующие файлы .  Соответствие содержимого папки data в корневой директории проекта и в Asset Browser Unity поддерживает широкий спектр форматов файлов, в то время как UNIGINE поддерживает большинство наиболее популярных, а также ряд специфических: Тип ассетов Поддерживаемые форматы Геометрия .fbx, .obj, .3ds, .dae, .glb/.gltf, .stp/.step, .igs/.iges, .brep, .stl Текстуры .png, .jpeg, .tif, .tga, .rgba, .psd, .hdr, .dds, and more Звук и видео .wav, .mp3, .oga/.ogg, .ogv Шрифты .ttf Меши .  Ассеты в формате FBX могут быть легко импортированы из Unity в UNIGINE без искажения масштаба .  Подробнее про импорт FBX-моделей читайте здесь .  Материалы .  Так же как и Unity, UNIGINE работает с PBR-материалами (Physically Based Materials) и поддерживает Metalness и Specular workflow .  Материалы, созданные в Unity, можно воссоздать в UNIGINE, благодаря встроенной богатой библиотеке материалов, а также возможности визуально создавать и редактировать материалы в Visual Material Editor .  Текстуры .  Текстуры можно импортировать либо как часть модели, либо отдельно, а затем назначать их мешу .  Но иногда может потребоваться предварительная подготовка .  Например, Shading-текстура в UNIGINE хранит карты Metalness, Roughness, Specular и Microfiber в соответствующих каналах .  Поэтому сначала нужно изменить Shading-текстуру с помощью GIMP или Photoshop, а затем импортировать ее в UNIGINE .  А перед импортом Normal-текстуры нужно инвертировать канал G с помощью соответствующей настройки при импорте .  Анимации .  Модель со скелетной анимацией, которую вы использовали в проекте Unity, может быть импортирована в UNIGINE, если она хранится в формате FBX .  При импорте такой модели, включите опцию Import Animations (импорт анимаций) и настройте дополнительные параметры .  Подробнее про импорт разных ассетов читайте здесь .  Концепция сцены в обоих движках одинакова .  Однако Unity и UNIGINE используют разные системы координат .  Unity UNIGINE Unity использует левостороннюю систему координат, в которой вертикальное направление представлено осью +Y .  1 юнит равен 1 метру .  Оси и направления:X — вправо (+), влево (-)Y — вверх (+), вниз (-)Z — вперед (+), назад (-)Положительный угол поворота задает вращение по часовой стрелке.Формат файла: *.scene UNIGINE использует правостороннюю систему координат, в которой вертикальное направление представлено осью +Z .  1 юнит равен 1 метру .  Оси и направления: X — вправо (+), влево (-) Y — вперед (+), назад (-) Z — вверх (+), вниз (-) Положительный угол поворота задает вращение против часовой стрелки .  Формат файла: *.world Как в Unity, так и в UNIGINE, сцена формируется из базовых объектов .  С их кратким описанием, а также основными сходствами и различиями можно ознакомиться ниже .  Unity UNIGINE Окно Hierarchy Окно World Nodes Базовый объект сцены — GameObject .  Базовый тип, от которого наследуются все типы объектов сцены — Node .  Некоторые имеют визуальное представление: Objects, Decals и Effects .  У каждого из них есть поверхности для представления своей геометрии (меши) .  Остальные — Light Sources, Players и др .  — невидимы .  GameObjects являются контейнерами для всех остальных компонентов .  Компоненты определяют функционал GameObject .  Базовая функциональность ноды определяется ее типом .  Дополнительные функции можно добавлять с помощью свойств и компонентной системы .  По умолчанию каждый GameObject имеет компонент Transform .  У каждой ноды есть матрица преобразования, которая задает ее положение, поворот и масштаб в пространстве .  GameObjects могут быть организованы в иерархию типа родитель-потомок .  Ноды могут быть организованы в иерархию типа родитель-потомок .  Важно .  Все объекты, добавляемые в сцену, независимо от их типа, называются нодами .  Процесс создания сцены в Unity основан на префабах .  Обычно вы собираете сложный объект из GameObjects с определенными компонентами и свойствами и создаете префаб из такого объекта .  Затем префабы могут быть размещены в сцене посредством редактора или созданы во время выполнения приложения .  Создание сцены в UNIGINE основано на Node Reference, которые очень похожи на префабы .  Чтобы создать сложный объект, экземпляры которого затем будут многократно использоваться в сцене, достаточно построить нужную иерархию из нод, назначить им материалы и свойства, а затем сохранить ее как Node Reference .  Так же, как и в случае с префабами, вы в любой момент сможете изменить Node Reference, просто изменив любой из ее экземпляров .  Подробнее про создание Node Reference и управление смотрите видео ниже (или читайте в документации): Есть русские субтитры В Unity Editor для разрешения конфликтов, возникающих при слиянии рабочих копий проекта, используется инструмент Smart Merge .  Также редактор позволяет применять пользовательские инструменты для тех же целей .  Для успешного объединения, сцены и другие файлы должны быть в формате YAML .  В UNIGINE все исходные форматы файлов по умолчанию являются текстовыми, поэтому вы можете использовать любую привычную систему контроля версий и объединять миры, ноды и другие ассеты .  Файловую систему можно расширять с помощью Mount Points, которые позволяют добавлять в проект любые внешние ресурсы, находящиеся в совместном доступе .  Кроме того, стандартный подход к работе над проектом заключается в разделении работы разных членов команды с помощью отдельных Node Layers .  Это позволяет избежать необходимости разрешения конфликтов при слиянии изменений .  Подробнее про совместную работу над проектом читайте здесь .  Камеры в Unity и UNIGINE устроены немного по-разному .  В Unity компонент Camera отвечает за захват изображения и отправку его на отрисовку .  Все включенные камеры, присутствующие в сцене, визуализируются в окне просмотра (Game View) и могут перекрывать друг друга .  Для переключения между камерами обычно нужно отключить текущую камеру и включить другую .  В UNIGINE камера — это объект, связанный с рендерингом и представленный нодами Player в мире .  Для упрощения создания наиболее часто используемых камер, управляемых с помощью устройств ввода (клавиатура, мышь, джойстик), предусмотрено несколько типов Node Player с различным поведением: Dummy — простая статическая камера, которая может быть усовершенствована с помощью пользовательских доработок .  Spectator — камера свободного перемещения .  Persecutor — камера, которая следует за целевым объектом и может свободно вращаться вокруг него на заданном расстоянии .  Это готовое решение для создания камеры от третьего лица .  Actor — камера с твердым физическим телом капсульной формы, которая может взаимодействовать с окружением .  Это готовое решение для создания вида от первого лица, схожее с Unity Character Controller .  Одновременно Editor Viewport показывает вид только с одной камеры .  Переключаться между камерами можно с помощью Camera Panel: Чтобы в режиме воспроизведения (когда нажата кнопка Play) определенная камера использовалась по умолчанию, нужно установить флажок Main Player в ее настройках .  Настройка общих параметров проекта в Unity Editor обычно выполняется через окно настроек проекта (меню: Edit -> Project Settings) .  Аудио, графика, физика, уровни качества и другие настройки влияют на весь проект .  В UNIGINE общие настройки доступны вменю Windows -> Settings в разделе Runtime .  Настройки мира задаются для каждого мира отдельно .  В Unity Editor асинхронная компиляция шейдеров включается и выключается в настройках редактора (меню: Edit -> Project Settings -> Editor -> Shader Compilation) .  В UNIGINE аналогичная функция редактора называется Forced Shader Compilation .  Она доступна как через панель инструментов, так и через раздел Editor окна Settings .  Вы используете пресеты в редакторе Unity, когда вам нужно повторно использовать настройки свойств, относящиеся к различным задачам, будь то настройки компонентов, настройки импорта или, в особенности, настройки проекта (Project Settings) .  Вы можете сохранить настройки для определенного раздела Project Settings в качестве *.preset ассета и использовать его в процессе разработки .  UNIGINE позволяет сохранять и загружать пресеты для общих настроек физики, звука и рендеринга .  Пресеты хранятся в виде ассетов с расширениями *.physics, *.sound и *.render соответственно .  Для загрузки и сохранения пресетов используются кнопки Load и Save в соответствующем разделе настроек окна Settings .  Сохраненные ассеты отображаются в Asset Browser .  Вы можете загрузить настройки рендеринга, дважды щелкнув необходимый ассет с расширением .render .  В UNIGINE пресеты доступны не только в редакторе .  Вы можете использовать классы Physics, Sound и Render для управления пресетами соответствующих настроек — например, для переключения между уровнями качества во время выполнения приложения .  В Unity Editor настройки качества графики в основном собраны в следующих разделах: Раздел Graphics содержит глобальные настройки графики .  Настройки уровня (Tier Settings) обеспечивают платформенно-ориентированную настройку рендеринга и компиляции шейдеров .  Уровень определяется автоматически в зависимости от используемой платформы .  Раздел Quality обрабатывает уровни графического качества, заданные для каждой платформы .  В UNIGINE настройки рендеринга мира можно найти в разделе Rendering окна Settings .  Также есть возможность включать и выключать самые распространенные функции рендеринга с помощью соответствующего меню: В UNIGINE нет платформенно-зависимых настроек качества, поэтому для управления уровнями качества необходимо написать свою собственную логику .  Для этой цели можно использовать пресеты рендеринга (Render Presets) .  Рассмотрим наиболее часто используемые настройки рендеринга в Unity и соответствующие им аналоги в UNIGINE: Unity UNIGINE HDR Mode Render -> Buffers -> Color 16F Rendering Path см .  ниже Shaders Preloading Render -> Streaming -> Preload at World Loading Pixel Light Count Forward Per-Object Limits Texture Quality Render -> Textures -> Quality Anisotropic Textures Render -> Textures -> Anisotropy Anti Aliasing Render -> Antialiasing -> Supersampling Soft Particles particles_base -> Soft Interaction Realtime Reflection Probes Меню: Rendering -> Dynamic Reflections -> Enabled Texture Streaming Render -> настройки Streaming Shadows Render -> настройки Shadows Shadow Cascades устанавливается для каждого источника World Light VSync Count Runtime -> настройки Video В Unity существует два способа рендеринга: Deferred (отложенный) и Forward (прямой) рендеринг .  Они определяют точность шейдинга, а также потребление ресурсов при рендеринге и необходимое аппаратное обеспечение .  Способ рендеринга можно выбрать в окне Graphics для каждой камеры .  UNIGINE имеет фиксированную последовательность рендеринга, представленную комбинацией полного отложенного рендеринга с методами упреждающего рендеринга: Вся непрозрачная геометрия отрисовывается в отложенном проходе (Deferred) .  Прозрачная геометрия отрисовывается во время прямого прохода (Forward) .  Вы можете уменьшить вычислительную нагрузку, пропустив определенные этапы рендеринга .  Посмотрите специальный видеоурок по использованию инструмента Microprofile для оптимизации рендеринга: В Unity доступность эффектов постобработки определяется используемым конвейером рендеринга .  В UNIGINE подобные эффекты не являются частью постобработки, а интегрированы в процесс рендеринга .  Таким образом, Unity High Definition Render Pipeline (HDRP) наиболее приближен к процессу рендеринга в UNIGINE по сравнению с другими конвейерами рендеринга .  В Unity для определения объемов, в которых параметры и эффекты постобработки локально (или глобально) переопределяются, используется фреймворк Volume .  В UNIGINE для плавной перехода между эффектами в различных областях необходимо написать собственную логику .  Unity UNIGINE Методы сглаживания: FXAA TAA SMAA MSAA Методы сглаживания: Fast approXimate Anti-Aliasing (FXAA) Temporal Anti-Aliasing (TAA) Subpixel Reconstruction Anti-Aliasing (SRAA) Supersampling Ambient Occlusion Screen-Space Ambient Occlusion Auto Exposure Эффекты камеры: Adaptive Exposure White Balance Tone Mapping Bloom Lens Dirt White Balance Tonemapping Bloom Цветокоррекция: Tone Lookup Texture Color Correction Color Correction LUT Chromatic Aberration Материалы постобработки: post_color_correction Grain Deferred Fog Haze Depth of Field Depth of Field Motion Blur Motion Blur Screen Space Reflection SSR (Screen Space Reflections) Contact Shadows Screen Space Shadows Micro Shadows Cavity of SSAO (Screen Space Ambient Occlusion) Материал получился объемный, но это лишь первый, обобщенный выпуск из запланированных трех по миграции с Unity .  Следующий выпуск будет более специализированным и расскажет про миграцию на UNIGINE с точки зрения 3D-художника .  А в последнем разберем все важные моменты по этому вопросу для программистов .  Чтобы получить доступ к бесплатной версии UNIGINE 2 Community заполните форму на нашем сайте .  Все комплектации UNIGINE: Community — базовая версия для любителей и независимых разработчиков .  Достаточна для разработки видеоигр большинства популярных жанров (включая VR) .  Engineering — расширенная, специализированная версия .  Включает множество заготовок для инженерных задач .  Sim — максимальная версия платформы под масштабные проекты (размеров планеты и даже больше) с готовыми механизмами симуляции .  Подробнее о комплектациях и ценах Пользователь ',\n",
              " 'Проведенный нами тест NVIDIA A4000 почти подтвердил, что она способна вытянуть на энкодинге до 16 независимых видеопотоков FullHD в формате H264 .  Удастся ли кратно увеличить производительность с профессиональной видеокартой, которая стоит в два раза дороже ?  Попробуем проверить .  В нашей второй статье про энкодинг (с тестом А4000) мы упустили, что видеопоток бывает и большего разрешения, поэтому стоит протестировать энкодинг файлов в формате 4К .  Для полноты картины мы также сравним энкодинг на решениях от NVIDIA с встроенным GPU от Intel .  Некоторые профессионалы полагают, будто достаточно собрать тот же FFmpeg с включенным QuickSync и внешняя видеокарта станет не нужна .  Проверим и это утверждение .  Мы не будем подробно расписывать процесс тестирования для видеокарт от NVIDIA и зачем нам FFmpeg, поскольку информация об этом есть в предыдущих статьях (первая и вторая части) .  Лучше сосредоточимся на новых результатах и полезных лайфхаках .  Используем тот же самый тестовый стенд из имеющихся в наличии серверов HOSTKEY, но установим в него видеокарту NVIDIA A5000 с большим количеством блоков энкодинга, 24 ГБ видеопамяти и более высоким энергопотреблением .  Для начала проверим ее работу на количестве потоков, оказавшемся предельным для А4000 по результатам предыдущего теста:14 потоков gpu pwr gtemp mtemp sm mem enc dec mclk pclk fb bar1 Idx W C C % % % % MHz MHz MB MB 0 97 47 - 92 3 100 0 7600 1920 3502 33 frame=1015 fps=31 q=28.0 Lsize= 9056kB time=00:00:33.80 bitrate=2194.8kbits/s speed=1.02x Удивительно !  Мы получили сравнимые с результатом A4000 цифры .  Несмотря на большую частоту работы чипа, больший объем используемой видеопамяти и большее энергопотребление, A5000 осилила энкодинг только 14 потоков и спасовала на пятнадцатом .  Это фиаско еще раз доказывает, что профессиональные видеоадаптеры предназначены для других целей .  Теперь попробуем запустить трансляцию потока с разрешением 3840x2160 (оно же 4K), благо есть и такая версия файла про кролика .  Энкодинг силами только центрального процессора захлебнулся уже на одном потоке, когда объем данных кратно увеличился: frame= 2902 fps=27 q=29.0 size=104448kB time=00:01:33.56 bitrate=9144.7kbits/s dup=436 drop=0 speed=0.878x Каковы возможности GPU (помним, результаты у A4000 и A5000 сравнимы) ?  Это 3 потока .  gpu pwr gtemp mtemp sm mem enc dec mclk pclk fb bar1 Idx W C C % % % % MHz MHz MB MB 0 96 46 - 100 3 96 0 7600 1920 1112 9 Как видим, по потребляемой мощности и загрузке блоков энкодинга видеочип работает явно не в режиме повышенного комфорта, хотя при этом расходуется лишь около 1 ГБ видеопамяти.Вывод FFmpeg подтверждает, что видеокарта справляется: frame= 1465 fps=33 q=35.0 Lsize=12584kB time=00:00:48.80 bitrate=2112.4kbits/s dup=159 drop=0 speed=1.09x А вот 4 потока адаптер уже не переваривает .  Хотя загрузка железа остается примерно на тех же значениях, начинаются просадки по кадрам: frame= 614 fps= 26 q=35.0 Lsize=4978kB time=00:00:20.43 bitrate=1995.6kbits/s speed=0.858x Если верить заявлению компании-разработчика, технология QuickSync должна «используя специальные возможности обработки мультимедийных данных графических технологий Intel® для ускорения декодирования и кодирования, позволить процессору параллельно выполнять другие задачи и повышая быстродействие системы» .  Для тестов понадобился подходящий процессор Intel (мы нашли машину с Core i9-9900K CPU @ 3.60GHz) и собранная с поддержкой Quick Sync утилита FFmpeg .  С первым проблем не возникло (достаточно чипа старше 6-го поколения и наличия в нем GPU, что несложно проверить), но сборка FFmpeg под тестовую Ubuntu 20.04 вызвала стойкие ассоциации с практическим освоением Камасутры .  Чтобы не заставлять вас тратить драгоценное время, опишем, как нам удалось решить проблему.Поскольку пакеты в репозиториях сломаны, первым делом нужно собрать и установить в систему библиотеки gmmlib и libva, а также последние версии Intel media driver и Media SDK .  Для этого в домашней директории создадим папку GIT, зайдем в нее и выполним последовательно следующие команды (если будет не хватать каких-то зависимостей, установим их из репозитория; мы рекомендуем сделать sudo apt install autoconf automake build-essential cmake pkg-config): Затем нужно собрать FFmpeg с помощью нескольких магических команд: Стоит убедиться, что у нас появилась поддержка Quick Sync: Вывод команды должен быть примерно таким: Ура !  Все готово к тестам .  Для начала проверим, как справляется с энкодингом видео в FullHD процессор без Quick Sync: он выдерживает максимум 4 потока, при которых все ядра загружены под 100% frame= 1461 fps= 33 q=29.0 size=24064kB time=00:00:46.33 bitrate=4254.7kbits/s speed=1.05x Пятый поток процессор уже не осиливает, поэтому можно смело приступать к тесту с Quick Sync .  В скрипте из предыдущей статьи для этого нужно будет заменить энкодер на h264_qsv, и он примет следующий вид (подробнее об использовании QuickSync с FFmpeg можно почитать тут): Сразу делаем проверку на 6 потоках (+2 к тесту на чистом CPU): frame=291 fps=55 q=29.0 size=1280kB time=00:00:10.13 bitrate=1034.8kbits/s dup=2 drop=0 speed=1.93x Разница очевидна: загрузка процессора не превышает 50%, а имеющийся запас вычислительных ресурсов позволяет прогнозировать 11 – 12 итоговых потоков.Ставим 11 потоков: frame=157 fps=30 q=38.0 Lsize=628kB time=00:00:05.69 bitrate=903.0kbits/s dup=2 drop=0 speed=1.09x Загрузка процессора возрастает незначительно, но GPU уже подходит к пределу возможностей .  Двенадцатый поток роняет битрейт и скорость обработки до 24 – 28 кадров.Теперь проверяем потоки в 4K .  В отличие от AMD, наш процессор Intel спокойно обрабатывает один поток в таком разрешении и без аппаратного ускорения:frame=655 fps=31 q=-1.0 Lsize=30637kB time=00:00:21.73 bitrate=11547.9kbits/s speed=1.03xНа большее он, увы, не способен .  С включенным Quick Sync тестовый компьютер смог вытянуть три потока с разрешением 4K:frame= 509 fps=31 q=33.0 Lsize=8010kB time=00:00:17.42 bitrate=3764.7kbits/s dup=2 drop=0 speed=1.07xСпасовал он только на четвертом, но столько же у нас выдержала и видеокарта Nvidia A5000 .  Недостатки у решения, увы, тоже есть .  При использовании модуля BMC (к примеру, при управлении машиной через IPMI), вы не получите доступ ко всем возможностям аппаратного ускорения, даже если GPU процессора будет определяться в системе .  Придется выбирать между удобством удаленного управления или получением всех плюсов от использования Quick Sync .  Выводы вы можете сделать самостоятельно .  Мы лишь отметим, что для энкодинга видео разница в мощности видеокарт не всегда определяется их ценой, а для решения некоторых задач стоит обратить внимание на специализированные технологии внутри центральных процессоров .  Также мы использовали для тестов H264, но кодеки HEVC (H265) или VP1 в теории должны дать лучшие результаты, особенно на разрешениях 4K .  Если вы самостоятельно проведете подобные тесты с первым (VP1 пока что представлен аппаратно и массово только для декодинга), поделитесь результатами в комментариях .  ____________ Стоимость описанных выше экспериментов измерить просто: воспользуйтесь нашим калькулятором-конфигуратором на этой странице .  Например, в самой простой конфигурации она следующая: машина с A4000 обойдется в 22 000р, 12 потоков - 1800р на поток в месяц; машина с A5000 обойдется в 31 000р, 14 потоков - 2214р на поток в месяц; сервер на i9-9900K с QuickSync (QSV) обойдется в 5000-6000р, 11 потоков, 450р на поток .  Серверы для такого необходимо собирать на материнских платах без удаленного управления, что мы умеем .  Обращайтесь !  Кстати, все серверы HOSTKEY предоставляются с нашим модулем полного удаленного управления сервером IPMI и панелью управления серверами и API .  Об устройстве последней мы рассказали в этой статье .  Пользователь ',\n",
              " 'Привет !  Перевод пятой лекции о создании Super Mario Bros .  В этом видео: Тайловые карты .  2D-анимация .  Процедурная генерация уровней .  Физика платформера .  Пользователь ',\n",
              " 'Профессиональные GPU в серверах позиционируются как устройства для высокопроизводительных вычислений, систем искусственного интеллекта и рендеринговых ферм для 3D-графики .  Стоит ли их применять для энкодинга, или это стрельба из пушки по воробьям ?  Попробуем разобраться .  Для работы с многопоточным видео достаточно мощностей современных CPU и решений наподобие Intel Quick Sync .  Более того, некоторые специалисты считают, будто загрузка профессиональных GPU декодингом и энкодингом — пустая трата ресурсов .  Для потребительских видеокарт количество входящих потоков специально ограничивают до двух-трех, хотя мы уже убедились, что небольшое шаманство с драйвером позволяет это ограничение обойти .  В предыдущей статье тестировались бытовые видеокарты, а сейчас мы займемся более серьезными — NVIDIA RTX A4000 .  Что делать, если вывод lscpu выдает вам что-то вроде AMD Ryzen 9 5950X 16-Core Processor, но в компьютер вставлена NVIDIA RTX A4000 с 16 ГБ оперативной памяти, а вы хотите перекодировать и записать поток с нескольких сетевых камер ?  Информация с них обычно поступает через http, rtp или rtsp, и наша задача — поймать эти потоки, перекодировать их в нужный формат и записать каждый в отдельный файл .  Для проверки мы в HOSTKEY создали небольшой тестовый стенд из имеющихся выделенных серверов с указанной выше конфигурацией CPU/GPU без специальной оптимизации и 32 ГБ оперативной памяти .  На нем через FFmpeg мы будем принимать мультикаст-вещание в форматах http и rtsp (использован видеофайл bbb_sunflower_1080p_30fps_normal.mp4 из деморепозитория Blender), декодировать его в разном количестве потоков FFmpeg и записывать каждый из них в отдельный файл .  Как видно из названия, мы принимаем поток в формате 1080p (30 кадров в секунду) .  Энкодинг будет применяться только к видео, а звуковые потоки пойдут без изменения .  Также несущественно, берем мы один входящий поток и имитируем его мультипоточность или параллельно обрабатываем несколько потоков .  Работа с сетью и текущие процессы на тестовом стенде отнимают менее 1% ресурсов CPU, поэтому можно считать, что основную нагрузку на процессор и дисковую подсистему даст именно энкодинг .  Все дальнейшее повествование будет вестись для вещания через http, поскольку результаты для потока rtsp оказались сравнимыми .  Чтобы не плодить множество консолей терминала на сервере, для теста были созданы простые bash-скрипты, в которые при запуске передается требуемое количество инстансов FFmpeg, перекодирующих видеопоток в h264 .  Энкодинг на голом CPU: На GPU мы будем использовать возможности видеокарты через NVENC (как собрать FFmpeg с его поддержкой, мы рассказывали в первой статье цикла): Скрипты запускают в цикле мультикаста и ловят в сети нашего кролика .  Предварительно стоит проверить через тот же vlc или ffplay, что поток реально вещается .  Результат мы будем оценивать по загрузке CPU/GPU, утилизации памяти и качеству записываемого видео, где главными для нас будут два параметра: fps (он должен быть стабильным и не опускаться ниже 30 кадров в секунду) и speed (показывает, успеваем ли мы обрабатывать видео на лету) .  Для realtime параметр speed должен быть больше 1.00x .  Проседания этих двух параметров приводят к выпадению кадров, артефактам, проблемам кодировки и другим повреждениям картинки, которые не хотелось бы видеть на записях с камер видеонаблюдения .  Запуск одной копии FFmpeg дает нам такую начальную картину: Загрузка по ядрам процессора в среднем на уровне 18–20%, а вывод FFmpeg показывает следующее: Запас есть, и можно попробовать сразу три потока: Четыре потока выбирают почти все мощности CPU и «отъедают» 13 ГБ оперативной памяти .  При этом вывод FFmpeg показывает, что резервы не исчерпаны: Увеличиваем количество потоков до пяти .  Процессор держится на пределе, местами начинаются просадки скорости кадров и битрейта на 5–10%: Запуск шести потоков показывает, что предел достигнут .  Мы все больше и больше отстаем от реального времени и начинаем пропускать кадры: Запускаем один поток FFmpeg с энкодингом через h264_nvenc .  Убеждаемся через вывод nvidia-smi, что у нас задействована именно видеокарта: Поскольку вывод достаточно громоздкий, мы будем отслеживать параметры GPU с помощью следующей команды: Расшифруем обозначения: pwr — потребляемая видеокартой мощность в ваттах; gtemp — температура видеоядра (в градусах Цельсия); sm — SM, mem — память, enc — энкодер, dec — декодер (утилизация их ресурсов указана в процентах); mclk — текущая частота памяти (в МГц), pclk — текущая частота процессора (в МГц); fb — использование кадрового буфера (в Мб) .  gpu pwr gtemp mtemp sm mem enc dec mclk pclk fb bar1 Idx W C C % % % % MHz MHz MB MB 0 35 48 – 1 0 6 0 6500 1560 213 5 Нас в этом выводе будут интересовать значения загрузки энкодеров GPU и утилизации видеопамяти .  Вывод FFmpeg дает следующие результаты: Запускаем сразу пять потоков .  Как видно из вывода htop, в случае энкодинга на GPU загрузка процессора минимальна, а большая часть работы ложится именно на видеокарту .  Дисковая подсистема также загружена гораздо меньше .  gpu pwr gtemp mtemp sm mem enc dec mclk pclk fb bar1 Idx W C C % % % % MHz MHz MB MB 0 36 48 – 8 2 40 0 6500 1560 1035 14 Загрузка блоков энкодинга увеличилась до 40%, память мы заняли почти на гигабайт, но видеокарта по факту загружена не сильно .  Вывод FFmpeg подтверждает это, показывая, что у нас есть ресурсы для увеличения количества потоков минимум в 2 раза: Ставим десять потоков .  Утилизация CPU на уровне 15–20% .  Параметры видеокарты: gpu pwr gtemp mtemp sm mem enc dec mclk pclk fb bar1 Idx W C C % % % % MHz MHz MB MB 0 55 48 – 14 4 61 0 6500 1920 2064 24 Потребление электроэнергии возросло, видеокарта вынуждена была разогнать частоту видеоядра, но мощности энкодинга и видеопамять позволяют увеличивать нагрузку .  Проверяем вывод FFmpeg, чтобы в этом убедиться: Пробуем добавить еще четыре потока и получаем загрузку блоков энкодинга в 100% .  gpu pwr gtemp mtemp sm mem enc dec mclk pclk fb bar1 Idx W C C % % % % MHz MHz MB MB 0 68 59 – 18 7 100 0 6500 1920 2886 33 Вывод FFmpeg подтверждает, что мы достигли предела .  Утилизация CPU при этом все еще не превышает 20% .  Контрольные 15 потоков показывают, что GPU начинает сдавать, так как блоки энкодинга работают с перегрузкой, а также наблюдается рост температуры и потребляемой мощности .  gpu pwr gtemp mtemp sm mem enc dec mclk pclk fb bar1 Idx W C C % % % % MHz MHz MB MB 0 70 63 – 18 7 100 0 6500 1920 3092 35 FFmpeg также подтверждает, что видеокарте становится тяжеловато .  Частота обработки и пропуск кадров уже не внушают оптимизма: Подытожим: применение GPU в такой конфигурации можно назвать оправданным, поскольку максимальное количество обрабатываемых видеокартой потоков в 3 раза превышает возможности далеко не самых слабых процессоров (особенно без поддержки технологий аппаратного кодирования) .  С другой стороны, мы используем только минимальную часть возможностей видеоадаптера .  Поскольку остальные его блоки и видеопамять не сильно нагружены, ресурсы дорогостоящего устройства утилизируются неэффективно.Искушенные читатели могут заметить, что мы не проверили работу в режимах 2K/4K, не использовали возможности современных кодеков (наподобие h265 и VP8/9), а также установили в тестовый стенд видеоадаптер на архитектуре предыдущего поколения .  Тот же A5000 должен показать лучший результат: его работу мы проверили в следующей статье, где немного препарировали и Intel Quick Sync .  Оправдались ли надежды, можно узнать здесь .  Напишите в комментариях, какие еще нюансы стоит учесть при тестировании, какие моменты мы упустили и что бы вы хотели узнать по этой теме .  Стоимость описанных выше экспериментов измерить просто: можно воспользоваться нашим калькулятором-конфигуратором на этой странице .  На, например, современных Xeon она следующая: машина с A4000 в самой простой конфигурации обойдется в 22000р, 12 потоков - 1800р на поток в месяц; машина с A5000 в самой простой конфигурации обойдется в 31000р, 14 потоков - 2214р на поток в месяц; сервер на i9-9900K в самой простой конфигурации с QuickSync (QSV) обойдется в 5000-6000р, 11 потоков, 450р на поток .  Серверы для такого необходимо собирать на материнских платах без удаленного управления, что мы умеем .  Обращайтесь !  Кстати, все серверы HOSTKEY предоставляются с нашим модулем полного удаленного управления сервером IPMI и панелью управления серверами и API .  Об устройстве последней мы рассказали в этой статье .  Пользователь ',\n",
              " 'В виду того, что мне срезали подписку на Medium решил поддерживать отечественные IT ресурсы .  Попробую кидать интересные статьи с переводом на русском, а правообладатели пусть сами разбираются, я честно платил за подписку .  На текущий момент VS Code остается средой разработки, которая доступна в период санкций, когда JetBrains отказался продавать лицензии, про Visual Studio даже не узнавал .  Сам использую VS Code много лет в разных стеках .  VS Code предоставляет возможности разработки практически во всех направлениях: веб-разработка, мобильные приложения, часто встречаются приложения для встраиваемых систем .  Ниже перечислены наиболее популярные расширения, которые облегчают разработку приложений .  Atom One Dark Theme При всем изобилии тем в VS Code тема Atome One Dark наиболее популярная, потому-что имеет наиболее удачный контраст и прекрасно выглядит .  Установка ext install akamud.vscode-theme-onedark VSCode Great Icons Популярное расширение для иконок .  Кому как красивее и удобнее решайте сами .  Установка ext install emmanuelbeziat.vscode-great-icons Hungry Delete Очень простое, но очень полезное расширение .  Помогает при удалении нескольких пустых строк .  Позволяет удалить все пустые строки клавишами Ctrl-Backspace для Windows, Linux и Alt+Backspace для Mac .  Чтобы удалить строки снизу служит комбинация клавиш Ctrl+] .  Поддерживает удаление в режиме мультикурсор .  Функция Smart Backspace позволяет выравнивать код при нажатии клавиши Backspace .  ext install jasonlhy.hungry-delete Live Server Простое и удобное расширение для веб-разработки .  Позволяет запускать статические веб-страницы в режиме локального сервера .  Поддерживается перезагрузка страниц при изменении исходных файлов .  Поддерживает команды контекстного меню в Проводнике и в редакторе кода .  ext install ritwickdey.LiveServer TabOut Расширение, похожее на Hungry Delete, но в отличии от него запускается через меню команд .  ext install albert.TabOut Если вы никогда не использовали сниппеты, стоит о них подумать, они делают нашу жизнь легче и упрощают работу с часто используемыми блоками .  Сниппеты - небольшие преднастроенные строки, которые позволяют заполнять большие куски кода .  Удобно использовать в React компонентах, где большое количество повторяемого шаблонного кода .  Установка React сниппетов ext install runningcoder.react-snippets Список расширений, который может заинтересовать Vim - эмулятор Vim редактора в VS Code .  Auto Close Tag - автоматически добавляет закрывающие теги для HTML/XML .  Git Graph - визуальное представление для веток Git репозитория .  Проще один раз увидеть .  Таблица горячих клавиш для VS Code Кидайте в комментарии расширения, которые используете вы.. .  Пользователь ',\n",
              " 'В этой статье я покажу простой способ генерации видео программами на Python и C/C++ без использования стороннего API .  Вам так же потребуется ffmpeg, без него вы не сможете конвертировать файлы в читаемые форматы !  Можно экспериментировать, например вы можете создать видео максимального качества и проверять как оно будет эффективно сжиматься тем или иным видео кодеком .  Можете даже создать картинку с градиентом в 64-битном цвете и с дизерингом, мало ли какие ещё извращения можно придумать .  Можно ещё делать видео с быстро движущимися объектами и сохранять его в 1000 кадров в секунду и потом тестировать всякие интерполяторы движения и моушн блюры .  С помощью скрипта на Python можно создать видео .  Просто сохраните этот код в какой-нибудь \"main.py\" Далее исполняете команду в консоли: python main.py | ffmpeg -y -f rawvideo -pixel_format gray -video_size 320x240 -framerate 25 -i pipe: out.mkvВ результате у вас получится двухсекундное видео с узором out.mkv .  В командную строку в Windows и Linux можно выводить не только текст, но и бинарные данные файлов, а так же эти данные можно перенаправлять в другую программу, в данном случае это ffmpeg который принимает RAW кадры и конвертирует их в видео .  И в коде и в команде вызова должны совпадать fps/framerate и video_size/w/h иначе всё разъедется .  Нельзя просто взять и написать данные пикселей в консоль через print, нужно записывать их в stdout как в файл через os.write .  Если в коде изменить duration на 1, то создастся только один кадр с узором и его можно сохранить как картинку так:python main.py | ffmpeg -y -f rawvideo -pixel_format gray -video_size 320x240 -i pipe: out.png Конечно Питон это медленно и я покажу как сделать это на C и C++, в этих языках стандартный поток вывода stdout тоже считается файлом и в него можно записывать бинарные данные .  Сборка и запуск:g++ -Wall -O2 main.cpp -o progprog | ffmpeg -y -f rawvideo -pixel_format gray -video_size 320x240 -framerate 25 -i pipe: out.mkv Сборка и запуск::gcc -Wall -O2 main.c -o progprog | ffmpeg -y -f rawvideo -pixel_format gray -video_size 320x240 -framerate 25 -i pipe: out.mkv Упрощённый вариант от @staticmain: Cборка и запуск:gcc -Wall -O2 main.c -o progprog | ffmpeg -y -f rawvideo -pixel_format gray -video_size 320x240 -framerate 25 -i pipe: out.mkv Я специально не указывал выходной видео кодек для упрощения команд, но вы можете добавить в ffmpeg опции -vcodec libx264rgb -crf 0 для сохранения видео в lossless качестве .  Если вы модернизируете программу и добавите в неё поддержку RGBA цвета, то помните что h264 не умеет сохранять прозрачность в кадрах и вам лучше использовать кодек FFV1 .  Можно сгенерировать видео на любом языке программирования, если на нём можно переключить стандартный вывод в бинарный режим .  По такой же логике можно и перенастроить поток ввода stdin в бинарный режим и передать в программу бинарные данные из ffmpeg, таким образом можно будет смастерить видео-фильтр .  В общем надо сделать что-то типа того:ffmpeg | фильтр | ffmpeg .  Вообще можно просто написать Frei0r фильтр на Си и использовать его в ffmpeg, но мой способ просто не требует никакого стороннего API .  Поток можно перенаправлять и в файл и потом этот файл скармливать ffmpeg\\'у, но учтите что видео будет совсем без сжатия и несколько секунд видео 1280x720 будут весить гигабайты .  Сделать это можно так:prog > video.datfmpeg -y -f rawvideo -pixel_format gray -video_size 320x240 -framerate 25 -i video.dat out.mkv Раз можно сгенерировать сырое видео, то можно и создать сырой PCM звук и конвертировать его в аудио форматы .  Можно например генерировать мелодии и сохранять их в pcm_s16le поток .  Опять же переключив stdin в pipe режим вы можете получать аудио поток извне, обрабатывать его своей программой и передавать далее, таким образом у вас получится аудио фильтр и не надо никакого VST/LADSPA API .  Это очень простой способ создания видео (для программиста) .  Если что, в ffmpeg уже встроены некоторые генераторы тестовых видео .  Сохраняются ли гигабайты сырых кадров в оперативной памяти при использовании такого способа передачи или же на диске - мне это неизвестно, возможно что у такого способа есть какие-то ограничения на размер передаваемых данных .  Помните что в передаваемом потоке данных нет никаких меток синхронизации и если что-то где-то потеряется в пути, то видео всё станет кашей, так что не пытайтесь передавать такой поток через net cat (я не пробовал) .  Разработчик игр ',\n",
              " 'В 2014 году вместе с релизом Android 5.0 Lollipop Google представил миру концепцию Material Design .  Каждый элемент в системе состоит из «материала», идею которого хорошо описал дизайнер Матиас Дуарте: «В отличие от настоящей бумаги цифровой материал может разумно расширяться и преобразовываться .  Материал имеет физические поверхности и края .  Швы и тени придают смысл тому, к чему можно прикоснуться» .  В 2018 году увидела свет вторая версия Material .  В ней сделали больше возможностей для кастомизации: обновили цветовую схему, обновили гайдлайны по работе со шрифтами, добавили поддержку форм (не форм ввода данных, а shapes у компонентов) .  Появилось больше способов выразить через стандартные компоненты Material айдентику — внешний визуальный интферфейс бренда .  Но Google и на этом не остановился: именно поэтому сейчас вы читаете эту статью .  В 2021 году на Google I/O представили концепцию Material You — новую версию Material под номером 3 .  По сравнению с прошлым обновлением изменений действительно много .  Цель новой концепции — персонализировать пользовательский опыт .  Меня зовут Тимур Задворнов, я Android-разработчик в Surf .  В статье обсудим: обновление цветовой палитры Material, Dynamic Color, обновление UI-компонентов .  Но сначала — вводная часть: разберём базовое устройство цветовой палитры Material .  Это поможет лучше понять обновления в Material 3: что они означают и как с ними работать .  Дисклеймер: эта статья — больше про дизайн, чем про разработку и использование компонентов в коде .  Material-палитра состоит из шести ключевых цветов: Primary Secondary Background Surface Error Outline Primary и Secondary — первичный и вторичный цвета, основные акцентные цвета приложения, цвета бренда .  Здесь всё очевидно .  Например, у YouTube Primary цвет — #ff0000 (красный), у Twitter — #1d9bf0 (синий) .  Background и Surface — цвета поверхностей, на которых располагается контент .  Background-цвет — цвет фона приложения, а Surface — цвет поверхностей компонентов в приложении .  Самый яркий пример — карточки (Card View) .  У Card View стандартный цвет фона — Surface .  Давайте вспомним базу Material .  Как располагаются компоненты в приложении относительно друг друга ?  В гайдлайнах Material это описано подробно, но мы пробежимся очень кратко .  Компоненты в приложении находятся на разных высотах относительно оси Z .  В светлой теме высота показывается с помощью тени под компонентом .  В тёмной теме это не сработает: тени не будет видно .  Решение простое и элегантное: чем выше контент по оси Z, тем ближе он будет к источнику света (поверхности экрана) и тем светлее будет компонент .  Тут-то и приходит на помощь Surface-цвет !  Если задать цвет Surface, при изменении elevation цвет контента будет меняться автоматически без лишних строк кода .  Маппинг значений elevation в значение яркости поверхности хорошо описан в документации и хорошо отображен на визуализации ниже .  Этот момент достаточно сложный для понимания, поэтому вопросы по цветам жду в комментариях, подискутируем :) Цвет Error — цвет для отображения ошибок .  В объяснении, думаю, не нуждается .  Outline — цвет для обводки различных компонентов .  Самый яркий пример — Outlined Text Field .  С ключевыми цветами покончили .  Остаются только их вариации — on-цвета .  On-цвета — цвета, которые будут идеально смотреться на «поверхности», окрашенной в основной или второстепенный цвета, цвета поверхности, фона или ошибки .  Сразу привожу пример: у красного Error-цвета OnError-цвет логично будет белым, потому что он хорошо читается на красном фоне .  У каждого цвета, кроме Outline, есть соответствующий ему on-цвет: у Primary есть OnPrimary, у Surface есть OnSurface и так далее .  Базу цветовой схемы Material разобрали .  Перейдём к нововведениям .  В палитру добавили Tertiary-цвет и все его вариации .  Tertiary — третий цвет для айдентики бренда наряду с Primary и Secondary: иногда двумя цветами бренду ограничиться непросто .  Появился новый Surface-цвет — SurfaceVariant (вместе с OnSurfaceVariant) .  Это второй вариант для цветов поверхностей .  Можно использовать, например, в качестве цвета текста на поверхностях или цвета дивайдеров .  Ещё одна новинка палитры Material — Container-цвета .  Container-цвета — новая вариация цветов, которая используется в контейнерах с компонентами .  Яркий пример — Floating Action Button .  Начиная с Material 3, цвет фона у этой кнопки стал PrimaryContainer, а цвет контента на этой кнопке — OnPrimaryContainer .  У Container вариаций также есть злой двойник — On-цвет .  Как Google собирается делать девайсы более персональными с Material You ?  С помощью Dynamic Color — одного из главных нововведений Material 3 !  Dynamic Color (динамический цвет) — фича, которая генерирует цветовую палитру по обоям пользователя и распространяет её на все приложения в системе (которые, естественно, поддерживают Dynamic Color) .  Как генерируется цвет ?  Цветовую палитру создаёт встроенный в Android 12 Monet Engine: он извлекает из обоев так называемый seed color и по нему генерирует палитру .  Тональная палитра состоит из тринадцати тонов, включая белый и черный .  Значение тона 100 эквивалентно представлению о максимальном освещении и даёт белый цвет .  Значение тона 0 — чистый чёрный цвет .  Каждое значение тона от 0 до 100 выражает количество света, присутствующего в цвете .  В Android генерируется пять ключевых цветов: Accent1 (используется для Primary), Accent2 (для Secondary), Accent3 (для Tertiary), Neutral1 (для Background и Surface), Neutral2 (для SurfaceVariant и Outline) .  Плюс 13 их вариантов с разной тональностью .  Сгенерированную палитру можно посмотреть с помощью виджета-пасхалки в Android 12 .  Теперь сопоставим все данные вместе: у нас есть большая сгенерированная палитра цветов и система цветов Material .  На картинке ниже — готовая цветовая схема приложения, сгенерированная лишь по одному seed color .  Сгенерировать свою палитру по канонам Material 3 можно с помощью Material Theme Builder .  Также оттуда можно выгружать темы в виде стилей XML и стилей Jetpack Compose .  В Material 3 обновили гайдлайны по UI-компонентам: кнопкам, чипам, диалогам, карточкам и панели навигации .  Сolor mapping у всех компонентов соответствует гайдлайнам Material 3 и поддерживает Dynamic Color .  Поговорим подробнее про каждый из компонентов .  Обновили всё: обычные кнопки, FAB (floating action button) и Extended FAB .  Новое в обычных кнопках: Полностью закруглили углы .  Поменяли размеры кнопок: стандартную высоту подняли с 36dp до 40dp, размер иконки в кнопке увеличили до 18dp .  Текст в кнопках теперь пишется не капсом, а с большой буквы (sentence case) .  Добавили 3 типа кнопок: filled — с бэкграундом primary, secondary, tertiary или какого угодно цвета, filled tonal — с бэкграундом container цвета) и elevated кнопки — с тенью .  Вот они слева направо: Filled, Filled Tonal, Elevated, Outlined, Text .  Новое в FAB: Изменили форму: теперь FAB — квадратные с закругленными углами, а не круглые .  Добавили новый тип — Large FAB .  Обновили цветовую палитру кнопки: теперь бэкграунд по гайдлайнам должен иметь Container-цвет (Primary, Secondary или Tertiary), а контент на кнопке — соответствующий On-Container цвет .  Новое в Extended FAB: Изменили форму: Extended FAB теперь тоже стали квадратные с закругленными углами .  Обновили цветовую схему по аналогии с обычными FAB .  Обновили размеры кнопки, если в ней есть текст: теперь по высоте она точно такая же, как и обычный FAB .  Чипы — компоненты, которые помогают пользователю вводить и фильтровать информацию .  Что нового: Обновили форму компонента .  Теперь они все одинаковые: прямоугольные с закруглениями по углам .  Разделили чипы на четыре типа: Assist, Filter, Input, Suggestion .  Assist — для «умных» или автоматизированных действий: например, добавить событие в календарь .  Ближайший визуальный аналог — обычная кнопка .  Filter — кнопка для фильтрации данных .  Input — данные, которые были введены пользователем .  Яркий пример: ввод адреса электронной почты, когда данные из текстового поля преобразуются в данные в чипе .  Suggestion-чипы помогают сузить намерения пользователя: предлагают динамические предположения о возможных действиях пользователя — например, варианты ответа на сообщение в мессенджере .  Обновления в диалогах: Увеличили паддинг контента .  Увеличили радиус закругления углов .  Обновили шрифты .  В стандартный диалог добавили иконку над заголовком диалога .  Также Google выкатил гайдлайны по реализации полноэкранных диалогов .  Их можно использовать для ввода данных на экранах мобильных устройств .  Правда, на планшетах этот диалог будет не полноэкранным, а обычным .  В Android всю жизнь было два способа построить user-friendly навигацию: боковой бар и нижний .  С Material 3 в Android унифицировали нейминг баров навигации и добавили новый вид — Navigation Rail .  Navigation Bar — переименованный Bottom Navigation .  Navigation Drawer — боковая панель навигации .  Можно вызвать по свайпу с левой стороны экрана или, если экран большой, закрепить в левой части .  Navigation Rail — тоже боковая панель навигации, но более узкая: как вертикальный Navigation Bar .  Обновлений по барам навигации не так много: обновили цветовую схему, добавили закругления, изменили размеры некоторых компонентов .  Хочу остановиться только на Navigation Rail .  По гайдлайнам его советуют использовать для больших экранов вместо Navigation Bar, который неопрятно растягивается на всю ширину внизу экрана .  Изменения коснулись и больших экранов .  В преддверии выхода Android 12L Google показал гайдлайны по дизайну приложений, которые адаптированы для разных экранов: мобильного, складного и большого .  Обновление затронуло много компонентов, о которых нет смысла рассказывать отдельно .  А вот карточки сильно перерабатывать не стали .  Помимо цветовой схемы, изменений минимум: : У карточки убрали elevation .  Карточки разделили на 3 типа: Elevated (с тенью), Filled (залитая цветом) и Outlined (с обводкой) .  Та же ситуация и с тулбарами: немного изменили цветовую схему, позиционирование текста для разных видов тулбара, обновили шрифты, убрали elevation .  Третье обновление концепции Material выдалось весьма объемным и принесло много нового, в частности, в дизайн Android .  Тезисно: Много нового появилось в палитре Material (надеюсь, вам помог мой краткий экскурс в палитру) .  Dynamic Color — интересная вещь .  Мне нравится, что с Android 13 все вендоры обязаны будут поддержать эту фичу .  Но есть сомнения, что все сторонние приложения в ближайшее время начнут поддерживать динамические цвета .  Обновили компоненты, API для работы с ними в Material Design Components и обновляют API для работы с ними на других платформах (Jetpack Compose, Flutter, Web) .  К сожалению, в Material You пока что есть недоработки .  По состоянию на февраль 2022-го: Обновлены не все компоненты .  На текущий момент Material You-гайдлайны полностью поддерживает только Material Design Components — старый подход к разработке Android-приложений .  Для Jetpack Compose вышла альфа-версия библиотеки Material 3 .  Для Flutter поддержка новых гайдлайнов находится в активной разработке .  Поддержка для Web только в планах .  Пользователь ']"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jf1M5yEJ4hvS"
      },
      "outputs": [],
      "source": [
        "new_li=[]\n",
        "import re\n",
        "for elem in new_p:\n",
        "    ne_elem = elem.split()\n",
        "    #print(ne_elem)\n",
        "    for word in ne_elem:\n",
        "        #print(word)\n",
        "        #if re.search(r'\\.$', word):\n",
        "            #word1 = re.sub(r'([?!.])$',r' \\1 ',word)\n",
        "        elem_new = word.replace(word + r'\\.$', word+' . ')\n",
        "        \n",
        "        print(elem_new)\n",
        "        new_li.append(elem_new)\n",
        "#new_li"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "QBWRHe6F6Ef9",
        "outputId": "d8a30243-eb0f-4ada-cb88-25f22f1b5f60"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'За последнее время значимость голосовых функций и звука заметно выросла. Примером тому может служить уже громкая история запуска приложения Clubhouse, голосовых ассистентов Сбера и общего оживления интереса со стороны пользователей, компаний и инвесторов к звуку на мобильных устройствах. В этой статье я бы хотел рассмотреть пример разработки голосового помощника на платформе iOS, используя язык Swift. На мой взгляд, звук как интерфейс между пользователем и приложениями изначально был недооценен, однако с появлением технологий искусственного интеллекта, высокой информационной нагрузки и нехватки времени, польза аудио становится очевиднее. Например, в этой статье представлены интересные факты об использовании голоса за последние 4 года и вывод: The key, however, is the device letting the human think and speak like a human. Once we get there, this whole voice thing will become the predominant mode for input. We’re likely five to ten years away from getting there. However, many businesses are seeing great success building their own personal assistant apps (aka Alexa Skills or Actions on Google apps) and developing a great deal of positive attention and visibility for their organizations. То есть, звук и голос как интерфейс имеют шанс стать преобладающим интерфейсом через 5-10 лет когда голосовые ассистенты будут достаточно умными и способными поддерживать разговор как человек. Исследования и развитие технологий в области ИИ в перспективе открывают перед нами подобные возможности. Сегодня есть достаточно большой выбор среди речевых технологий распознавания и синтеза речи. В качестве примера можно привести доступные речевые библиотеки Apple и Yandex. В Apple Speech Kit синтез и распознавание речи доступны «из коробки» для iOS 10 и выше, а для его использования необходимо подключить Speech.framework в проект. Распознавание речи на достойном уровне, а вот насчет синтеза не могу этого сказать. В компании Яндекс есть собственные технологии синтеза и распознавания речи — репозитории для iOS и Android с подробными примерами их использования. Напишем своё первое приложение, в котором используем перечисленные выше библиотеки. Создадим новый XCode проект, и поскольку мы будем пока тестировать различные SDK, то определим два таргета: speechkit_apple и speechkit_yandex. В качестве системы управления зависимостями будем использовать Cocoapods, поэтому в корне проекта необходимо создать Podfile: Переходим в корень проекта и выполняем pod install чтобы все зависимости установились: Оба таргета будут использовать общие ресурсы из папки speechkit_demo_ios и иметь свои реализации SpeechViewController: Для работы с микрофоном необходимо разрешение NSMicrophoneUsageDescription, а для распознавания речи NSSpeechRecognitionUsageDescription. Эти ключи и текстовые описания к ним нужно сразу добавить в Info.plist проекта: В итоге, получится примерно следующее: В случае Apple в проект необходимо подключить библиотеку Speech и использовать SFSpeechRecognizer, SFSpeechRecognitionTask и AVSpeechSynthesizer для распознавания и синтеза голоса. Для каждой новой сессии распознавания необходимо проделать следующие шаги: Cоздать новый запрос: Cоздать задачу распознавания: Cоздать и запустить захват аудио буфера из AVAudioEngine в запрос распознавания: Для синтеза речи необходимо инициализировать и запустить AVSpeechSynthesizer: Готовый пример приложения можно скачать здесь: chapter1_ios, проект speechkit_demo_ios, таргет speechkit_apple. Если вы используете Swift, то для подключения Yandex SpeechKit потребуется использовать Bridging-header для связи с Objective-C кодом, который использует эта библиотека. Самый простой способ быстро подключить Bridging-header — создать любой *.m файл в нужном таргете, а затем можно удалить этот файл. В нашем случае к проекту добавится speechkit_yandex-Bridging-Header.h, в котором нужно указать ссылку на header от Objective-C библиотеки компании Yandex: Далее в Swift коде уже не нужно подключать специально эту библиотеку через конструкцию виде import. Основные шаги инициализации: указание API ключа. Ключ необходимо создать в личном кабинете Yandex Cloud. Более подробную информацию можно найти в документации: активация аудиосессии не в главном потоке приложения (поскольку это может занимать некоторое время и блокировать UI): создание и инициализация экземпляров синтезатора и менеджера распознавания речи: синтез или старт распознавания речи: В нашем случае ViewController (у вас это может быть View Model или VIPER модуль) должен реализовать протоколы YSKVocalizerDelegate и YSKRecognizerDelegate для возможности получения событий от библиотеки: старт записи, конец записи, окончание распознавания, получения ошибок и т.д. Готовый пример приложения можно найти здесь: chapter1_ios, проект speechkit_demo_ios, таргет speechkit_yandex. Сделаем несложный голосовой ассистент, который умеет управлять светом, воспроизведением музыки, поддерживать приветствие и отвечать на различные запросы пользователя. Например, может рассказать анекдот, прочитать цитату или прогноз погоды. Чтобы сделать возможным использование любого речевого SDK используем абстракцию и определим протоколы синтеза и распознавания речи, которые должны будут реализовать конкретные речевые SDK: Например, в случае Apple Speech реализация класса синтеза будет следующая: Из первой части статьи мы также знаем, как использовать распознавание речи, используя Apple Speech, поэтому реализуем класс VBAppleSpeechRecognizer в соответствии с протоколом VBSpeechRecognizerProtocol. Чтобы распознавать окончание записи голоса, сделаем отдельный класс VBVoiceLevelDetector, который реализует протокол VBVoiceLevelDetectorProtocol и будет заниматься отслеживанием начала и окончания записи голосовых фраз. При первом запуске этот класс производит калибровку уровня звука на основе 32 аудио-фреймов. Для абстракции от музыкального сервиса также опишем протокол: и сделаем соответствующую его реализацию в VBAppleMusicPlayer. Реализация через протоколы очень желательна, поскольку в какой-то момент вы можете захотеть использовать, например, SpotifySDK или Mubert API, а в целях совместимости вам не придется ломать жесткие зависимости от Apple Player в приложении и переход будет проще. Теперь нам понадобится главный класс, который будет обрабатывать текстовые запросы от пользователя и выдавать результат. Создадим такой класс VoiceBoxManager, который реализует протокол VoiceBoxManagerProtocol, а в качестве коммуникации он будет работать с классом-делегатом, который должен реализовывать протокол VoiceBoxManagerDelegate. В нашем случае таким делегатом будет выступать VoiceViewModel — View модель для UI контроллера VoiceViewController, который отвечает за визуализацию сообщений и интерфейс пользователя: Итого, VoiceBoxManager — это общий контейнер или конфигуратор для навыков нашего ассистента: , который реализует протокол: Массив _assistantProcessors содержит реализации протокола VBProcessingProtocol, то есть навыки нашего голосового ассистента: Как можно заметить, классы, реализующие навыки через VBProcessingProtocol, должны отвечать словарём, который содержит «type» — тип ответа и «data». Это сделано чтобы унифицировать ответ навыков и иметь возможность запрашивать любые данные через сторонние API. Таким образом, мы можем добавлять новые навыки нашему ассистенту, просто добавляя в этот массив новую реализацию протокола VBProcessingProtocol. Обратите внимание, что обработкой обычных фраз пользователя занимается класс VBLocalVoiceProcessing, который для простоты реализации берёт текстовые значения из файла Resources/voiceProcessigPhrases.plist: Чтобы добавить обычные реплики ассистента достаточно добавить ответы в этом файле. Конечно, это не искусственный интеллект, однако вам ничего не мешает создать свой класс VBAIVoiceProcessing, который реализует протокол VBProcessingProtocol и, например, будет общаться со своим сервером, использующий для обработки фраз русскоязычную модель GPT-3. Тогда ответы ассистента станут намного интереснее и умнее. Пример получения афоризмов и цитат можно посмотреть в реализации VBQuotaProcessing, а новостей в VBNewsProcessing. Навыки умного дома реализует класс VBHomeKitProcessing, который в свою очередь использует VBHomeKitManager для управления устройствами Apple HomeKit. Посмотреть видео-демонстрацию работы приложения можно здесь. В этой статье мы создали мобильные приложение на iOS с использование сторонних речевых SDK. На практике, основные проблемы интеграций речевых технологий заключаются в дополнительных разрешениях, предъявляемых к приложению, получении API ключа и работе с аудио-сессиями. Также попробовали создать собственный голосовой ассистент с абстракцией от используемых речевых технологий и возможностью расширять навыки. В коде примера chapter2_ios добавлены заготовки для навыков получения курсов валют VBCurrencyProcessing и погоды VBWeatherProcessing. В качестве дополнительной тренировки можно реализовать эти навыки самостоятельно, используя любые открытые API сервисов, например, ЦБ, openweather или другие. Вы также можете добавить собственные навыки, которые считаете интересными и поделиться ими. Для этого сделайте форк репозитория, добавьте навыки и отправьте pull запрос, будет любопытно посмотреть. Надеюсь, данная статья была полезна, и вы теперь сможете создавать голосовые помощники для своих проектов или даже создать цифровой продукт, который изменит мир =) Жду ваши примеры реализаций навыков и желаю будущих достижений в области голосовых технологий! iOS, Flutter, IoT, Product'"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "elem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_RZN1fVGeCy"
      },
      "outputs": [],
      "source": [
        "with open('file_habr.txt', 'w') as f:\n",
        "    for elem in new_li:\n",
        "        f.write(elem)\n",
        "        f.write('\\n')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "parse_habr_coursework.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}